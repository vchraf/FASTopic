{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b2bda3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import re\n",
    "import time\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import hdbscan\n",
    "import logging\n",
    "from umap import UMAP\n",
    "import networkx as nx\n",
    "import jellyfish\n",
    "from segtok.segmenter import split_multi\n",
    "from segtok.tokenizer import web_tokenizer, split_contractions\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from fasttext import load_model\n",
    "# fasttext_model = 'cc.en.300.bin'\n",
    "# fmodel = load_model(fasttext_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ac127052",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27b71db8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "363f87a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(text)]\n",
    "# doc2vec_args = {\"vector_size\": 300,\n",
    "#                 \"min_count\": 1,\n",
    "#                 \"window\": 15,\n",
    "#                 \"sample\": 1e-5,\n",
    "#                 \"negative\": 0,\n",
    "#                 \"hs\": 1,\n",
    "#                 \"epochs\": 50,\n",
    "#                 \"dm\": 0,\n",
    "#                 \"dbow_words\": 1,\n",
    "#                 \"workers\":8,\n",
    "#                \"documents\":documents}\n",
    "# model = Doc2Vec(**doc2vec_args)\n",
    "vec=model.dv.get_normed_vectors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c38d2dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 177.27208542823792 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "d489de73",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = getClusers(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "9de55b3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "1cec1ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getClusers(embeddings):\n",
    "    outliers = len(embeddings)*.22\n",
    "    min_cluster_size, min_samples = 15, 2\n",
    "    clusters = np.full(embeddings.shape[0], -1)\n",
    "    _clusters = np.arange(len(clusters))\n",
    "    umap_model = UMAP(n_neighbors=15, n_components=5, min_dist=0.0, metric='cosine', low_memory=False, verbose=False)\n",
    "    if len(embeddings)//50000 < 2:\n",
    "        _umap_embeddings = umap_model.fit_transform(embeddings)\n",
    "        _embeddings = np.nan_to_num(_umap_embeddings) \n",
    "    else:\n",
    "        umap_model.fit(embeddings[np.random.choice(embeddings.shape[0], 60000, replace=False), :])\n",
    "        chunks = np.array_split(embeddings, len(embeddings)//50000)\n",
    "        _umap_embeddings = []\n",
    "        for chunk in chunks:\n",
    "            _umap_embeddings.extend(umap_model.transform(chunk))\n",
    "        _embeddings = np.nan_to_num(_umap_embeddings)    \n",
    "    while(len(_clusters)>outliers):\n",
    "        nbrCl = len(set(clusters))-1\n",
    "        hdbscan_model =hdbscan.HDBSCAN(min_cluster_size=min_cluster_size, metric='euclidean',cluster_selection_method='eom', prediction_data=True)\n",
    "        hdbscan_model.fit(_embeddings)\n",
    "        indexes = np.argwhere(hdbscan_model.labels_!=-1)\n",
    "        for i, v in zip(indexes, hdbscan_model.labels_[indexes]):\n",
    "            clusters[_clusters[i]] = nbrCl + v\n",
    "        _clusters = np.argwhere(hdbscan_model.labels_==-1)\n",
    "        _embeddings = _embeddings[_clusters]\n",
    "        if _embeddings.size == 0: break\n",
    "        _embeddings = _embeddings.reshape(len(_clusters),-1)\n",
    "        min_cluster_size, min_samples = 8, 1\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "0f6a1740",
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_model = UMAP(n_neighbors=15, n_components=5, min_dist=0.0, metric='cosine', low_memory=False, verbose=False)\n",
    "_umap_embeddings = umap_model.fit_transform(vec)\n",
    "vec = np.nan_to_num(_umap_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "1f9905a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-20 {color: black;background-color: white;}#sk-container-id-20 pre{padding: 0;}#sk-container-id-20 div.sk-toggleable {background-color: white;}#sk-container-id-20 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-20 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-20 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-20 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-20 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-20 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-20 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-20 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-20 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-20 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-20 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-20 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-20 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-20 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-20 div.sk-item {position: relative;z-index: 1;}#sk-container-id-20 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-20 div.sk-item::before, #sk-container-id-20 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-20 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-20 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-20 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-20 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-20 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-20 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-20 div.sk-label-container {text-align: center;}#sk-container-id-20 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-20 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-20\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>HDBSCAN(min_cluster_size=10, prediction_data=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" checked><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">HDBSCAN</label><div class=\"sk-toggleable__content\"><pre>HDBSCAN(min_cluster_size=10, prediction_data=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "HDBSCAN(min_cluster_size=10, prediction_data=True)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdbscan_model =hdbscan.HDBSCAN(min_cluster_size=10,metric='euclidean', cluster_selection_method='eom', prediction_data=True)\n",
    "hdbscan_model.fit(vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "23fa00ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(hdbscan_model.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c3387585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 31    15934\n",
       "-1       591\n",
       " 22      330\n",
       " 33      221\n",
       " 27      118\n",
       " 18      100\n",
       " 4        96\n",
       " 37       94\n",
       " 26       78\n",
       " 9        75\n",
       " 21       74\n",
       " 2        70\n",
       " 39       64\n",
       " 38       63\n",
       " 36       57\n",
       " 24       56\n",
       " 5        54\n",
       " 0        53\n",
       " 20       52\n",
       " 6        51\n",
       " 35       48\n",
       " 40       42\n",
       " 17       36\n",
       " 10       35\n",
       " 34       34\n",
       " 14       33\n",
       " 13       33\n",
       " 12       31\n",
       " 30       31\n",
       " 16       30\n",
       " 19       28\n",
       " 7        28\n",
       " 25       27\n",
       " 28       25\n",
       " 11       22\n",
       " 8        21\n",
       " 1        21\n",
       " 23       19\n",
       " 32       18\n",
       " 3        18\n",
       " 29       18\n",
       " 15       17\n",
       "dtype: int64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(hdbscan_model.labels_).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef231320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.23317775e-02,  6.58288971e-02,  1.25106825e-02, -4.74178381e-02,\n",
       "        9.59125534e-02, -8.63540992e-02,  1.06869541e-01,  4.76633608e-02,\n",
       "       -5.09298705e-02,  1.33005483e-03,  3.01549155e-02, -3.32995206e-02,\n",
       "       -2.41408721e-01, -4.43766341e-02,  3.22487056e-02,  4.10272405e-02,\n",
       "        2.75378376e-02, -3.78786437e-02,  7.90869370e-02, -7.90262222e-02,\n",
       "       -9.73701254e-02, -3.10429204e-02, -1.16537482e-01,  3.34297046e-02,\n",
       "        7.74220154e-02,  1.29241766e-02, -1.26352319e-02,  4.17493656e-02,\n",
       "       -8.17062855e-02,  5.59743047e-02,  3.79567780e-02, -2.77244654e-02,\n",
       "        6.10271618e-02, -1.00215171e-02,  2.29185987e-02,  7.88366199e-02,\n",
       "       -3.42737697e-03,  6.49926718e-03,  3.69488075e-02, -2.08858456e-02,\n",
       "        2.59066354e-02, -8.15460235e-02, -2.62043942e-02, -2.34507141e-03,\n",
       "        1.02848105e-01, -1.46775749e-02,  3.36938538e-02, -1.74646638e-02,\n",
       "        4.09522206e-02, -5.62588591e-03,  1.36226401e-01, -1.82062000e-01,\n",
       "       -7.86272157e-03,  1.32019147e-02,  2.83296984e-02,  3.18722390e-02,\n",
       "        4.15803418e-02, -2.46280432e-02,  1.58578232e-01,  3.66506726e-02,\n",
       "        2.61727185e-03,  3.25296745e-02, -2.48778481e-02, -7.20695406e-02,\n",
       "       -1.88880898e-02, -1.74974725e-02,  9.44889635e-02,  4.10668328e-02,\n",
       "       -6.81274459e-02,  9.85744223e-02,  6.44591749e-02,  1.18245654e-01,\n",
       "        1.45181967e-02, -1.04780421e-01,  1.52993314e-02,  1.18855059e-01,\n",
       "       -9.97546986e-02, -4.17859517e-02, -4.55764122e-02, -3.59726325e-02,\n",
       "        7.96786547e-02,  4.87054093e-03, -4.41185199e-02,  7.84306377e-02,\n",
       "        5.64406812e-02,  2.57008318e-02,  9.13406629e-03, -1.16884355e-02,\n",
       "        4.62101139e-02, -2.42028963e-02, -7.06244353e-03, -4.59510498e-02,\n",
       "        9.30798426e-02,  8.85573477e-02,  6.63928613e-02,  4.74368781e-02,\n",
       "        7.51434341e-02, -5.64662516e-02, -5.16942702e-02,  3.98461847e-03,\n",
       "       -3.77084091e-02, -1.63449924e-02,  4.20592017e-02,  4.23662029e-02,\n",
       "       -4.98900972e-02,  1.93150043e-02, -6.01080172e-02,  2.06208043e-02,\n",
       "        9.52990651e-02,  2.72109006e-02,  1.66902842e-03,  8.18124935e-02,\n",
       "       -2.80443635e-02,  6.87763374e-03,  4.53673415e-02, -8.04475322e-03,\n",
       "        3.03254686e-02, -2.01134961e-02,  2.11376362e-02,  1.67200360e-02,\n",
       "       -1.01535141e-01,  6.43507615e-02,  1.70351099e-02, -3.41566317e-02,\n",
       "        3.54502536e-02, -3.81862442e-03, -1.07397415e-01, -2.31470391e-02,\n",
       "       -1.00622810e-02,  8.46637934e-02,  4.64556143e-02,  4.22211289e-02,\n",
       "       -7.99112990e-02,  1.16443262e-01, -1.31219313e-01, -2.68320069e-02,\n",
       "       -3.87863852e-02,  2.20465660e-03,  2.48426795e-02,  7.38679431e-03,\n",
       "       -9.38466638e-02, -7.93622360e-02, -1.79305486e-02,  2.70209070e-02,\n",
       "       -2.25150306e-02,  2.82216053e-02,  4.81506996e-03,  4.83142510e-02,\n",
       "       -3.97785008e-02, -2.52306052e-02,  6.21450879e-03,  5.64349350e-03,\n",
       "       -1.64819863e-02, -2.62220856e-02, -3.50103937e-02, -2.55029202e-02,\n",
       "       -3.56326364e-02,  6.13306575e-02,  5.67431077e-02,  1.78189110e-02,\n",
       "        6.86491802e-02, -5.10844700e-02,  2.07344778e-02, -3.67056020e-02,\n",
       "        9.92684998e-03,  1.08811356e-01,  3.58212441e-02, -4.87368368e-02,\n",
       "        5.64201102e-02,  1.41476184e-01, -3.76146436e-02, -7.96637088e-02,\n",
       "        3.32133658e-03, -2.89510470e-02, -2.63087191e-02, -2.54685283e-02,\n",
       "       -2.23709755e-02,  5.10727521e-03,  1.92886405e-02, -8.29484407e-03,\n",
       "       -5.94617100e-03, -1.51869757e-02,  1.05461933e-01, -1.12736421e-02,\n",
       "       -8.93503521e-03,  6.36677146e-02, -1.15235172e-01, -3.54180597e-02,\n",
       "       -5.86164445e-02, -7.90402889e-02, -2.76696030e-02,  2.14728471e-02,\n",
       "        7.87818059e-02,  1.37761563e-01,  8.96038041e-02,  1.03032455e-01,\n",
       "        1.42539963e-02, -5.81936091e-02,  4.69431728e-02, -2.16585789e-02,\n",
       "        9.59674176e-03, -1.08840168e-01,  7.54501438e-03,  8.28667358e-02,\n",
       "        2.12363917e-02,  4.75923494e-02, -1.18406862e-02, -5.81901930e-02,\n",
       "       -7.04979375e-02, -6.44429103e-02,  9.93269682e-02,  4.39746119e-02,\n",
       "       -2.79133189e-02,  8.16211104e-03,  9.67032388e-02, -5.13138808e-02,\n",
       "       -1.63957812e-02, -3.27040330e-02,  7.52690202e-03,  7.77279306e-03,\n",
       "        5.41353002e-02,  2.32406054e-02,  4.74172346e-02,  3.29951346e-02,\n",
       "        1.78010575e-02,  2.13339720e-02, -5.21208942e-02, -5.52930981e-02,\n",
       "       -1.21368915e-01,  3.44964936e-02, -8.55921768e-03,  1.71026234e-02,\n",
       "       -6.26251101e-02,  5.67794554e-02, -1.71040818e-02,  8.76564384e-02,\n",
       "        1.49241276e-03,  2.34015491e-02, -6.96144300e-03, -2.93357708e-02,\n",
       "        3.90921421e-02,  5.52415326e-02,  1.46051240e-03,  1.65954083e-02,\n",
       "       -5.06964466e-03,  2.54857130e-02,  2.10183091e-03, -1.01775244e-01,\n",
       "        7.32398704e-02, -9.25367177e-02, -9.26365182e-02, -4.26099263e-02,\n",
       "        3.70286442e-02,  3.08970883e-02,  1.37187755e-02, -4.55443077e-02,\n",
       "       -5.28114736e-02,  8.68417621e-02, -3.53679322e-02,  1.14249200e-01,\n",
       "        5.74982949e-02,  4.07080278e-02, -1.80478431e-02, -1.78302322e-02,\n",
       "        6.07021712e-03,  2.03030817e-02,  1.22479014e-01,  5.83612919e-02,\n",
       "        1.36489749e-01,  4.89991680e-02, -8.08543265e-02, -4.65011597e-02,\n",
       "        6.00695889e-03, -1.19878009e-01, -1.90942716e-02, -7.53857894e-03,\n",
       "       -3.66562866e-02, -4.03863229e-02,  7.03391479e-03, -4.54325490e-02,\n",
       "       -2.69411616e-02, -2.20288113e-02, -3.27119306e-02, -4.40411344e-02,\n",
       "       -2.47541536e-02,  3.72542068e-02,  1.61613300e-02,  2.70687975e-02,\n",
       "        2.12191066e-04,  1.26069458e-02,  2.24778671e-02,  4.39045345e-03,\n",
       "        2.43096557e-02,  5.35274763e-03,  1.68543011e-02,  1.68225486e-02,\n",
       "        2.31075082e-02,  1.89986043e-02, -3.49343778e-03, -9.74295810e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vecs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "7b2d1b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORD_WEIGHT = 'bi'\n",
    "class DataCore(object):\n",
    "    \n",
    "    def __init__(self, text, stopword_set, windowsSize, n, tagsToDiscard = set(['u', 'd']), exclude = set(string.punctuation)):\n",
    "        self.number_of_sentences = 0\n",
    "        self.number_of_words = 0\n",
    "        self.terms = {}\n",
    "        self.candidates = {}\n",
    "        self.sentences_obj = []\n",
    "        self.sentences_str = []\n",
    "        self.G = nx.DiGraph()\n",
    "        self.exclude = exclude\n",
    "        self.tagsToDiscard = tagsToDiscard\n",
    "        self.freq_ns = {}\n",
    "        for i in range(n):\n",
    "            self.freq_ns[i+1] = 0.\n",
    "        self.stopword_set = stopword_set\n",
    "        self._build(text, windowsSize, n)\n",
    "\n",
    "    # Build the datacore features\n",
    "    def _build(self, text, windowsSize, n):\n",
    "        text = self.pre_filter(text)\n",
    "        self.sentences_str = [ [w for w in split_contractions(web_tokenizer(s)) if not (w.startswith(\"'\") and len(w) > 1) and len(w) > 0] for s in list(split_multi(text)) if len(s.strip()) > 0]\n",
    "        self.number_of_sentences = len(self.sentences_str)\n",
    "        pos_text = 0\n",
    "        block_of_word_obj = []\n",
    "        sentence_obj_aux = []\n",
    "        for (sentence_id, sentence) in enumerate(self.sentences_str):\n",
    "            sentence_obj_aux = []\n",
    "            block_of_word_obj = []\n",
    "            for (pos_sent, word) in enumerate(sentence):\n",
    "                if len([c for c in word if c in self.exclude]) == len(word): # If the word is based on exclude chars\n",
    "                    if len(block_of_word_obj) > 0:\n",
    "                        sentence_obj_aux.append( block_of_word_obj )\n",
    "                        block_of_word_obj = []\n",
    "                else:\n",
    "                    tag = self.getTag(word, pos_sent)\n",
    "                    term_obj = self.getTerm(word)\n",
    "                    term_obj.addOccur(tag, sentence_id, pos_sent, pos_text)\n",
    "                    pos_text += 1\n",
    "\n",
    "                    #Create co-occurrence matrix\n",
    "                    if tag not in self.tagsToDiscard:\n",
    "                        word_windows = list(range( max(0, len(block_of_word_obj)-windowsSize), len(block_of_word_obj) ))\n",
    "                        for w in word_windows:\n",
    "                            if block_of_word_obj[w][0] not in self.tagsToDiscard: \n",
    "                                self.addCooccur(block_of_word_obj[w][2], term_obj)\n",
    "                    #Generate candidate keyphrase list\n",
    "                    candidate = [ (tag, word, term_obj) ]\n",
    "                    cand = composed_word(candidate)\n",
    "                    self.addOrUpdateComposedWord(cand)\n",
    "                    word_windows = list(range( max(0, len(block_of_word_obj)-(n-1)), len(block_of_word_obj) ))[::-1]\n",
    "                    for w in word_windows:\n",
    "                        candidate.append(block_of_word_obj[w])\n",
    "                        self.freq_ns[len(candidate)] += 1.\n",
    "                        cand = composed_word(candidate[::-1])\n",
    "                        self.addOrUpdateComposedWord(cand)\n",
    "\n",
    "                    # Add term to the block of words' buffer\n",
    "                    block_of_word_obj.append( (tag, word, term_obj) )\n",
    "\n",
    "            if len(block_of_word_obj) > 0:\n",
    "                sentence_obj_aux.append( block_of_word_obj )\n",
    "\n",
    "            if len(sentence_obj_aux) > 0:\n",
    "                self.sentences_obj.append(sentence_obj_aux)\n",
    "\n",
    "        if len(block_of_word_obj) > 0:\n",
    "            sentence_obj_aux.append( block_of_word_obj )\n",
    "\n",
    "        if len(sentence_obj_aux) > 0:\n",
    "            self.sentences_obj.append(sentence_obj_aux)\n",
    "\n",
    "        self.number_of_words = pos_text\n",
    "\n",
    "    def build_single_terms_features(self, features=None):\n",
    "        validTerms = [ term for term in self.terms.values() if not term.stopword ]\n",
    "        validTFs = (np.array([ x.tf for x in validTerms ]))\n",
    "\n",
    "        if len(validTFs) == 0:\n",
    "            return\n",
    "\n",
    "        avgTF = validTFs.mean()\n",
    "        stdTF = validTFs.std()\n",
    "        maxTF = max([ x.tf for x in self.terms.values()])\n",
    "        list(map(lambda x: x.updateH(maxTF=maxTF, avgTF=avgTF, stdTF=stdTF, number_of_sentences=self.number_of_sentences, features=features), self.terms.values()))\n",
    "\n",
    "    def build_mult_terms_features(self, features=None):\n",
    "        list(map(lambda x: x.updateH(features=features), [cand for cand in self.candidates.values() if cand.isValid()]))\n",
    "\n",
    "    def pre_filter(self, text):\n",
    "        prog = re.compile(\"^(\\\\s*([A-Z]))\")\n",
    "        parts = text.split('\\n')\n",
    "        buffer = ''\n",
    "        for part in parts:\n",
    "            sep = ' '\n",
    "            if prog.match(part):\n",
    "                sep = '\\n\\n'\n",
    "            buffer += sep + part.replace('\\t',' ')\n",
    "        return buffer\n",
    "\n",
    "    def getTag(self, word, i):\n",
    "        try:\n",
    "            w2 = word.replace(\",\",\"\")\n",
    "            float(w2)\n",
    "            return \"d\"\n",
    "        except:\n",
    "            cdigit = len([c for c in word if c.isdigit()])\n",
    "            calpha = len([c for c in word if c.isalpha()])\n",
    "            if ( cdigit > 0 and calpha > 0 ) or (cdigit == 0 and calpha == 0) or len([c for c in word if c in self.exclude]) > 1:\n",
    "                return \"u\"\n",
    "            if len(word) == len([c for c in word if c.isupper()]):\n",
    "                return \"a\"\n",
    "            if len([c for c in word if c.isupper()]) == 1 and len(word) > 1 and word[0].isupper() and i > 0:\n",
    "                return \"n\"\n",
    "        return \"p\"\n",
    "\n",
    "    def getTerm(self, str_word, save_non_seen=True):\n",
    "        unique_term = str_word.lower()\n",
    "        simples_sto = unique_term in self.stopword_set\n",
    "        if unique_term.endswith('s') and len(unique_term) > 3:\n",
    "            unique_term = unique_term[:-1]\n",
    "\n",
    "        if unique_term in self.terms:\n",
    "            return self.terms[unique_term]\n",
    "                \n",
    "        # Include this part\n",
    "        simples_unique_term = unique_term\n",
    "        for pontuation in self.exclude:\n",
    "            simples_unique_term = simples_unique_term.replace(pontuation, '')\n",
    "        # until here\n",
    "        isstopword = simples_sto or unique_term in self.stopword_set or len(simples_unique_term) < 3\n",
    "        \n",
    "        term_id = len(self.terms)\n",
    "        term_obj = single_word(unique_term, term_id, self.G)\n",
    "        term_obj.stopword = isstopword\n",
    "\n",
    "        if save_non_seen:\n",
    "            self.G.add_node(term_id)\n",
    "            self.terms[unique_term] = term_obj\n",
    "\n",
    "        return term_obj\n",
    "\n",
    "    def addCooccur(self, left_term, right_term):\n",
    "        if right_term.id not in self.G[left_term.id]:\n",
    "            self.G.add_edge(left_term.id, right_term.id, TF=0.)\n",
    "        self.G[left_term.id][right_term.id][\"TF\"]+=1.\n",
    "        \n",
    "    def addOrUpdateComposedWord(self, cand):\n",
    "        if cand.unique_kw not in self.candidates:\n",
    "            self.candidates[cand.unique_kw] = cand\n",
    "        else:\n",
    "            self.candidates[cand.unique_kw].uptadeCand(cand)\n",
    "        self.candidates[cand.unique_kw].tf += 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c15a1e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class composed_word(object):\n",
    "    def __init__(self, terms): # [ (tag, word, term_obj) ]\n",
    "        if terms == None:\n",
    "             self.start_or_end_stopwords = True\n",
    "             self.tags = set()\n",
    "             return\n",
    "        self.tags = set([''.join([ w[0] for w in terms ])])\n",
    "        self.kw = ' '.join( [ w[1] for w in terms ] )\n",
    "        self.unique_kw = self.kw.lower()\n",
    "        self.size = len(terms)\n",
    "        self.terms = [ w[2] for w in terms if w[2] != None ]\n",
    "        self.tf = 0.\n",
    "        self.integrity = 1.\n",
    "        self.H = 1.\n",
    "        self.start_or_end_stopwords = self.terms[0].stopword or self.terms[-1].stopword\n",
    "\n",
    "    def uptadeCand(self, cand):\n",
    "        for tag in cand.tags:\n",
    "            self.tags.add( tag )\n",
    "\n",
    "    def isValid(self):\n",
    "        isValid = False\n",
    "        for tag in self.tags:\n",
    "            isValid = isValid or ( \"u\" not in tag and \"d\" not in tag )\n",
    "        return isValid and not self.start_or_end_stopwords\n",
    "\n",
    "    def get_composed_feature(self, feature_name, discart_stopword=True):\n",
    "        list_of_features = [ getattr(term, feature_name) for term in self.terms if ( discart_stopword and not term.stopword ) or not discart_stopword ]\n",
    "        sum_f  = sum(list_of_features)\n",
    "        prod_f = np.prod(list_of_features)\n",
    "        return ( sum_f, prod_f, prod_f /(sum_f + 1) )\n",
    "\n",
    "    def build_features(self, doc_id=None, keys=None, rel=True, rel_approx=True, isVirtual=False, features=['WFreq', 'WRel', 'tf', 'WCase', 'WPos', 'WSpread'], _stopword=[True, False]):\n",
    "        columns = []\n",
    "        seen = set()\n",
    "        features_cand = []\n",
    "\n",
    "        if doc_id != None:\n",
    "            columns.append('doc_id')\n",
    "            features_cand.append(doc_id)\n",
    "\n",
    "        if keys != None:\n",
    "            if rel:\n",
    "                columns.append('rel')\n",
    "                if self.unique_kw in keys or isVirtual:\n",
    "                    features_cand.append(1)\n",
    "                    seen.add(self.unique_kw)\n",
    "                else:\n",
    "                    features_cand.append(0)\n",
    "\n",
    "            if rel_approx:\n",
    "                columns.append('rel_approx')\n",
    "                max_gold_ = ('', 0.)\n",
    "                for gold_key in keys:\n",
    "                    dist = 1.-jellyfish.levenshtein_distance(gold_key, self.unique_kw ) / max(len(gold_key), len(self.unique_kw)) # _tL\n",
    "                    if max_gold_[1] < dist:\n",
    "                        max_gold_ = ( gold_key, dist )\n",
    "                features_cand.append(max_gold_[1])\n",
    "\n",
    "        columns.append('kw')\n",
    "        features_cand.append(self.unique_kw)\n",
    "        columns.append('h')\n",
    "        features_cand.append(self.H)\n",
    "        columns.append('tf')\n",
    "        features_cand.append(self.tf)\n",
    "        columns.append('size')\n",
    "        features_cand.append(self.size)\n",
    "        columns.append('isVirtual')\n",
    "        features_cand.append(int(isVirtual))\n",
    "\n",
    "        for feature_name in features:\n",
    "\n",
    "            for discart_stopword in _stopword:\n",
    "                (f_sum, f_prod, f_sum_prod) = self.get_composed_feature(feature_name, discart_stopword=discart_stopword)\n",
    "                columns.append('%ss_sum_K%s' % ('n' if discart_stopword else '', feature_name) )\n",
    "                features_cand.append(f_sum)\n",
    "\n",
    "                columns.append('%ss_prod_K%s' % ('n' if discart_stopword else '', feature_name) )\n",
    "                features_cand.append(f_prod)\n",
    "\n",
    "                columns.append('%ss_sum_prod_K%s' % ('n' if discart_stopword else '', feature_name) )\n",
    "                features_cand.append(f_sum_prod)\n",
    "\n",
    "        return (features_cand, columns, seen)\n",
    "\n",
    "    def updateH(self, features=None, isVirtual=False):\n",
    "        sum_H  = 0.\n",
    "        prod_H = 1.\n",
    "\n",
    "        for (t, term_base) in enumerate(self.terms):\n",
    "            if not term_base.stopword:\n",
    "                sum_H += term_base.H\n",
    "                prod_H *= term_base.H\n",
    "\n",
    "            else:\n",
    "                if STOPWORD_WEIGHT == 'bi':\n",
    "                    prob_t1 = 0.\n",
    "                    if term_base.G.has_edge(self.terms[t-1].id, self.terms[ t ].id):\n",
    "                        prob_t1 = term_base.G[self.terms[t-1].id][self.terms[ t ].id][\"TF\"] / self.terms[t-1].tf\n",
    "\n",
    "                    prob_t2 = 0.\n",
    "                    if term_base.G.has_edge(self.terms[ t ].id, self.terms[t+1].id):\n",
    "                        prob_t2 = term_base.G[self.terms[ t ].id][self.terms[t+1].id][\"TF\"] / self.terms[t+1].tf\n",
    "\n",
    "                    prob = prob_t1 * prob_t2\n",
    "                    prod_H *= (1 + (1 - prob ) )\n",
    "                    sum_H -= (1 - prob)\n",
    "                elif STOPWORD_WEIGHT == 'h':\n",
    "                    sum_H += term_base.H\n",
    "                    prod_H *= term_base.H\n",
    "                elif STOPWORD_WEIGHT == 'none':\n",
    "                    pass\n",
    "\n",
    "        tf_used = 1.\n",
    "        if features == None or \"KPF\" in features:\n",
    "            tf_used = self.tf\n",
    "\n",
    "        if isVirtual:\n",
    "            tf_used = np.mean( [term_obj.tf for term_obj in self.terms] )\n",
    "\n",
    "        self.H = prod_H / ( ( sum_H + 1 ) * tf_used )\n",
    "\n",
    "    def updateH_old(self, features=None, isVirtual=False):\n",
    "        sum_H  = 0.\n",
    "        prod_H = 1.\n",
    "\n",
    "        for (t, term_base) in enumerate(self.terms):\n",
    "            if isVirtual and term_base.tf==0:\n",
    "                continue\n",
    "\n",
    "            if term_base.stopword:\n",
    "                prob_t1 = 0.\n",
    "                if term_base.G.has_edge(self.terms[t-1].id, self.terms[ t ].id):\n",
    "                    prob_t1 = term_base.G[self.terms[t-1].id][self.terms[ t ].id][\"TF\"] / self.terms[t-1].tf\n",
    "\n",
    "                prob_t2 = 0.\n",
    "                if term_base.G.has_edge(self.terms[ t ].id, self.terms[t+1].id):\n",
    "                    prob_t2 = term_base.G[self.terms[ t ].id][self.terms[t+1].id][\"TF\"] / self.terms[t+1].tf\n",
    "\n",
    "                prob = prob_t1 * prob_t2\n",
    "                prod_H *= (1 + (1 - prob ) )\n",
    "                sum_H -= (1 - prob)\n",
    "            else:\n",
    "                sum_H += term_base.H\n",
    "                prod_H *= term_base.H\n",
    "        tf_used = 1.\n",
    "        if features == None or \"KPF\" in features:\n",
    "            tf_used = self.tf\n",
    "        if isVirtual:\n",
    "            tf_used = np.mean( [term_obj.tf for term_obj in self.terms] )\n",
    "        self.H = prod_H / ( ( sum_H + 1 ) * tf_used )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "7b37228e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class single_word(object):\n",
    "\n",
    "    def __init__(self, unique, idx, graph):\n",
    "        self.unique_term = unique\n",
    "        self.id = idx\n",
    "        self.tf = 0.\n",
    "        self.WFreq = 0.0\n",
    "        self.WCase = 0.0\n",
    "        self.tf_a = 0.\n",
    "        self.tf_n = 0.\n",
    "        self.WRel = 1.0\n",
    "        self.PL = 0.\n",
    "        self.PR = 0.\n",
    "        self.occurs = {}\n",
    "        self.WPos = 1.0\n",
    "        self.WSpread = 0.0\n",
    "        self.H = 0.0\n",
    "        self.stopword = False\n",
    "        self.G = graph\n",
    "\n",
    "        self.pagerank = 1.\n",
    "\n",
    "    def updateH(self, maxTF, avgTF, stdTF, number_of_sentences, features=None):\n",
    "        \"\"\"if features == None or \"WRel\" in features:\n",
    "            self.PL = self.WDL / maxTF\n",
    "            self.PR = self.WDR / maxTF\n",
    "            self.WRel = ( (0.5 + (self.PWL * (self.tf / maxTF) + self.PL)) + (0.5 + (self.PWR * (self.tf / maxTF) + self.PR)) )\"\"\"\n",
    "\n",
    "        if features == None or \"WRel\" in features:\n",
    "            self.PL = self.WDL / maxTF\n",
    "            self.PR = self.WDR / maxTF\n",
    "            self.WRel = ( (0.5 + (self.PWL * (self.tf / maxTF))) + (0.5 + (self.PWR * (self.tf / maxTF))) )\n",
    "\n",
    "        if features == None or \"WFreq\" in features:\n",
    "            self.WFreq = self.tf / (avgTF + stdTF)\n",
    "        \n",
    "        if features == None or \"WSpread\" in features:\n",
    "            self.WSpread = len(self.occurs) / number_of_sentences\n",
    "        \n",
    "        if features == None or \"WCase\" in features:\n",
    "            self.WCase = max(self.tf_a, self.tf_n) / (1. + math.log(self.tf))\n",
    "        \n",
    "        if features == None or \"WPos\" in features:\n",
    "            self.WPos = math.log( math.log( 3. + np.median(list(self.occurs.keys())) ) )\n",
    "\n",
    "        self.H = (self.WPos * self.WRel) / (self.WCase + (self.WFreq / self.WRel) + (self.WSpread / self.WRel))\n",
    "        \n",
    "    @property\n",
    "    def WDR(self):\n",
    "        return len( self.G.out_edges(self.id) )\n",
    "\n",
    "    @property\n",
    "    def WIR(self):\n",
    "        return sum( [ d['TF'] for (u,v,d) in self.G.out_edges(self.id, data=True) ] )\n",
    "\n",
    "    @property\n",
    "    def PWR(self):\n",
    "        wir = self.WIR\n",
    "        if wir == 0:\n",
    "            return 0\n",
    "        return self.WDR / wir \n",
    "    \n",
    "    @property\n",
    "    def WDL(self):\n",
    "        return len( self.G.in_edges(self.id) )\n",
    "\n",
    "    @property\n",
    "    def WIL(self):\n",
    "        return sum( [ d['TF'] for (u,v,d) in self.G.in_edges(self.id, data=True) ] )\n",
    "\n",
    "    @property\n",
    "    def PWL(self):\n",
    "        wil = self.WIL\n",
    "        if wil == 0:\n",
    "            return 0\n",
    "        return self.WDL / wil \n",
    "\n",
    "    def addOccur(self, tag, sent_id, pos_sent, pos_text):\n",
    "        if sent_id not in self.occurs:\n",
    "            self.occurs[sent_id] = []\n",
    "\n",
    "        self.occurs[sent_id].append( (pos_sent, pos_text) )\n",
    "        self.tf += 1.\n",
    "\n",
    "        if tag == \"a\":\n",
    "            self.tf_a += 1.\n",
    "        if tag == \"n\":\n",
    "            self.tf_n += 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "1f9ededd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TopicsExtractor(object):\n",
    "    def __init__(self, top=20, features=None, stopwords=None):\n",
    "        self.stopword_set = set(stopwords)\n",
    "        self.n = 1\n",
    "        self.top = top\n",
    "        self.dedupLim = 0.9\n",
    "        self.features = features\n",
    "        self.windowsSize = 10\n",
    "        self.dedu_function = self.jaro\n",
    "#         fasttext_model = 'cc.en.300.bin'#'wiki/wiki.fr.bin'\n",
    "#         self.model = load_model(fasttext_model)\n",
    "        logging.basicConfig(format='%(asctime)s - %(message)s', level=logging.INFO)\n",
    "        logging.info('model init')\n",
    "    \n",
    "    def txtPreprocessing(self, txt):\n",
    "        _txtpp = []\n",
    "        for s in txt:\n",
    "            x = str(s).lower()\n",
    "            x = re.sub(r'http\\S+', ' ', x)\n",
    "            x = re.sub('<.*?>', ' ', x)\n",
    "            x = re.sub(' +', ' ', x)\n",
    "            x = re.sub(\"\\[.*?\\]\",\" \",x)\n",
    "            x = re.sub(\"['\\\"\\\\n]\",\" \", x)\n",
    "            x = re.sub(\"www.\\S+\",\" \", x)\n",
    "            x = re.sub('[{’{»|«}~}]', ' ',x)\n",
    "            x = re.sub('\\s+', ' ', x)\n",
    "            x = re.sub(\"(.)\\\\1{2,}\", \"\\\\1\", x)\n",
    "            x = re.sub(' +', ' ',x)\n",
    "            x = x.strip()\n",
    "            _txtpp.append(x)\n",
    "        return _txtpp\n",
    "    \n",
    "    def txtEmbedding(self, txt):\n",
    "        documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(txt)]\n",
    "        doc2vec_args = {\"vector_size\": 300,\n",
    "                \"min_count\": 1,\n",
    "                \"window\": 15,\n",
    "                \"sample\": 1e-5,\n",
    "                \"negative\": 0,\n",
    "                \"hs\": 1,\n",
    "                \"epochs\": 50,\n",
    "                \"dm\": 0,\n",
    "                \"dbow_words\": 1,\n",
    "                \"workers\":8,\n",
    "               \"documents\":documents}\n",
    "        model = Doc2Vec(**doc2vec_args)\n",
    "        return model.dv.get_normed_vectors()\n",
    "\n",
    "\n",
    "    \n",
    "    def getClusers(self, embeddings):\n",
    "        outliers = len(embeddings)*.22\n",
    "        min_cluster_size, min_samples = 15, 2\n",
    "        clusters = np.full(embeddings.shape[0], -1)\n",
    "        _clusters = np.arange(len(clusters))\n",
    "\n",
    "        umap_model = UMAP(n_neighbors=15, n_components=5, min_dist=0.0, metric='cosine', low_memory=False, verbose=False)\n",
    "        if len(embeddings)//50000 < 2:\n",
    "            _umap_embeddings = umap_model.fit_transform(embeddings)\n",
    "            _embeddings = np.nan_to_num(_umap_embeddings) \n",
    "        else:\n",
    "            umap_model.fit(embeddings[np.random.choice(embeddings.shape[0], 60000, replace=False), :])\n",
    "            chunks = np.array_split(embeddings, len(embeddings)//50000)\n",
    "            _umap_embeddings = []\n",
    "            for chunk in chunks:\n",
    "                _umap_embeddings.extend(umap_model.transform(chunk))\n",
    "            _embeddings = np.nan_to_num(_umap_embeddings)    \n",
    "        while(len(_clusters)>outliers):\n",
    "            nbrCl = len(set(clusters))-1\n",
    "            hdbscan_model =hdbscan.HDBSCAN(min_cluster_size=min_cluster_size, metric='euclidean',cluster_selection_method='eom', prediction_data=True)\n",
    "            hdbscan_model.fit(_embeddings)\n",
    "            indexes = np.argwhere(hdbscan_model.labels_!=-1)\n",
    "            for i, v in zip(indexes, hdbscan_model.labels_[indexes]):\n",
    "                clusters[_clusters[i]] = nbrCl + v\n",
    "            _clusters = np.argwhere(hdbscan_model.labels_==-1)\n",
    "            _embeddings = _embeddings[_clusters]\n",
    "            if _embeddings.size == 0: break\n",
    "            _embeddings = _embeddings.reshape(len(_clusters),-1)\n",
    "            min_cluster_size, min_samples = 9, 1\n",
    "        return clusters\n",
    "\n",
    "    def getFreqKeywords(self,doc):\n",
    "        tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,1), stop_words=self.stopword_set)\n",
    "        tfidf = tfidf_vectorizer.fit_transform([doc])\n",
    "        score = np.argsort(np.asarray(tfidf.sum(axis=0)).ravel())[::-1]\n",
    "        candidates = np.array(tfidf_vectorizer.get_feature_names_out())[score[:np.minimum(450,len(score)-1)]]\n",
    "        return ' '.join(candidates)\n",
    "\n",
    "    def jaro(self, cand1, cand2):\n",
    "        return jellyfish.jaro_winkler(cand1, cand2 )\n",
    "\n",
    "    def extract_keywords(self, text):\n",
    "        try:\n",
    "            if not(len(text) > 0):\n",
    "                return []\n",
    "            \n",
    "            text = text.replace('\\n\\t',' ')\n",
    "            dc = DataCore(text=text, stopword_set=self.stopword_set, windowsSize=self.windowsSize, n=self.n)\n",
    "            dc.build_single_terms_features(features=self.features)\n",
    "            dc.build_mult_terms_features(features=self.features)\n",
    "            resultSet = []\n",
    "            todedup = sorted([cc for cc in dc.candidates.values() if cc.isValid()], key=lambda c: c.H)\n",
    "\n",
    "            if self.dedupLim >= 1.:\n",
    "                return ([ (cand.H, cand.unique_kw) for cand in todedup])[:self.top]\n",
    "\n",
    "            for cand in todedup:\n",
    "                toadd = True\n",
    "                for (h, candResult) in resultSet:\n",
    "                    dist = self.dedu_function(cand.unique_kw, candResult.unique_kw)\n",
    "                    if dist > self.dedupLim:\n",
    "                        toadd = False\n",
    "                        break\n",
    "                if toadd:\n",
    "                    resultSet.append( (cand.H, cand) )\n",
    "                if len(resultSet) == self.top:\n",
    "                    break\n",
    "\n",
    "            return \" \".join([cand.kw for (h,cand) in resultSet])\n",
    "        except Exception as e:\n",
    "            print(f\"Warning! Exception: {e} generated by the following text: '{text}' \")\n",
    "            return []\n",
    "    \n",
    "    def groupBy(self, txtpp, clusters, nbrClusters):\n",
    "        docs = np.full((nbrClusters, ), \"\",dtype=object)\n",
    "        for cluster, txt in zip(clusters,txtpp):\n",
    "            docs[cluster+1] += txt\n",
    "        return docs\n",
    "    \n",
    "    def extract_topics_keywords(self, docs):\n",
    "        topics = {}\n",
    "        for i, doc in enumerate(docs):\n",
    "            topics[i-1]=self.extract_keywords(doc)\n",
    "        return topics\n",
    "\n",
    "    def clusterreduction(self, docs, nbrClusters, clusters):\n",
    "        freqKey = []\n",
    "        embeddings = []\n",
    "        for doc in docs[1:]: freqKey.append(self.getFreqKeywords(doc))\n",
    "        for doc in freqKey:embeddings.append(self.model.get_sentence_vector(doc))\n",
    "        hdbscan_model =hdbscan.HDBSCAN(min_cluster_size=3, metric='euclidean', cluster_selection_method='eom', prediction_data=True)\n",
    "        hdbscan_model.fit(embeddings)\n",
    "        print(hdbscan_model.labels_, set(hdbscan_model.labels_))\n",
    "        mapper = []\n",
    "        for i, lable in enumerate(hdbscan_model.labels_):\n",
    "            if lable !=-1:\n",
    "                mapper.append(nbrClusters + lable)\n",
    "            else:\n",
    "                mapper.append(i + 1)\n",
    "        _args = np.array(sorted(mapper))\n",
    "        \n",
    "        for i, lable in enumerate(mapper): \n",
    "            mapper[i]=np.argwhere(lable == _args)[0].item()\n",
    "        topicMapper = {}\n",
    "        \n",
    "        for o,n in zip(docs[1:],mapper): \n",
    "            topicMapper[o] = n \n",
    "        for i, v in enumerate(clusters):\n",
    "            try:\n",
    "                clusters[i]= topicMapper[v]\n",
    "            except: pass\n",
    "        return clusters\n",
    "    \n",
    "    def extract_topics(self, text):\n",
    "        txtpp = self.txtPreprocessing(text)\n",
    "        logging.info('end of text pre processing')\n",
    "        embeddings = self.txtEmbedding(txtpp)\n",
    "        logging.info('end of text embedding')\n",
    "        clusters = self.getClusers(embeddings)\n",
    "        nbrClusters = len(set(clusters))\n",
    "        logging.info(f'end of clustring : {nbrClusters}')\n",
    "        docs = self.groupBy(txtpp, clusters, nbrClusters)\n",
    "        topics = self.extract_topics_keywords(docs)\n",
    "        logging.info('end of key extra')\n",
    "        return topics, clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "9a807398",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/data/notebooks/others/french_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "e415098e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet('/data/big-data-collection/OTHERS/data_esg.parquet')\n",
    "data = data[['TITRE','CONTENU']]\n",
    "data[\"txt\"] = data['TITRE'] +\" \"+data['CONTENU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5065ca2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "newsgroups_train = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))\n",
    "text = newsgroups_train.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "25e0bdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWords = open('./stopwordEng', 'r').readlines()\n",
    "for i in range(len(stopWords)):\n",
    "    stopWords[i] = stopWords[i].replace('\\n', '').replace(' ', '')\n",
    "stopWords += list(set(stopWords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "5f9d77f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-28 14:47:03,025 - model init\n",
      "2022-07-28 14:47:06,725 - end of text pre processing\n",
      "2022-07-28 14:47:06,740 - collecting all words and their counts\n",
      "2022-07-28 14:47:06,741 - Each 'words' should be a list of words (usually unicode strings). First 'words' here is instead plain <class 'str'>.\n",
      "2022-07-28 14:47:06,741 - PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2022-07-28 14:47:07,534 - PROGRESS: at example #10000, processed 11130724 words (14055163 words/s), 76 word types, 0 tags\n",
      "2022-07-28 14:47:08,199 - collected 89 word types and 18846 unique tags from a corpus of 18846 examples and 20553241 words\n",
      "2022-07-28 14:47:08,200 - Creating a fresh vocabulary\n",
      "2022-07-28 14:47:08,201 - Doc2Vec lifecycle event {'msg': 'effective_min_count=1 retains 89 unique words (100.00% of original 89, drops 0)', 'datetime': '2022-07-28T14:47:08.201051', 'gensim': '4.2.0', 'python': '3.8.0 (default, Dec  9 2021, 17:53:27) \\n[GCC 8.4.0]', 'platform': 'Linux-5.4.0-1080-azure-x86_64-with-glibc2.27', 'event': 'prepare_vocab'}\n",
      "2022-07-28 14:47:08,201 - Doc2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 20553241 word corpus (100.00% of original 20553241, drops 0)', 'datetime': '2022-07-28T14:47:08.201427', 'gensim': '4.2.0', 'python': '3.8.0 (default, Dec  9 2021, 17:53:27) \\n[GCC 8.4.0]', 'platform': 'Linux-5.4.0-1080-azure-x86_64-with-glibc2.27', 'event': 'prepare_vocab'}\n",
      "2022-07-28 14:47:08,202 - deleting the raw counts dictionary of 89 items\n",
      "2022-07-28 14:47:08,202 - sample=1e-05 downsamples 63 most-common words\n",
      "2022-07-28 14:47:08,202 - Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 400771.56424705754 word corpus (1.9%% of prior 20553241)', 'datetime': '2022-07-28T14:47:08.202783', 'gensim': '4.2.0', 'python': '3.8.0 (default, Dec  9 2021, 17:53:27) \\n[GCC 8.4.0]', 'platform': 'Linux-5.4.0-1080-azure-x86_64-with-glibc2.27', 'event': 'prepare_vocab'}\n",
      "2022-07-28 14:47:08,203 - constructing a huffman tree from 89 words\n",
      "2022-07-28 14:47:08,205 - built huffman tree with maximum node depth 20\n",
      "2022-07-28 14:47:08,205 - estimated required memory for 89 words and 300 dimensions: 26660300 bytes\n",
      "2022-07-28 14:47:08,206 - resetting layer weights\n",
      "2022-07-28 14:47:08,225 - Doc2Vec lifecycle event {'msg': 'training model with 8 workers on 89 vocabulary and 300 features, using sg=1 hs=1 sample=1e-05 negative=0 window=15 shrink_windows=True', 'datetime': '2022-07-28T14:47:08.225117', 'gensim': '4.2.0', 'python': '3.8.0 (default, Dec  9 2021, 17:53:27) \\n[GCC 8.4.0]', 'platform': 'Linux-5.4.0-1080-azure-x86_64-with-glibc2.27', 'event': 'train'}\n",
      "2022-07-28 14:47:09,231 - EPOCH 0 - PROGRESS: at 31.30% examples, 138403 words/s, in_qsize 16, out_qsize 0\n",
      "2022-07-28 14:47:10,234 - EPOCH 0 - PROGRESS: at 64.89% examples, 136526 words/s, in_qsize 16, out_qsize 2\n",
      "2022-07-28 14:47:11,236 - EPOCH 0 - PROGRESS: at 98.29% examples, 136586 words/s, in_qsize 16, out_qsize 1\n",
      "2022-07-28 14:47:11,271 - EPOCH 0: training on 20553241 raw words (418973 effective words) took 3.0s, 137698 effective words/s\n",
      "2022-07-28 14:47:12,273 - EPOCH 1 - PROGRESS: at 31.07% examples, 138157 words/s, in_qsize 16, out_qsize 0\n",
      "2022-07-28 14:47:13,275 - EPOCH 1 - PROGRESS: at 63.61% examples, 135231 words/s, in_qsize 15, out_qsize 0\n",
      "2022-07-28 14:47:14,276 - EPOCH 1 - PROGRESS: at 98.18% examples, 137021 words/s, in_qsize 15, out_qsize 0\n",
      "2022-07-28 14:47:14,320 - EPOCH 1: training on 20553241 raw words (420008 effective words) took 3.0s, 137848 effective words/s\n",
      "2022-07-28 14:47:15,323 - EPOCH 2 - PROGRESS: at 31.87% examples, 141224 words/s, in_qsize 13, out_qsize 2\n",
      "2022-07-28 14:47:16,324 - EPOCH 2 - PROGRESS: at 65.52% examples, 140418 words/s, in_qsize 16, out_qsize 0\n",
      "2022-07-28 14:47:17,326 - EPOCH 2 - PROGRESS: at 98.90% examples, 137738 words/s, in_qsize 16, out_qsize 0\n",
      "2022-07-28 14:47:17,350 - EPOCH 2: training on 20553241 raw words (420104 effective words) took 3.0s, 138794 effective words/s\n",
      "2022-07-28 14:47:18,358 - EPOCH 3 - PROGRESS: at 31.12% examples, 136969 words/s, in_qsize 14, out_qsize 1\n",
      "2022-07-28 14:47:19,360 - EPOCH 3 - PROGRESS: at 64.55% examples, 136069 words/s, in_qsize 15, out_qsize 0\n",
      "2022-07-28 14:47:20,360 - EPOCH 3 - PROGRESS: at 98.15% examples, 136459 words/s, in_qsize 15, out_qsize 0\n",
      "2022-07-28 14:47:20,401 - EPOCH 3: training on 20553241 raw words (418722 effective words) took 3.0s, 137414 effective words/s\n",
      "2022-07-28 14:47:21,404 - EPOCH 4 - PROGRESS: at 31.33% examples, 138253 words/s, in_qsize 16, out_qsize 1\n",
      "2022-07-28 14:47:22,405 - EPOCH 4 - PROGRESS: at 64.98% examples, 137141 words/s, in_qsize 15, out_qsize 0\n",
      "2022-07-28 14:47:23,406 - EPOCH 4 - PROGRESS: at 98.68% examples, 137407 words/s, in_qsize 14, out_qsize 1\n",
      "2022-07-28 14:47:23,434 - EPOCH 4: training on 20553241 raw words (419708 effective words) took 3.0s, 138474 effective words/s\n",
      "2022-07-28 14:47:24,439 - EPOCH 5 - PROGRESS: at 31.72% examples, 140803 words/s, in_qsize 15, out_qsize 3\n",
      "2022-07-28 14:47:25,441 - EPOCH 5 - PROGRESS: at 66.09% examples, 141737 words/s, in_qsize 15, out_qsize 1\n",
      "2022-07-28 14:47:26,432 - EPOCH 5: training on 20553241 raw words (419688 effective words) took 3.0s, 140192 effective words/s\n",
      "2022-07-28 14:47:27,440 - EPOCH 6 - PROGRESS: at 31.10% examples, 137122 words/s, in_qsize 16, out_qsize 0\n",
      "2022-07-28 14:47:28,444 - EPOCH 6 - PROGRESS: at 65.52% examples, 139879 words/s, in_qsize 14, out_qsize 2\n",
      "2022-07-28 14:47:29,428 - EPOCH 6: training on 20553241 raw words (418989 effective words) took 3.0s, 140049 effective words/s\n",
      "2022-07-28 14:47:30,432 - EPOCH 7 - PROGRESS: at 31.87% examples, 140495 words/s, in_qsize 15, out_qsize 0\n",
      "2022-07-28 14:47:31,432 - EPOCH 7 - PROGRESS: at 66.40% examples, 141577 words/s, in_qsize 15, out_qsize 0\n",
      "2022-07-28 14:47:32,383 - EPOCH 7: training on 20553241 raw words (418776 effective words) took 3.0s, 141893 effective words/s\n",
      "2022-07-28 14:47:33,386 - EPOCH 8 - PROGRESS: at 31.51% examples, 139731 words/s, in_qsize 16, out_qsize 2\n",
      "2022-07-28 14:47:34,388 - EPOCH 8 - PROGRESS: at 65.56% examples, 140623 words/s, in_qsize 16, out_qsize 3\n",
      "2022-07-28 14:47:35,379 - EPOCH 8: training on 20553241 raw words (420075 effective words) took 3.0s, 140320 effective words/s\n",
      "2022-07-28 14:47:36,383 - EPOCH 9 - PROGRESS: at 31.66% examples, 139039 words/s, in_qsize 16, out_qsize 0\n",
      "2022-07-28 14:47:37,386 - EPOCH 9 - PROGRESS: at 66.19% examples, 141093 words/s, in_qsize 15, out_qsize 3\n",
      "2022-07-28 14:47:38,368 - EPOCH 9: training on 20553241 raw words (418646 effective words) took 3.0s, 140221 effective words/s\n",
      "2022-07-28 14:47:39,371 - EPOCH 10 - PROGRESS: at 31.32% examples, 138331 words/s, in_qsize 15, out_qsize 0\n",
      "2022-07-28 14:47:40,374 - EPOCH 10 - PROGRESS: at 65.64% examples, 140337 words/s, in_qsize 16, out_qsize 1\n",
      "2022-07-28 14:47:41,374 - EPOCH 10 - PROGRESS: at 99.55% examples, 139206 words/s, in_qsize 6, out_qsize 1\n",
      "2022-07-28 14:47:41,378 - EPOCH 10: training on 20553241 raw words (419064 effective words) took 3.0s, 139354 effective words/s\n",
      "2022-07-28 14:47:42,384 - EPOCH 11 - PROGRESS: at 31.60% examples, 139921 words/s, in_qsize 16, out_qsize 0\n",
      "2022-07-28 14:47:43,384 - EPOCH 11 - PROGRESS: at 66.31% examples, 141886 words/s, in_qsize 16, out_qsize 0\n",
      "2022-07-28 14:47:44,350 - EPOCH 11: training on 20553241 raw words (419616 effective words) took 3.0s, 141408 effective words/s\n",
      "2022-07-28 14:47:45,356 - EPOCH 12 - PROGRESS: at 31.07% examples, 137567 words/s, in_qsize 16, out_qsize 0\n",
      "2022-07-28 14:47:46,357 - EPOCH 12 - PROGRESS: at 64.93% examples, 136940 words/s, in_qsize 16, out_qsize 0\n",
      "2022-07-28 14:47:47,357 - EPOCH 12 - PROGRESS: at 99.74% examples, 139379 words/s, in_qsize 4, out_qsize 1\n",
      "2022-07-28 14:47:47,360 - EPOCH 12: training on 20553241 raw words (419374 effective words) took 3.0s, 139469 effective words/s\n",
      "2022-07-28 14:47:48,364 - EPOCH 13 - PROGRESS: at 31.67% examples, 140047 words/s, in_qsize 16, out_qsize 0\n",
      "2022-07-28 14:47:49,366 - EPOCH 13 - PROGRESS: at 64.86% examples, 136685 words/s, in_qsize 15, out_qsize 0\n",
      "2022-07-28 14:47:50,368 - EPOCH 13 - PROGRESS: at 98.16% examples, 136622 words/s, in_qsize 15, out_qsize 0\n",
      "2022-07-28 14:47:50,406 - EPOCH 13: training on 20553241 raw words (418815 effective words) took 3.0s, 137680 effective words/s\n",
      "2022-07-28 14:47:51,409 - EPOCH 14 - PROGRESS: at 31.71% examples, 139532 words/s, in_qsize 13, out_qsize 0\n",
      "2022-07-28 14:47:52,409 - EPOCH 14 - PROGRESS: at 65.35% examples, 140310 words/s, in_qsize 15, out_qsize 0\n",
      "2022-07-28 14:47:53,389 - EPOCH 14: training on 20553241 raw words (420270 effective words) took 3.0s, 141014 effective words/s\n",
      "2022-07-28 14:47:54,392 - EPOCH 15 - PROGRESS: at 31.30% examples, 138449 words/s, in_qsize 16, out_qsize 0\n",
      "2022-07-28 14:47:55,394 - EPOCH 15 - PROGRESS: at 64.78% examples, 136959 words/s, in_qsize 16, out_qsize 1\n",
      "2022-07-28 14:47:56,396 - EPOCH 15 - PROGRESS: at 99.09% examples, 137708 words/s, in_qsize 16, out_qsize 0\n",
      "2022-07-28 14:47:56,415 - EPOCH 15: training on 20553241 raw words (419875 effective words) took 3.0s, 138854 effective words/s\n",
      "2022-07-28 14:47:57,419 - EPOCH 16 - PROGRESS: at 31.60% examples, 139557 words/s, in_qsize 15, out_qsize 0\n",
      "2022-07-28 14:47:58,420 - EPOCH 16 - PROGRESS: at 64.46% examples, 136342 words/s, in_qsize 15, out_qsize 0\n",
      "2022-07-28 14:47:59,420 - EPOCH 16 - PROGRESS: at 98.16% examples, 136979 words/s, in_qsize 16, out_qsize 1\n",
      "2022-07-28 14:47:59,457 - EPOCH 16: training on 20553241 raw words (419646 effective words) took 3.0s, 138097 effective words/s\n",
      "2022-07-28 14:48:00,462 - EPOCH 17 - PROGRESS: at 32.03% examples, 141752 words/s, in_qsize 15, out_qsize 0\n",
      "2022-07-28 14:48:01,462 - EPOCH 17 - PROGRESS: at 66.85% examples, 142527 words/s, in_qsize 16, out_qsize 0\n",
      "2022-07-28 14:48:02,417 - EPOCH 17: training on 20553241 raw words (419453 effective words) took 3.0s, 141875 effective words/s\n",
      "2022-07-28 14:48:03,420 - EPOCH 18 - PROGRESS: at 31.31% examples, 138537 words/s, in_qsize 14, out_qsize 4\n",
      "2022-07-28 14:48:04,421 - EPOCH 18 - PROGRESS: at 65.14% examples, 137224 words/s, in_qsize 16, out_qsize 0\n",
      "2022-07-28 14:48:05,421 - EPOCH 18 - PROGRESS: at 99.27% examples, 137698 words/s, in_qsize 14, out_qsize 0\n",
      "2022-07-28 14:48:05,440 - EPOCH 18: training on 20553241 raw words (418827 effective words) took 3.0s, 138679 effective words/s\n",
      "2022-07-28 14:48:06,448 - EPOCH 19 - PROGRESS: at 31.97% examples, 140955 words/s, in_qsize 15, out_qsize 0\n",
      "2022-07-28 14:48:07,450 - EPOCH 19 - PROGRESS: at 65.50% examples, 138465 words/s, in_qsize 16, out_qsize 2\n",
      "2022-07-28 14:48:08,451 - EPOCH 19 - PROGRESS: at 99.54% examples, 139137 words/s, in_qsize 7, out_qsize 2\n",
      "2022-07-28 14:48:08,457 - EPOCH 19: training on 20553241 raw words (419483 effective words) took 3.0s, 139257 effective words/s\n",
      "2022-07-28 14:48:09,460 - EPOCH 20 - PROGRESS: at 31.52% examples, 139044 words/s, in_qsize 16, out_qsize 0\n",
      "2022-07-28 14:48:10,461 - EPOCH 20 - PROGRESS: at 66.13% examples, 140958 words/s, in_qsize 16, out_qsize 0\n",
      "2022-07-28 14:48:11,422 - EPOCH 20: training on 20553241 raw words (418500 effective words) took 3.0s, 141281 effective words/s\n",
      "2022-07-28 14:48:12,426 - EPOCH 21 - PROGRESS: at 31.73% examples, 140662 words/s, in_qsize 16, out_qsize 1\n",
      "2022-07-28 14:48:13,427 - EPOCH 21 - PROGRESS: at 66.29% examples, 141677 words/s, in_qsize 16, out_qsize 0\n",
      "2022-07-28 14:48:14,396 - EPOCH 21: training on 20553241 raw words (419272 effective words) took 3.0s, 141098 effective words/s\n",
      "2022-07-28 14:48:15,400 - EPOCH 22 - PROGRESS: at 32.90% examples, 144871 words/s, in_qsize 14, out_qsize 1\n",
      "2022-07-28 14:48:16,401 - EPOCH 22 - PROGRESS: at 66.79% examples, 142355 words/s, in_qsize 14, out_qsize 1\n",
      "2022-07-28 14:48:17,349 - EPOCH 22: training on 20553241 raw words (419552 effective words) took 2.9s, 142251 effective words/s\n",
      "2022-07-28 14:48:18,353 - EPOCH 23 - PROGRESS: at 31.66% examples, 139335 words/s, in_qsize 15, out_qsize 0\n",
      "2022-07-28 14:48:19,353 - EPOCH 23 - PROGRESS: at 65.14% examples, 137048 words/s, in_qsize 14, out_qsize 0\n",
      "2022-07-28 14:48:20,351 - EPOCH 23: training on 20553241 raw words (419784 effective words) took 3.0s, 139965 effective words/s\n",
      "2022-07-28 14:48:21,354 - EPOCH 24 - PROGRESS: at 31.56% examples, 139759 words/s, in_qsize 15, out_qsize 0\n",
      "2022-07-28 14:48:22,355 - EPOCH 24 - PROGRESS: at 65.19% examples, 137813 words/s, in_qsize 15, out_qsize 1\n",
      "2022-07-28 14:48:23,347 - EPOCH 24: training on 20553241 raw words (420104 effective words) took 3.0s, 140362 effective words/s\n",
      "2022-07-28 14:48:24,349 - EPOCH 25 - PROGRESS: at 31.41% examples, 138925 words/s, in_qsize 15, out_qsize 0\n",
      "2022-07-28 14:48:25,350 - EPOCH 25 - PROGRESS: at 64.97% examples, 137117 words/s, in_qsize 13, out_qsize 1\n",
      "2022-07-28 14:48:26,350 - EPOCH 25 - PROGRESS: at 99.64% examples, 139574 words/s, in_qsize 4, out_qsize 3\n",
      "2022-07-28 14:48:26,352 - EPOCH 25: training on 20553241 raw words (419723 effective words) took 3.0s, 139748 effective words/s\n",
      "2022-07-28 14:48:27,356 - EPOCH 26 - PROGRESS: at 32.29% examples, 142603 words/s, in_qsize 15, out_qsize 0\n",
      "2022-07-28 14:48:28,362 - EPOCH 26 - PROGRESS: at 66.77% examples, 142232 words/s, in_qsize 14, out_qsize 1\n",
      "2022-07-28 14:48:29,318 - EPOCH 26: training on 20553241 raw words (419248 effective words) took 3.0s, 141550 effective words/s\n",
      "2022-07-28 14:48:30,321 - EPOCH 27 - PROGRESS: at 31.22% examples, 137870 words/s, in_qsize 16, out_qsize 1\n",
      "2022-07-28 14:48:31,321 - EPOCH 27 - PROGRESS: at 65.78% examples, 140657 words/s, in_qsize 16, out_qsize 0\n",
      "2022-07-28 14:48:32,290 - EPOCH 27: training on 20553241 raw words (419102 effective words) took 3.0s, 141149 effective words/s\n",
      "2022-07-28 14:48:33,296 - EPOCH 28 - PROGRESS: at 32.03% examples, 141668 words/s, in_qsize 13, out_qsize 1\n",
      "2022-07-28 14:48:34,298 - EPOCH 28 - PROGRESS: at 65.99% examples, 141202 words/s, in_qsize 15, out_qsize 0\n",
      "2022-07-28 14:48:35,300 - EPOCH 28 - PROGRESS: at 99.61% examples, 139347 words/s, in_qsize 6, out_qsize 1\n",
      "2022-07-28 14:48:35,303 - EPOCH 28: training on 20553241 raw words (419743 effective words) took 3.0s, 139523 effective words/s\n",
      "2022-07-28 14:48:36,306 - EPOCH 29 - PROGRESS: at 31.73% examples, 140378 words/s, in_qsize 15, out_qsize 0\n",
      "2022-07-28 14:48:37,307 - EPOCH 29 - PROGRESS: at 65.14% examples, 137102 words/s, in_qsize 16, out_qsize 0\n",
      "2022-07-28 14:48:38,305 - EPOCH 29: training on 20553241 raw words (418998 effective words) took 3.0s, 139673 effective words/s\n",
      "2022-07-28 14:48:39,309 - EPOCH 30 - PROGRESS: at 32.14% examples, 141663 words/s, in_qsize 14, out_qsize 1\n",
      "2022-07-28 14:48:40,313 - EPOCH 30 - PROGRESS: at 66.28% examples, 141612 words/s, in_qsize 15, out_qsize 1\n",
      "2022-07-28 14:48:41,259 - EPOCH 30: training on 20553241 raw words (419640 effective words) took 3.0s, 142192 effective words/s\n",
      "2022-07-28 14:48:42,263 - EPOCH 31 - PROGRESS: at 31.61% examples, 139402 words/s, in_qsize 15, out_qsize 0\n",
      "2022-07-28 14:48:43,264 - EPOCH 31 - PROGRESS: at 66.22% examples, 141661 words/s, in_qsize 15, out_qsize 1\n",
      "2022-07-28 14:48:44,207 - EPOCH 31: training on 20553241 raw words (419950 effective words) took 2.9s, 142645 effective words/s\n",
      "2022-07-28 14:48:45,211 - EPOCH 32 - PROGRESS: at 32.50% examples, 143081 words/s, in_qsize 15, out_qsize 0\n",
      "2022-07-28 14:48:46,214 - EPOCH 32 - PROGRESS: at 67.73% examples, 143952 words/s, in_qsize 16, out_qsize 0\n",
      "2022-07-28 14:48:47,141 - EPOCH 32: training on 20553241 raw words (420003 effective words) took 2.9s, 143233 effective words/s\n",
      "2022-07-28 14:48:48,149 - EPOCH 33 - PROGRESS: at 31.52% examples, 138253 words/s, in_qsize 15, out_qsize 0\n",
      "2022-07-28 14:48:49,150 - EPOCH 33 - PROGRESS: at 64.87% examples, 136478 words/s, in_qsize 14, out_qsize 2\n",
      "2022-07-28 14:48:50,151 - EPOCH 33 - PROGRESS: at 99.36% examples, 138759 words/s, in_qsize 10, out_qsize 0\n",
      "2022-07-28 14:48:50,160 - EPOCH 33: training on 20553241 raw words (418728 effective words) took 3.0s, 138858 effective words/s\n",
      "2022-07-28 14:48:51,165 - EPOCH 34 - PROGRESS: at 32.23% examples, 142019 words/s, in_qsize 16, out_qsize 0\n",
      "2022-07-28 14:48:52,166 - EPOCH 34 - PROGRESS: at 65.52% examples, 139428 words/s, in_qsize 16, out_qsize 0\n",
      "2022-07-28 14:48:53,152 - EPOCH 34: training on 20553241 raw words (419526 effective words) took 3.0s, 140395 effective words/s\n",
      "2022-07-28 14:48:54,156 - EPOCH 35 - PROGRESS: at 32.55% examples, 142681 words/s, in_qsize 16, out_qsize 2\n",
      "2022-07-28 14:48:55,157 - EPOCH 35 - PROGRESS: at 66.00% examples, 140643 words/s, in_qsize 16, out_qsize 2\n",
      "2022-07-28 14:48:56,149 - EPOCH 35: training on 20553241 raw words (418438 effective words) took 3.0s, 139760 effective words/s\n",
      "2022-07-28 14:48:57,152 - EPOCH 36 - PROGRESS: at 30.99% examples, 137347 words/s, in_qsize 15, out_qsize 1\n",
      "2022-07-28 14:48:58,155 - EPOCH 36 - PROGRESS: at 64.82% examples, 137132 words/s, in_qsize 16, out_qsize 0\n",
      "2022-07-28 14:48:59,157 - EPOCH 36 - PROGRESS: at 99.27% examples, 137912 words/s, in_qsize 14, out_qsize 0\n",
      "2022-07-28 14:48:59,171 - EPOCH 36: training on 20553241 raw words (419919 effective words) took 3.0s, 139087 effective words/s\n",
      "2022-07-28 14:49:00,177 - EPOCH 37 - PROGRESS: at 32.09% examples, 141652 words/s, in_qsize 16, out_qsize 0\n",
      "2022-07-28 14:49:01,178 - EPOCH 37 - PROGRESS: at 65.99% examples, 140741 words/s, in_qsize 16, out_qsize 3\n",
      "2022-07-28 14:49:02,157 - EPOCH 37: training on 20553241 raw words (419253 effective words) took 3.0s, 140571 effective words/s\n",
      "2022-07-28 14:49:03,160 - EPOCH 38 - PROGRESS: at 32.30% examples, 142639 words/s, in_qsize 16, out_qsize 1\n",
      "2022-07-28 14:49:04,163 - EPOCH 38 - PROGRESS: at 66.44% examples, 141833 words/s, in_qsize 15, out_qsize 0\n",
      "2022-07-28 14:49:05,163 - EPOCH 38 - PROGRESS: at 99.28% examples, 138589 words/s, in_qsize 13, out_qsize 0\n",
      "2022-07-28 14:49:05,174 - EPOCH 38: training on 20553241 raw words (418915 effective words) took 3.0s, 138959 effective words/s\n",
      "2022-07-28 14:49:06,182 - EPOCH 39 - PROGRESS: at 32.02% examples, 140996 words/s, in_qsize 14, out_qsize 1\n",
      "2022-07-28 14:49:07,184 - EPOCH 39 - PROGRESS: at 66.51% examples, 141403 words/s, in_qsize 14, out_qsize 1\n",
      "2022-07-28 14:49:08,167 - EPOCH 39: training on 20553241 raw words (419462 effective words) took 3.0s, 140285 effective words/s\n",
      "2022-07-28 14:49:09,174 - EPOCH 40 - PROGRESS: at 31.61% examples, 139560 words/s, in_qsize 16, out_qsize 0\n",
      "2022-07-28 14:49:10,174 - EPOCH 40 - PROGRESS: at 65.14% examples, 137426 words/s, in_qsize 16, out_qsize 0\n",
      "2022-07-28 14:49:11,176 - EPOCH 40 - PROGRESS: at 98.23% examples, 137184 words/s, in_qsize 15, out_qsize 0\n",
      "2022-07-28 14:49:11,211 - EPOCH 40: training on 20553241 raw words (420458 effective words) took 3.0s, 138274 effective words/s\n",
      "2022-07-28 14:49:12,216 - EPOCH 41 - PROGRESS: at 31.10% examples, 137454 words/s, in_qsize 15, out_qsize 0\n",
      "2022-07-28 14:49:13,217 - EPOCH 41 - PROGRESS: at 65.23% examples, 137199 words/s, in_qsize 15, out_qsize 0\n",
      "2022-07-28 14:49:14,219 - EPOCH 41 - PROGRESS: at 99.28% examples, 138799 words/s, in_qsize 12, out_qsize 0\n",
      "2022-07-28 14:49:14,230 - EPOCH 41: training on 20553241 raw words (419059 effective words) took 3.0s, 138922 effective words/s\n",
      "2022-07-28 14:49:15,239 - EPOCH 42 - PROGRESS: at 31.22% examples, 137719 words/s, in_qsize 13, out_qsize 3\n",
      "2022-07-28 14:49:16,241 - EPOCH 42 - PROGRESS: at 66.16% examples, 141701 words/s, in_qsize 16, out_qsize 1\n",
      "2022-07-28 14:49:17,218 - EPOCH 42: training on 20553241 raw words (421131 effective words) took 3.0s, 141134 effective words/s\n",
      "2022-07-28 14:49:18,223 - EPOCH 43 - PROGRESS: at 31.83% examples, 141054 words/s, in_qsize 15, out_qsize 0\n",
      "2022-07-28 14:49:19,224 - EPOCH 43 - PROGRESS: at 65.79% examples, 140902 words/s, in_qsize 16, out_qsize 1\n",
      "2022-07-28 14:49:20,225 - EPOCH 43 - PROGRESS: at 99.83% examples, 139569 words/s, in_qsize 2, out_qsize 1\n",
      "2022-07-28 14:49:20,226 - EPOCH 43: training on 20553241 raw words (419517 effective words) took 3.0s, 139643 effective words/s\n",
      "2022-07-28 14:49:21,229 - EPOCH 44 - PROGRESS: at 31.88% examples, 141175 words/s, in_qsize 16, out_qsize 0\n",
      "2022-07-28 14:49:22,231 - EPOCH 44 - PROGRESS: at 65.72% examples, 138349 words/s, in_qsize 15, out_qsize 0\n",
      "2022-07-28 14:49:23,212 - EPOCH 44: training on 20553241 raw words (419708 effective words) took 3.0s, 140650 effective words/s\n",
      "2022-07-28 14:49:24,216 - EPOCH 45 - PROGRESS: at 32.54% examples, 142884 words/s, in_qsize 16, out_qsize 0\n",
      "2022-07-28 14:49:25,217 - EPOCH 45 - PROGRESS: at 66.51% examples, 142149 words/s, in_qsize 13, out_qsize 3\n",
      "2022-07-28 14:49:26,191 - EPOCH 45: training on 20553241 raw words (419155 effective words) took 3.0s, 140864 effective words/s\n",
      "2022-07-28 14:49:27,195 - EPOCH 46 - PROGRESS: at 31.83% examples, 141032 words/s, in_qsize 16, out_qsize 1\n",
      "2022-07-28 14:49:28,196 - EPOCH 46 - PROGRESS: at 64.69% examples, 136934 words/s, in_qsize 16, out_qsize 0\n",
      "2022-07-28 14:49:29,199 - EPOCH 46 - PROGRESS: at 99.01% examples, 137656 words/s, in_qsize 15, out_qsize 0\n",
      "2022-07-28 14:49:29,219 - EPOCH 46: training on 20553241 raw words (419813 effective words) took 3.0s, 138822 effective words/s\n",
      "2022-07-28 14:49:30,224 - EPOCH 47 - PROGRESS: at 31.88% examples, 141316 words/s, in_qsize 16, out_qsize 2\n",
      "2022-07-28 14:49:31,224 - EPOCH 47 - PROGRESS: at 66.22% examples, 141791 words/s, in_qsize 13, out_qsize 1\n",
      "2022-07-28 14:49:32,189 - EPOCH 47: training on 20553241 raw words (420151 effective words) took 3.0s, 141634 effective words/s\n",
      "2022-07-28 14:49:33,194 - EPOCH 48 - PROGRESS: at 32.24% examples, 142140 words/s, in_qsize 16, out_qsize 1\n",
      "2022-07-28 14:49:34,198 - EPOCH 48 - PROGRESS: at 66.92% examples, 142219 words/s, in_qsize 15, out_qsize 2\n",
      "2022-07-28 14:49:35,132 - EPOCH 48: training on 20553241 raw words (419149 effective words) took 2.9s, 142641 effective words/s\n",
      "2022-07-28 14:49:36,136 - EPOCH 49 - PROGRESS: at 31.87% examples, 141550 words/s, in_qsize 15, out_qsize 1\n",
      "2022-07-28 14:49:37,137 - EPOCH 49 - PROGRESS: at 66.37% examples, 142150 words/s, in_qsize 14, out_qsize 2\n",
      "2022-07-28 14:49:38,101 - EPOCH 49: training on 20553241 raw words (420269 effective words) took 3.0s, 141656 effective words/s\n",
      "2022-07-28 14:49:38,102 - Doc2Vec lifecycle event {'msg': 'training on 1027662050 raw words (20974382 effective words) took 149.9s, 139944 effective words/s', 'datetime': '2022-07-28T14:49:38.102646', 'gensim': '4.2.0', 'python': '3.8.0 (default, Dec  9 2021, 17:53:27) \\n[GCC 8.4.0]', 'platform': 'Linux-5.4.0-1080-azure-x86_64-with-glibc2.27', 'event': 'train'}\n",
      "2022-07-28 14:49:38,103 - Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow+w,d300,hs,w15,s1e-05,t8>', 'datetime': '2022-07-28T14:49:38.103096', 'gensim': '4.2.0', 'python': '3.8.0 (default, Dec  9 2021, 17:53:27) \\n[GCC 8.4.0]', 'platform': 'Linux-5.4.0-1080-azure-x86_64-with-glibc2.27', 'event': 'created'}\n",
      "2022-07-28 14:49:38,115 - end of text embedding\n",
      "2022-07-28 14:49:51,469 - end of clustring : 84\n",
      "2022-07-28 14:52:51,036 - end of key extra\n"
     ]
    }
   ],
   "source": [
    "topicModel = TopicsExtractor(top=30, stopwords=stopWords)\n",
    "out = topicModel.extract_topics(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "fd0b6d11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{-1: 'people time god government file space program windows armenian data law key question read drive list power day car set disk jesus send hard university email support word called public',\n",
       " 0: 'max bhj giz scx bxn okz air rlk fij fyn qax ahf kjz ghj gcx nrhj biz wwiz uww qtm mcx mtm sqs khf syx nuy vmk ajz xte rck',\n",
       " 1: 'people homosexual god true evidence belief time theism moral claim bible reason gay read argument lot sexual statement jesus question children force wrong issue support church person subject university agree',\n",
       " 2: 'hitler dollars nazis government chancellor time party avs games parties people german mission motif power support constitution coalition esd conductive increase manager reichstag democratic hindenburg national lost software jesus drive',\n",
       " 3: 'file image program jpeg people dos version time data software pub graphics server ftp format window output display subject stephanopoulos set president entry source package space support color code gif',\n",
       " 4: 'cosy pak file mathematica wsh directory chi nyr notebooks det tor packages nyi edm bos van mtl lib min control pit buf phi hfd wpg brian steve cgy stl ibm',\n",
       " 5: 'gopher search client pub database software pntr sele internet geom ftp data pty public dos local veronica colormaps windows people unix e-mail standard max retrieve delt red list card mult',\n",
       " 6: 'tyre god time neck colormap book catalog pressure mustang massager standard days window reading sound car return situation government people cities products law set tension muscles base physical thumbs flashing',\n",
       " 7: 'win.win main mydisplay music children event deaf panel tesla lives win.text win mask mac lost key car flags nature read time provide hard money chip widget set windows files receives',\n",
       " 8: 'god ndet loop.c people time include university error question court lib cement program property boomer data function read doug type answer usr parse atlantic conference set day claim price life',\n",
       " 9: 'image author design times title norton note gun pistol police journal article criminal disk variational fired routines god hard kimura error clip modeling editor booktitle inproceedings program rsa read geometry',\n",
       " 10: 'people president myers armenians time god dod russian told started administration day children apartment question stephanopoulos official azerbaijani government car left senior sumgait soldiers list house dee program building book',\n",
       " 11: 'people time god government law human key jesus question power president son insurance center game dog station chip space israel support clipper day team evidence fbi reason life real children',\n",
       " 12: 'echo keymap string lib hostname file xterm windows set tmp undefined symbol xmu message libxmu.a shift people error time hope translation bytes algorithm bob stay application message-digest email head read',\n",
       " 13: 'motif borland guide bindings jagr time gas tear people francis list release support software e-mail windows seat user library turbo ftp dog reference dos mailing-list utilities teleuse sort cars game',\n",
       " 14: 'time display istanbul window graphic title god mary ankara people university light engine turkey power bible bit running osmanli ermeni server true book seat colors access belief credit input conception',\n",
       " 15: 'den radius luminosity double theta sqrt green blue struct red define muslim hue printf sin subdivide tri wave break nation saturation include jle pole cos hsl float output program war',\n",
       " 16: 'files windows midi events application server bike play bit button openwindows card set patch soundblaster armenians user bmp miles understand fundamentalists ticket client irritating mis-labels kill capture accelerated mouse sunos',\n",
       " 17: 'drive master slave jumper card time bus disk data space standard single ide led center mode mouse pin program nasa interface heads port set people read email version mac power',\n",
       " 18: 'chip windows media people time xterm-map define-key tax disk keys network serial program clipper team car turkey magnetic send pretty national start local read list file security processor dos package',\n",
       " 19: 'vue display vizquel mind israel bit drive images wrong ball gateway rangers cough note zeos colored root stuff helmet rocket size brad e-mail mentioned video months final throw watched riles',\n",
       " 20: 'people time god word person love sin christian government israel life question hate bad feel food book matter police read day lot key americans argument live answer reason country issue',\n",
       " 21: 'april apple shipping drive original usa 20:00 time machine modem germany sale ibm obo national czech republic 15:30 manuals sweden norway finland canada russia italy switzerland france austria email disks',\n",
       " 22: 'company bike post dave larry margolis passed word mail months rape body easter people meaning ide isa improper violation cruel apr wibbled lotus edmondson elan sell practices time address dod',\n",
       " 23: 'time file dog modem lot people god board windows ppi bike post harddisk feel program bitmaps product local read version remember stuff idea crime books doctor moral transfer slow standard',\n",
       " 24: 'people time god question government read post game true reason lot idea key evidence day bit law fbi team real program wrong claim word remember bible church christian jesus book',\n",
       " 25: 'drive space games time card software april copies season people windows armenian sale wolverine box email speed price scsi list team chip hard shipping mac bit annual machine meg serial',\n",
       " 26: 'program power markus windows file disk drive day turkey corn idea games card word read commercial options megs supply helmet people software swap bike server gif motherboard chip bus question',\n",
       " 27: 'windows drive data card time software sale price power offer modem people board dos version program average mac port input chip email pin speed memory file condition control games john',\n",
       " 28: 'card lost april mac display windows program color duo armenian 20:00 type fast drivers esdi modem idle 15:30 set send germany disk usa york graphics 01-02 bus fax data software',\n",
       " 29: 'list sale windows manual color drive card tomlin period monitor board shots shipping current offer dos book cal leads version email roberts grammar true saves series red bit unix hulk',\n",
       " 30: 'card drive time sell vlb noise software miles white aviation application bit cache bike muslims file memory mode moscow board magellan cdtv rally monitor running colour resources people original weeks',\n",
       " 31: 'dos art copies wolverine mpc cover annual hulk rider comics ghost shots period card punisher hobgoblin sabretooth saves time price issue power space print liefeld pts bagged station wings spider-man',\n",
       " 32: 'star trek jews fan hawks time israel bus dune vlb studies reader book conspiracy henry ethnic community reminded palestine change post macintosh beat advance mastering motherboard solo han offer report',\n",
       " 33: 'windows drive car game space time conference pub john mac price software program version team email video series sale fax file monitor astronomy university model disks send set cover condition',\n",
       " 34: 'drive windows time monitor people mouse food adaptor scsi question east person source vga john deleted alarm board dye intersection viper engine draw package language mode note delorean appreciated bit',\n",
       " 35: 'armenians colors extra drive card defensive university residence version population miles port bit muslim ram video domicile time board window battalions average package price software hits graphics total nasa nazi',\n",
       " 36: 'cold des study bit file yogurt max hfe application driver colour fingers viruses windows killed vce story seconds.it children lone gunman fired bullets space catch nose based easier encryptions fast',\n",
       " 37: 'people god time son game government religion law question bullets read control gun person power evidence claim hard daughter bayonet david weapons muslims day killed lot weaver armenians wrong team',\n",
       " 38: 'people god question time christians light sin israel ellipse law white outline graphics matter hate car read software paul true key war arabs polygons address government mary offset lot support',\n",
       " 39: 'people time israel government team players coming start change deal helmet pretty batteries real dead game read hope key season cox bits lopez local person koresh guess energy lebanese soldiers',\n",
       " 40: 'people time life bit book read candida registration god truth real cult short nice ntsc patients fatty acids rock govt accept apple physician voter reason treatment house claim light muslims',\n",
       " 41: 'flyers time games modem scsi drive play ibm card idle fonts files motif lost send windows condition cost dec short type day pre power reds port bunning interface printer team',\n",
       " 42: 'drive phigs list game scsi software windows price win time email machine power sale dos usa data ram support ibm june car version hard set unix supply speed chip disk',\n",
       " 43: 'drives list people time windows jacket bible send pretty sony optical mds flopticals local memory coptic question angels etc. cold freon include aerostich brakes sounds files couple cost bit floppy',\n",
       " 44: 'planes article leave israel wrong statement frame armenia getgeometry relative azerbadjan translatecoordinates window upperleft corner search weapons announced syrians resistance movements posted lebanese time adam zionism racism mcgill bombing germany',\n",
       " 45: 'team splitfires network card twins torque morris read placebo clemens btw people e-mail vaseline normal behavior newsie followup accepted increased performance power drug effective pill common prescription guy manny lee',\n",
       " 46: 'god time win drive power pit det mon car tor van buf chi bos condition cal stl period philadelphia windows sale play file nyi price bit lost life people shipping',\n",
       " 47: 'people time militia god christians life jesus question government authority human day sort argument simply serbs hand claim idea couple law john mind federal person plane team evidence war master',\n",
       " 48: 'people evidence idea files subject turk bike keyboard post bad team lot homosexuals apple time heard rus anecdotal power body arsenokoitai term format article original running yugoslavia wrong real god',\n",
       " 49: 'drive simms april monitor card windows time degrees data wide sale lost email wsh ram screen address memory van chi nyr phone running fax bos det tor nyi mtl edm',\n",
       " 50: 'card box drive dram price cost lens monitor unknown offer sale shipping scsi ppd membership condition disk software siggraph model games graphics controller list edition brand stuff simms meg jefferson',\n",
       " 51: 'card monitor bit vram color god rev gao program sell mail price power question amiga scsi time sin left simms report quadra mac slot adapter alomar serial ide included keyboard',\n",
       " 52: 'weight bit zephyr cars secaris unix hockey package xon adiposity vms holding automatics people gel canadian product called water-soluble game watch baseball supposed life true lasorda saturn suggestions info jesus',\n",
       " 53: 'file people windows manager time question phone game mouse program address drive mac left answer security widget lot card team access read season clinton reason des print understand send nsa',\n",
       " 54: 'people time lot program question game monitor braves scsi pretty called weight chip list mind team university card based fans reason live days start win events guess check faq expose',\n",
       " 55: 'people god love time key government bible power reason question israel day life law read person children christian car left real live sin heard bad faith moses set idea police',\n",
       " 56: 'people god time question jesus christian nature human life israel power law reason church day jews religion true book arab john government person follow food live bible feel truth lot',\n",
       " 57: 'version players money book windows entries memory hard pool segment internet mormon gli prize denis papp chris stoochnoff error team wired bbs model time requires software win documentation wordperfect install',\n",
       " 58: 'card drive windows april version power video file time price mode graphics shuttle running speed email period play pts location disk memory goal space vga phone monitor 20:00 select engine',\n",
       " 59: 'people time god msg holy game true carrying oil weapon read center difference law grbs pitching ability baseball concealed program pressure tails federal colorado illegal quack frank galaxy west article',\n",
       " 60: 'people game objective war pin key team time technology drive science based subjective cable fat support muslims goal ground space clemens real morality evidence individual model library justifiable nuclear bosnian',\n",
       " 61: 'gun batf people god game law tongues tiff power wires based suppose time projectile jew federal larger switch turbo israel rushdie classes questions source led gas father war pentecostals crime',\n",
       " 62: 'price game power 00-00 card drive players windows time blues period team graphics sale apple chicago phone software mode email winner american set hawks bit real people monitor chip hard',\n",
       " 63: 'limit shuttle launch list clock oil months local messages vehicle. elv backlog political email maxima stuff engine media cop heard court car times noise firearm programs gun request manual server',\n",
       " 64: 'chip ghostscript power bid printer shipping dram speed set version supports dos israel ghostview monitor data game item vga running color user original windows note graphics baseball bruins settings bit',\n",
       " 65: 'mhz cpu operational model heat sink car chip tested type installed machines fpu speed price june color version time chr team drive power speakers board original scsi xsun cover upgrade',\n",
       " 66: 'people time god government read law question reason true jesus lot power public person heard evidence key life program idea religion christian book told matter arab understand wrong based game',\n",
       " 67: 'duo door chips ram technology cards monitor security nsa hard drive vendors people apple report time file window pairs school unit software hit server type koresh warrant closed agent perforated',\n",
       " 68: 'scsi people time paul drive boswell chip message list file disk game arsenokoitai term god windows homosexual read mac male power law custom software true idea material child enforcement device',\n",
       " 69: 'people government time jesus god koresh mary gun police question law evidence light key mind canada wrong true nsa data person human fbi sin individual life happened private claim clipper',\n",
       " 70: 'people time god government gant word country money women usa life dir yassin game society insurance phigs article belief lot question device pretty children scripture care health postscript windows iran',\n",
       " 71: 'people time god israel jesus window person government question lot day guns bible reason control clipper remember game folks public read called kill left christians access chip mail dos idea',\n",
       " 72: 'god people jesus sin time noise faith helmet islam word president heard baptism read wrong hockey support person father romans empire fans christ white prayers power death components life sinful',\n",
       " 73: 'widget chip void window include application code notice char atom region static return save level remote exit key data memory function user event extern set release dpy character message xsi',\n",
       " 74: 'government people german key application note keyboard ungodly window auto times called cor lord started report cnn stove doubt vehicle ppl usr lib linux running brackets xmodmap backslash car solve',\n",
       " 75: 'peace canada church usa game goal soderstrom ranford rus puck attendance penalties played lindros sanderson sweden shot tires referee amour cze eric geoff bike period torch international brind rod peter',\n",
       " 76: 'people time god windows question government game file read program lot day drive car set key post word true data life power law support list hard real bit space software',\n",
       " 77: 'vitamin people retinol time government liver infection level christian arab patients gun committee zinc turkey serum jewish random bible chronic church power beta-carotene list individual reason idea post control encryption',\n",
       " 78: 'bmw time provide answer x-designer money dealer micro oft fose windows win club display running local insurance disk tracks cost pass crime sound bad pay welfare tool taxes owners regulate',\n",
       " 79: 'rom dog bicycle everyday constitution owners mac resell iix chase people list teeth define dictionary uva warm gas cute moto stupid day pick coming lane.the fluff played momentum sharing dodge',\n",
       " 80: 'aaron god faith time grafsys baptism popup sin word source infant speech raised sinful drawing package box dialog window location christ power players response program routines read ulf press version',\n",
       " 81: 'development windows dos organization reasoning writer relaying so-called genius nra foolish city people simply apps objectives read agree time president aware to.i doubts bush worse billboard puzzling amazed clinton orbit.actually',\n",
       " 82: 'people max time windows god question drive game government program file law power lot read car data day key book software post space team idea chip real set bad bit'}"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "01558541",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tpp(txt):\n",
    "    x = str(txt).lower()\n",
    "    x = re.sub(r'http\\S+', '', x)\n",
    "    x = re.sub(r'@[^\\s]+', '', x)\n",
    "    x = re.sub(r'#[^\\s]+', '',x)\n",
    "    x = re.sub('<.*?>', ' ', x)\n",
    "    x = re.sub(' +', ' ', x)\n",
    "    x = re.sub(\"\\[.*?\\]\",\" \",x)\n",
    "    x = re.sub(\"[()!?',:;!.\\\"\\\\n]\",\" \", x)\n",
    "    x = re.sub(\"['\\\"\\\\n]\",\" \", x)\n",
    "    x = re.sub(\"www.\\S+\",\" \", x)\n",
    "    x = re.sub('[{!\"#$%&\\'()*’+,-./:;<=>?@[\\\\]^_`{»|«}~}]', ' ',x)\n",
    "    x = re.sub('\\s+', ' ', x)\n",
    "    x = re.sub(\"(.)\\\\1{2,}\", \"\\\\1\", x)\n",
    "    x = re.sub(' +', ' ',x)\n",
    "    x = x.strip()\n",
    "    x = \" \".join([word for word in x.split(\" \") if word not in stopWords])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "c5511a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "txtClean = []\n",
    "for d in text:\n",
    "    txtClean.append(tpp(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "78d02c59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'school lab assistant bunch experimental psychologists bell labs visual perception memory experiments vector type displays 1 millisecond refresh rates common 1 200th practical experimenters 5 milliseconds 4 6 steve'"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txtClean[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b149aa9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bashers', 'pens', 'fans', 'pretty', 'confused', 'lack', 'posts', 'pens', 'massacre', 'devils', 'bit', 'puzzled', 'bit', 'relieved', 'pittsburghers', 'relief', 'bit', 'praise', 'pens', 'killing', 'devils', 'worse', 'jagr', 'regular', 'season', 'stats', 'lot', 'fun', 'watch', 'playoffs']\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "# data = papers.paper_text_processed.values.tolist()\n",
    "data_words = list(sent_to_words(txtClean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "5a87cb5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-28 13:14:24,819 - adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2022-07-28 13:14:25,471 - adding document #10000 to Dictionary<61185 unique tokens: ['bashers', 'beat', 'bit', 'bowman', 'confused']...>\n",
      "2022-07-28 13:14:26,041 - built Dictionary<84565 unique tokens: ['bashers', 'beat', 'bit', 'bowman', 'confused']...> from 18846 documents (total 1359697 corpus positions)\n",
      "2022-07-28 13:14:26,042 - Dictionary lifecycle event {'msg': \"built Dictionary<84565 unique tokens: ['bashers', 'beat', 'bit', 'bowman', 'confused']...> from 18846 documents (total 1359697 corpus positions)\", 'datetime': '2022-07-28T13:14:26.042187', 'gensim': '4.2.0', 'python': '3.8.0 (default, Dec  9 2021, 17:53:27) \\n[GCC 8.4.0]', 'platform': 'Linux-5.4.0-1080-azure-x86_64-with-glibc2.27', 'event': 'created'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 3), (3, 1), (4, 1), (5, 1), (6, 2), (7, 1), (8, 1), (9, 1), (10, 2), (11, 1), (12, 1), (13, 1), (14, 2), (15, 1), (16, 1), (17, 1), (18, 1), (19, 2), (20, 1), (21, 5), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 2), (30, 1), (31, 1), (32, 1), (33, 2), (34, 1), (35, 1), (36, 1)]]\n"
     ]
    }
   ],
   "source": [
    "import gensim.corpora as corpora\n",
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_words)\n",
    "# Create Corpus\n",
    "texts = data_words\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "# View\n",
    "print(corpus[:1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "e8a7f1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-28 13:49:24,417 - using ParallelWordOccurrenceAccumulator<processes=8, batch_size=64> to estimate probabilities from sliding windows\n",
      "2022-07-28 13:49:24,763 - worker encountered unexpected exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 561, in run\n",
      "    self._run()\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 581, in _run\n",
      "    self.accumulator.partial_accumulate(docs, self.window_size)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 353, in partial_accumulate\n",
      "    super(WordOccurrenceAccumulator, self).accumulate(texts, window_size)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 296, in accumulate\n",
      "    self.analyze_text(virtual_document, doc_num)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 360, in analyze_text\n",
      "    self._slide_window(window, doc_num)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 375, in _slide_window\n",
      "    self._token_at_edge = window[0]\n",
      "IndexError: index 0 is out of bounds for axis 0 with size 0\n",
      "2022-07-28 13:49:24,765 - worker encountered unexpected exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 561, in run\n",
      "    self._run()\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 581, in _run\n",
      "    self.accumulator.partial_accumulate(docs, self.window_size)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 353, in partial_accumulate\n",
      "    super(WordOccurrenceAccumulator, self).accumulate(texts, window_size)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 296, in accumulate\n",
      "    self.analyze_text(virtual_document, doc_num)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 360, in analyze_text\n",
      "    self._slide_window(window, doc_num)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 375, in _slide_window\n",
      "    self._token_at_edge = window[0]\n",
      "IndexError: index 0 is out of bounds for axis 0 with size 0\n",
      "2022-07-28 13:49:24,768 - serializing accumulator to return to master...\n",
      "2022-07-28 13:49:24,771 - serializing accumulator to return to master...\n",
      "2022-07-28 13:49:24,780 - serializing accumulator to return to master...\n",
      "2022-07-28 13:49:24,769 - worker encountered unexpected exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 561, in run\n",
      "    self._run()\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 581, in _run\n",
      "    self.accumulator.partial_accumulate(docs, self.window_size)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 353, in partial_accumulate\n",
      "    super(WordOccurrenceAccumulator, self).accumulate(texts, window_size)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 296, in accumulate\n",
      "    self.analyze_text(virtual_document, doc_num)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 360, in analyze_text\n",
      "    self._slide_window(window, doc_num)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 375, in _slide_window\n",
      "    self._token_at_edge = window[0]\n",
      "IndexError: index 0 is out of bounds for axis 0 with size 0\n",
      "2022-07-28 13:49:24,777 - worker encountered unexpected exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 561, in run\n",
      "    self._run()\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 581, in _run\n",
      "    self.accumulator.partial_accumulate(docs, self.window_size)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 353, in partial_accumulate\n",
      "    super(WordOccurrenceAccumulator, self).accumulate(texts, window_size)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 296, in accumulate\n",
      "    self.analyze_text(virtual_document, doc_num)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 360, in analyze_text\n",
      "    self._slide_window(window, doc_num)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 375, in _slide_window\n",
      "    self._token_at_edge = window[0]\n",
      "IndexError: index 0 is out of bounds for axis 0 with size 0\n",
      "2022-07-28 13:49:24,776 - serializing accumulator to return to master...\n",
      "2022-07-28 13:49:24,775 - worker encountered unexpected exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 561, in run\n",
      "    self._run()\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 581, in _run\n",
      "    self.accumulator.partial_accumulate(docs, self.window_size)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 353, in partial_accumulate\n",
      "    super(WordOccurrenceAccumulator, self).accumulate(texts, window_size)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 296, in accumulate\n",
      "    self.analyze_text(virtual_document, doc_num)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 360, in analyze_text\n",
      "    self._slide_window(window, doc_num)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 375, in _slide_window\n",
      "    self._token_at_edge = window[0]\n",
      "IndexError: index 0 is out of bounds for axis 0 with size 0\n",
      "2022-07-28 13:49:24,779 - accumulator serialized\n",
      "2022-07-28 13:49:24,782 - serializing accumulator to return to master...\n",
      "2022-07-28 13:49:24,782 - worker encountered unexpected exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 561, in run\n",
      "    self._run()\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 581, in _run\n",
      "    self.accumulator.partial_accumulate(docs, self.window_size)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 353, in partial_accumulate\n",
      "    super(WordOccurrenceAccumulator, self).accumulate(texts, window_size)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 296, in accumulate\n",
      "    self.analyze_text(virtual_document, doc_num)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 360, in analyze_text\n",
      "    self._slide_window(window, doc_num)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 375, in _slide_window\n",
      "    self._token_at_edge = window[0]\n",
      "IndexError: index 0 is out of bounds for axis 0 with size 0\n",
      "2022-07-28 13:49:24,791 - serializing accumulator to return to master...\n",
      "2022-07-28 13:49:24,800 - worker encountered unexpected exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 561, in run\n",
      "    self._run()\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 581, in _run\n",
      "    self.accumulator.partial_accumulate(docs, self.window_size)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 353, in partial_accumulate\n",
      "    super(WordOccurrenceAccumulator, self).accumulate(texts, window_size)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 296, in accumulate\n",
      "    self.analyze_text(virtual_document, doc_num)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 360, in analyze_text\n",
      "    self._slide_window(window, doc_num)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 375, in _slide_window\n",
      "    self._token_at_edge = window[0]\n",
      "IndexError: index 0 is out of bounds for axis 0 with size 0\n",
      "2022-07-28 13:49:24,801 - worker encountered unexpected exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 561, in run\n",
      "    self._run()\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 581, in _run\n",
      "    self.accumulator.partial_accumulate(docs, self.window_size)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 353, in partial_accumulate\n",
      "    super(WordOccurrenceAccumulator, self).accumulate(texts, window_size)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 296, in accumulate\n",
      "    self.analyze_text(virtual_document, doc_num)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 360, in analyze_text\n",
      "    self._slide_window(window, doc_num)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 375, in _slide_window\n",
      "    self._token_at_edge = window[0]\n",
      "IndexError: index 0 is out of bounds for axis 0 with size 0\n",
      "2022-07-28 13:49:24,805 - serializing accumulator to return to master...\n",
      "2022-07-28 13:49:24,805 - serializing accumulator to return to master...\n",
      "2022-07-28 13:49:24,807 - accumulator serialized\n",
      "2022-07-28 13:49:24,807 - accumulator serialized\n",
      "2022-07-28 13:49:24,774 - accumulator serialized\n",
      "2022-07-28 13:49:24,782 - accumulator serialized\n",
      "2022-07-28 13:49:24,773 - accumulator serialized\n",
      "2022-07-28 13:49:24,786 - accumulator serialized\n",
      "2022-07-28 13:49:24,793 - accumulator serialized\n",
      "2022-07-28 14:05:46,755 - stats accumulation interrupted; <= -58776 documents processed\n",
      "Process AccumulatingWorker-95:\n",
      "Process AccumulatingWorker-90:\n",
      "Process AccumulatingWorker-96:\n",
      "Process AccumulatingWorker-94:\n",
      "Process AccumulatingWorker-89:\n",
      "Process AccumulatingWorker-92:\n",
      "Process AccumulatingWorker-91:\n",
      "Process AccumulatingWorker-93:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 316, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 316, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 316, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 316, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 316, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 316, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 316, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/util.py\", line 337, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/util.py\", line 337, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/util.py\", line 337, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/util.py\", line 337, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/util.py\", line 337, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/util.py\", line 277, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/util.py\", line 337, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/util.py\", line 337, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/util.py\", line 277, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/util.py\", line 277, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/util.py\", line 277, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/util.py\", line 277, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/util.py\", line 277, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/util.py\", line 277, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/util.py\", line 201, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/util.py\", line 201, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/util.py\", line 201, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/util.py\", line 201, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 195, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 195, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/util.py\", line 201, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 195, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 195, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 1011, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 1011, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 195, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 1011, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 1027, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 1011, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/util.py\", line 201, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 1027, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 1011, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 1027, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 195, in _finalize_join\n",
      "    thread.join()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 1027, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 1011, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/multiprocessing/util.py\", line 201, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 195, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 316, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/util.py\", line 337, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/util.py\", line 277, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/util.py\", line 201, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 195, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 1011, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 1027, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 1027, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 1027, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 1011, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 1027, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [168]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Compute Coherence Score\u001b[39;00m\n\u001b[1;32m      3\u001b[0m coherence_model_lda \u001b[38;5;241m=\u001b[39m CoherenceModel(model\u001b[38;5;241m=\u001b[39mlda_model, texts\u001b[38;5;241m=\u001b[39mdata_words, dictionary\u001b[38;5;241m=\u001b[39mid2word, coherence\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc_v\u001b[39m\u001b[38;5;124m'\u001b[39m,processes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m coherence_lda \u001b[38;5;241m=\u001b[39m \u001b[43mcoherence_model_lda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_coherence\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCoherence Score: \u001b[39m\u001b[38;5;124m'\u001b[39m, coherence_ld)\n",
      "File \u001b[0;32m/data/env/lib/python3.8/site-packages/gensim/models/coherencemodel.py:615\u001b[0m, in \u001b[0;36mCoherenceModel.get_coherence\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_coherence\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    607\u001b[0m     \u001b[38;5;124;03m\"\"\"Get coherence value based on pipeline parameters.\u001b[39;00m\n\u001b[1;32m    608\u001b[0m \n\u001b[1;32m    609\u001b[0m \u001b[38;5;124;03m    Returns\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    613\u001b[0m \n\u001b[1;32m    614\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 615\u001b[0m     confirmed_measures \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_coherence_per_topic\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    616\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maggregate_measures(confirmed_measures)\n",
      "File \u001b[0;32m/data/env/lib/python3.8/site-packages/gensim/models/coherencemodel.py:575\u001b[0m, in \u001b[0;36mCoherenceModel.get_coherence_per_topic\u001b[0;34m(self, segmented_topics, with_std, with_support)\u001b[0m\n\u001b[1;32m    573\u001b[0m     segmented_topics \u001b[38;5;241m=\u001b[39m measure\u001b[38;5;241m.\u001b[39mseg(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtopics)\n\u001b[1;32m    574\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accumulator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 575\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimate_probabilities\u001b[49m\u001b[43m(\u001b[49m\u001b[43msegmented_topics\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(with_std\u001b[38;5;241m=\u001b[39mwith_std, with_support\u001b[38;5;241m=\u001b[39mwith_support)\n\u001b[1;32m    578\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoherence \u001b[38;5;129;01min\u001b[39;00m BOOLEAN_DOCUMENT_BASED \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoherence \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc_w2v\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m/data/env/lib/python3.8/site-packages/gensim/models/coherencemodel.py:547\u001b[0m, in \u001b[0;36mCoherenceModel.estimate_probabilities\u001b[0;34m(self, segmented_topics)\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoherence \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc_w2v\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    545\u001b[0m         kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeyed_vectors\n\u001b[0;32m--> 547\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accumulator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmeasure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprob\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accumulator\n",
      "File \u001b[0;32m/data/env/lib/python3.8/site-packages/gensim/topic_coherence/probability_estimation.py:156\u001b[0m, in \u001b[0;36mp_boolean_sliding_window\u001b[0;34m(texts, segmented_topics, dictionary, window_size, processes)\u001b[0m\n\u001b[1;32m    154\u001b[0m     accumulator \u001b[38;5;241m=\u001b[39m ParallelWordOccurrenceAccumulator(processes, top_ids, dictionary)\n\u001b[1;32m    155\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musing \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m to estimate probabilities from sliding windows\u001b[39m\u001b[38;5;124m\"\u001b[39m, accumulator)\n\u001b[0;32m--> 156\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43maccumulator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccumulate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py:444\u001b[0m, in \u001b[0;36mParallelWordOccurrenceAccumulator.accumulate\u001b[0;34m(self, texts, window_size)\u001b[0m\n\u001b[1;32m    441\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstats accumulation interrupted; <= \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m documents processed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_docs)\n\u001b[1;32m    442\u001b[0m     interrupted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 444\u001b[0m accumulators \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mterminate_workers\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_q\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_q\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterrupted\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmerge_accumulators(accumulators)\n",
      "File \u001b[0;32m/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py:521\u001b[0m, in \u001b[0;36mParallelWordOccurrenceAccumulator.terminate_workers\u001b[0;34m(self, input_q, output_q, workers, interrupted)\u001b[0m\n\u001b[1;32m    519\u001b[0m accumulators \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    520\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(accumulators) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(workers):\n\u001b[0;32m--> 521\u001b[0m     accumulators\u001b[38;5;241m.\u001b[39mappend(\u001b[43moutput_q\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    522\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m accumulators retrieved from output queue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(accumulators))\n\u001b[1;32m    524\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m worker \u001b[38;5;129;01min\u001b[39;00m workers:\n",
      "File \u001b[0;32m/usr/lib/python3.8/multiprocessing/queues.py:97\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block \u001b[38;5;129;01mand\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rlock:\n\u001b[0;32m---> 97\u001b[0m         res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sem\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.8/multiprocessing/connection.py:216\u001b[0m, in \u001b[0;36m_ConnectionBase.recv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m maxlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m maxlength \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnegative maxlength\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 216\u001b[0m buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaxlength\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m buf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bad_message_length()\n",
      "File \u001b[0;32m/usr/lib/python3.8/multiprocessing/connection.py:421\u001b[0m, in \u001b[0;36mConnection._recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m maxsize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m size \u001b[38;5;241m>\u001b[39m maxsize:\n\u001b[1;32m    420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 421\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.8/multiprocessing/connection.py:379\u001b[0m, in \u001b[0;36mConnection._recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m remaining \u001b[38;5;241m=\u001b[39m size\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m remaining \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 379\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m \u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    380\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(chunk)\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_words, dictionary=id2word, coherence='c_v',processes=8)\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_ld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae17c76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"fij kf\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "f5a0fb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "topicc = []\n",
    "for i in out[0].keys():\n",
    "    topicc.append(out[0][i].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "53de40d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['file',\n",
       "  'people',\n",
       "  'dos',\n",
       "  'time',\n",
       "  'god',\n",
       "  'president',\n",
       "  'space',\n",
       "  'stephanopoulos',\n",
       "  'program',\n",
       "  'version',\n",
       "  'jpeg',\n",
       "  'health',\n",
       "  'data',\n",
       "  'output',\n",
       "  'armenian',\n",
       "  'software',\n",
       "  'ftp',\n",
       "  'jesus',\n",
       "  'windows',\n",
       "  'questions',\n",
       "  'children',\n",
       "  'image',\n",
       "  'united',\n",
       "  'adl',\n",
       "  'national',\n",
       "  'april',\n",
       "  'set',\n",
       "  'public',\n",
       "  'control',\n",
       "  'day'],\n",
       " ['dollars',\n",
       "  'motif',\n",
       "  'avs',\n",
       "  'games',\n",
       "  'mission',\n",
       "  'time',\n",
       "  'constitution',\n",
       "  'esd',\n",
       "  'conductive',\n",
       "  'increase',\n",
       "  'government',\n",
       "  'manager',\n",
       "  'ms-w',\n",
       "  'software',\n",
       "  'jesus',\n",
       "  'graphics',\n",
       "  'power',\n",
       "  'disks',\n",
       "  'floppy',\n",
       "  'drive',\n",
       "  'unleaded',\n",
       "  'card',\n",
       "  'spent',\n",
       "  'question',\n",
       "  'phill',\n",
       "  'program',\n",
       "  'forget',\n",
       "  'national',\n",
       "  'features',\n",
       "  'network'],\n",
       " ['people',\n",
       "  'internet',\n",
       "  'zionism',\n",
       "  'ethernet',\n",
       "  'christianity',\n",
       "  'node',\n",
       "  'decnet',\n",
       "  'address',\n",
       "  'worth',\n",
       "  'homosexual',\n",
       "  'religious',\n",
       "  'chancellor',\n",
       "  'voted',\n",
       "  'hitler',\n",
       "  'space',\n",
       "  'count',\n",
       "  'connected',\n",
       "  'vaxstation',\n",
       "  'live',\n",
       "  'statement',\n",
       "  'advertising',\n",
       "  'immoral',\n",
       "  'sort',\n",
       "  'time',\n",
       "  'qemm',\n",
       "  'aids',\n",
       "  'person',\n",
       "  'false',\n",
       "  'jeezus',\n",
       "  'reich'],\n",
       " ['people',\n",
       "  'homosexual',\n",
       "  'god',\n",
       "  'true',\n",
       "  'evidence',\n",
       "  'belief',\n",
       "  'theism',\n",
       "  'moral',\n",
       "  'claim',\n",
       "  'time',\n",
       "  'bible',\n",
       "  'reason',\n",
       "  'argument',\n",
       "  'read',\n",
       "  'gay',\n",
       "  'sexual',\n",
       "  'lot',\n",
       "  'statement',\n",
       "  'jesus',\n",
       "  'church',\n",
       "  'question',\n",
       "  'issue',\n",
       "  'children',\n",
       "  'agree',\n",
       "  'force',\n",
       "  'wrong',\n",
       "  'person',\n",
       "  'laws',\n",
       "  'freedom',\n",
       "  'article'],\n",
       " ['people',\n",
       "  'time',\n",
       "  'god',\n",
       "  'windows',\n",
       "  'question',\n",
       "  'government',\n",
       "  'drive',\n",
       "  'game',\n",
       "  'read',\n",
       "  'program',\n",
       "  'file',\n",
       "  'power',\n",
       "  'day',\n",
       "  'lot',\n",
       "  'law',\n",
       "  'car',\n",
       "  'key',\n",
       "  'data',\n",
       "  'set',\n",
       "  'book',\n",
       "  'bit',\n",
       "  'true',\n",
       "  'post',\n",
       "  'reason',\n",
       "  'software',\n",
       "  'space',\n",
       "  'support',\n",
       "  'list',\n",
       "  'team',\n",
       "  'word'],\n",
       " ['max',\n",
       "  'file',\n",
       "  'bhj',\n",
       "  'giz',\n",
       "  'entry',\n",
       "  'program',\n",
       "  'scx',\n",
       "  'bxn',\n",
       "  'output',\n",
       "  'internet',\n",
       "  'email',\n",
       "  'privacy',\n",
       "  'entries',\n",
       "  'rules',\n",
       "  'okz',\n",
       "  'anonymous',\n",
       "  'air',\n",
       "  'rlk',\n",
       "  'openwindows',\n",
       "  'build',\n",
       "  'user',\n",
       "  'list',\n",
       "  'fij',\n",
       "  'fyn',\n",
       "  'windows',\n",
       "  'pub',\n",
       "  'address',\n",
       "  'info',\n",
       "  'qax',\n",
       "  'source'],\n",
       " ['image',\n",
       "  'file',\n",
       "  'jpeg',\n",
       "  'data',\n",
       "  'pub',\n",
       "  'graphics',\n",
       "  'version',\n",
       "  'program',\n",
       "  'software',\n",
       "  'server',\n",
       "  'ftp',\n",
       "  'format',\n",
       "  'package',\n",
       "  'window',\n",
       "  'display',\n",
       "  'subject',\n",
       "  'support',\n",
       "  'color',\n",
       "  'send',\n",
       "  'space',\n",
       "  'includes',\n",
       "  'code',\n",
       "  'gif',\n",
       "  'sun',\n",
       "  'time',\n",
       "  'set',\n",
       "  'contact',\n",
       "  'motif',\n",
       "  'source',\n",
       "  'applications']]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topicc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8b55a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "235a279e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-28 13:46:04,865 - using symmetric alpha at 0.1\n",
      "2022-07-28 13:46:04,866 - using symmetric eta at 0.1\n",
      "2022-07-28 13:46:04,875 - using serial LDA version on this node\n",
      "2022-07-28 13:46:04,950 - running online LDA training, 10 topics, 10 passes over the supplied corpus of 18846 documents, updating every 1500 documents, evaluating every ~15000 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2022-07-28 13:46:04,951 - training LDA model using 15 processes\n",
      "2022-07-28 13:46:05,521 - PROGRESS: pass 0, dispatched chunk #0 = documents up to #100/18846, outstanding queue size 1\n",
      "2022-07-28 13:46:05,533 - PROGRESS: pass 0, dispatched chunk #1 = documents up to #200/18846, outstanding queue size 2\n",
      "2022-07-28 13:46:05,534 - PROGRESS: pass 0, dispatched chunk #2 = documents up to #300/18846, outstanding queue size 3\n",
      "2022-07-28 13:46:05,534 - PROGRESS: pass 0, dispatched chunk #3 = documents up to #400/18846, outstanding queue size 4\n",
      "2022-07-28 13:46:05,535 - PROGRESS: pass 0, dispatched chunk #4 = documents up to #500/18846, outstanding queue size 5\n",
      "2022-07-28 13:46:05,538 - PROGRESS: pass 0, dispatched chunk #5 = documents up to #600/18846, outstanding queue size 6\n",
      "2022-07-28 13:46:05,539 - PROGRESS: pass 0, dispatched chunk #6 = documents up to #700/18846, outstanding queue size 7\n",
      "2022-07-28 13:46:05,540 - PROGRESS: pass 0, dispatched chunk #7 = documents up to #800/18846, outstanding queue size 8\n",
      "2022-07-28 13:46:05,541 - PROGRESS: pass 0, dispatched chunk #8 = documents up to #900/18846, outstanding queue size 9\n",
      "2022-07-28 13:46:05,542 - PROGRESS: pass 0, dispatched chunk #9 = documents up to #1000/18846, outstanding queue size 10\n",
      "2022-07-28 13:46:05,545 - PROGRESS: pass 0, dispatched chunk #10 = documents up to #1100/18846, outstanding queue size 11\n",
      "2022-07-28 13:46:05,546 - PROGRESS: pass 0, dispatched chunk #11 = documents up to #1200/18846, outstanding queue size 12\n",
      "2022-07-28 13:46:05,548 - PROGRESS: pass 0, dispatched chunk #12 = documents up to #1300/18846, outstanding queue size 13\n",
      "2022-07-28 13:46:05,548 - PROGRESS: pass 0, dispatched chunk #13 = documents up to #1400/18846, outstanding queue size 14\n",
      "2022-07-28 13:46:05,550 - PROGRESS: pass 0, dispatched chunk #14 = documents up to #1500/18846, outstanding queue size 15\n",
      "2022-07-28 13:46:05,554 - PROGRESS: pass 0, dispatched chunk #15 = documents up to #1600/18846, outstanding queue size 16\n",
      "2022-07-28 13:46:05,555 - PROGRESS: pass 0, dispatched chunk #16 = documents up to #1700/18846, outstanding queue size 17\n",
      "2022-07-28 13:46:05,556 - PROGRESS: pass 0, dispatched chunk #17 = documents up to #1800/18846, outstanding queue size 18\n",
      "2022-07-28 13:46:05,557 - PROGRESS: pass 0, dispatched chunk #18 = documents up to #1900/18846, outstanding queue size 19\n",
      "2022-07-28 13:46:05,558 - PROGRESS: pass 0, dispatched chunk #19 = documents up to #2000/18846, outstanding queue size 20\n",
      "2022-07-28 13:46:05,562 - PROGRESS: pass 0, dispatched chunk #20 = documents up to #2100/18846, outstanding queue size 21\n",
      "2022-07-28 13:46:05,563 - PROGRESS: pass 0, dispatched chunk #21 = documents up to #2200/18846, outstanding queue size 22\n",
      "2022-07-28 13:46:05,565 - PROGRESS: pass 0, dispatched chunk #22 = documents up to #2300/18846, outstanding queue size 23\n",
      "2022-07-28 13:46:05,566 - PROGRESS: pass 0, dispatched chunk #23 = documents up to #2400/18846, outstanding queue size 24\n",
      "2022-07-28 13:46:05,567 - PROGRESS: pass 0, dispatched chunk #24 = documents up to #2500/18846, outstanding queue size 25\n",
      "2022-07-28 13:46:05,568 - PROGRESS: pass 0, dispatched chunk #25 = documents up to #2600/18846, outstanding queue size 26\n",
      "2022-07-28 13:46:05,569 - PROGRESS: pass 0, dispatched chunk #26 = documents up to #2700/18846, outstanding queue size 27\n",
      "2022-07-28 13:46:05,570 - PROGRESS: pass 0, dispatched chunk #27 = documents up to #2800/18846, outstanding queue size 28\n",
      "2022-07-28 13:46:05,573 - PROGRESS: pass 0, dispatched chunk #28 = documents up to #2900/18846, outstanding queue size 29\n",
      "2022-07-28 13:46:05,574 - PROGRESS: pass 0, dispatched chunk #29 = documents up to #3000/18846, outstanding queue size 30\n",
      "2022-07-28 13:46:05,575 - PROGRESS: pass 0, dispatched chunk #30 = documents up to #3100/18846, outstanding queue size 31\n",
      "2022-07-28 13:46:05,576 - PROGRESS: pass 0, dispatched chunk #31 = documents up to #3200/18846, outstanding queue size 32\n",
      "2022-07-28 13:46:05,577 - PROGRESS: pass 0, dispatched chunk #32 = documents up to #3300/18846, outstanding queue size 33\n",
      "2022-07-28 13:46:05,578 - PROGRESS: pass 0, dispatched chunk #33 = documents up to #3400/18846, outstanding queue size 34\n",
      "2022-07-28 13:46:05,583 - PROGRESS: pass 0, dispatched chunk #34 = documents up to #3500/18846, outstanding queue size 35\n",
      "2022-07-28 13:46:05,584 - PROGRESS: pass 0, dispatched chunk #35 = documents up to #3600/18846, outstanding queue size 36\n",
      "2022-07-28 13:46:05,593 - PROGRESS: pass 0, dispatched chunk #36 = documents up to #3700/18846, outstanding queue size 37\n",
      "2022-07-28 13:46:05,599 - PROGRESS: pass 0, dispatched chunk #37 = documents up to #3800/18846, outstanding queue size 38\n",
      "2022-07-28 13:46:05,610 - PROGRESS: pass 0, dispatched chunk #38 = documents up to #3900/18846, outstanding queue size 39\n",
      "2022-07-28 13:46:05,619 - PROGRESS: pass 0, dispatched chunk #39 = documents up to #4000/18846, outstanding queue size 40\n",
      "2022-07-28 13:46:05,631 - PROGRESS: pass 0, dispatched chunk #40 = documents up to #4100/18846, outstanding queue size 41\n",
      "2022-07-28 13:46:05,640 - PROGRESS: pass 0, dispatched chunk #41 = documents up to #4200/18846, outstanding queue size 42\n",
      "2022-07-28 13:46:05,673 - PROGRESS: pass 0, dispatched chunk #42 = documents up to #4300/18846, outstanding queue size 42\n",
      "2022-07-28 13:46:05,695 - PROGRESS: pass 0, dispatched chunk #43 = documents up to #4400/18846, outstanding queue size 41\n",
      "2022-07-28 13:46:05,697 - PROGRESS: pass 0, dispatched chunk #44 = documents up to #4500/18846, outstanding queue size 42\n",
      "2022-07-28 13:46:05,733 - PROGRESS: pass 0, dispatched chunk #45 = documents up to #4600/18846, outstanding queue size 40\n",
      "2022-07-28 13:46:05,735 - PROGRESS: pass 0, dispatched chunk #46 = documents up to #4700/18846, outstanding queue size 41\n",
      "2022-07-28 13:46:05,748 - PROGRESS: pass 0, dispatched chunk #47 = documents up to #4800/18846, outstanding queue size 42\n",
      "2022-07-28 13:46:05,774 - PROGRESS: pass 0, dispatched chunk #48 = documents up to #4900/18846, outstanding queue size 43\n",
      "2022-07-28 13:46:05,804 - PROGRESS: pass 0, dispatched chunk #49 = documents up to #5000/18846, outstanding queue size 41\n",
      "2022-07-28 13:46:05,805 - PROGRESS: pass 0, dispatched chunk #50 = documents up to #5100/18846, outstanding queue size 42\n",
      "2022-07-28 13:46:05,823 - PROGRESS: pass 0, dispatched chunk #51 = documents up to #5200/18846, outstanding queue size 43\n",
      "2022-07-28 13:46:05,864 - PROGRESS: pass 0, dispatched chunk #52 = documents up to #5300/18846, outstanding queue size 42\n",
      "2022-07-28 13:46:05,865 - PROGRESS: pass 0, dispatched chunk #53 = documents up to #5400/18846, outstanding queue size 43\n",
      "2022-07-28 13:46:05,866 - PROGRESS: pass 0, dispatched chunk #54 = documents up to #5500/18846, outstanding queue size 44\n",
      "2022-07-28 13:46:05,897 - PROGRESS: pass 0, dispatched chunk #55 = documents up to #5600/18846, outstanding queue size 44\n",
      "2022-07-28 13:46:05,899 - PROGRESS: pass 0, dispatched chunk #56 = documents up to #5700/18846, outstanding queue size 45\n",
      "2022-07-28 13:46:06,022 - PROGRESS: pass 0, dispatched chunk #57 = documents up to #5800/18846, outstanding queue size 46\n",
      "2022-07-28 13:46:06,191 - PROGRESS: pass 0, dispatched chunk #58 = documents up to #5900/18846, outstanding queue size 45\n",
      "2022-07-28 13:46:06,194 - PROGRESS: pass 0, dispatched chunk #59 = documents up to #6000/18846, outstanding queue size 46\n",
      "2022-07-28 13:46:06,196 - PROGRESS: pass 0, dispatched chunk #60 = documents up to #6100/18846, outstanding queue size 47\n",
      "2022-07-28 13:46:06,197 - PROGRESS: pass 0, dispatched chunk #61 = documents up to #6200/18846, outstanding queue size 48\n",
      "2022-07-28 13:46:06,199 - PROGRESS: pass 0, dispatched chunk #62 = documents up to #6300/18846, outstanding queue size 49\n",
      "2022-07-28 13:46:06,200 - PROGRESS: pass 0, dispatched chunk #63 = documents up to #6400/18846, outstanding queue size 50\n",
      "2022-07-28 13:46:06,202 - PROGRESS: pass 0, dispatched chunk #64 = documents up to #6500/18846, outstanding queue size 51\n",
      "2022-07-28 13:46:06,206 - PROGRESS: pass 0, dispatched chunk #65 = documents up to #6600/18846, outstanding queue size 52\n",
      "2022-07-28 13:46:06,208 - PROGRESS: pass 0, dispatched chunk #66 = documents up to #6700/18846, outstanding queue size 53\n",
      "2022-07-28 13:46:06,369 - merging changes from 1500 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:06,489 - topic #4 (0.100): 0.005*\"people\" + 0.004*\"god\" + 0.003*\"time\" + 0.003*\"mb\" + 0.002*\"program\" + 0.002*\"key\" + 0.002*\"law\" + 0.002*\"question\" + 0.002*\"jesus\" + 0.002*\"mail\"\n",
      "2022-07-28 13:46:06,498 - topic #9 (0.100): 0.006*\"people\" + 0.003*\"window\" + 0.003*\"time\" + 0.003*\"question\" + 0.002*\"god\" + 0.002*\"true\" + 0.002*\"lost\" + 0.002*\"space\" + 0.002*\"windows\" + 0.002*\"set\"\n",
      "2022-07-28 13:46:06,501 - topic #3 (0.100): 0.004*\"people\" + 0.004*\"time\" + 0.002*\"data\" + 0.002*\"god\" + 0.002*\"server\" + 0.002*\"det\" + 0.002*\"law\" + 0.002*\"idea\" + 0.002*\"question\" + 0.002*\"van\"\n",
      "2022-07-28 13:46:06,505 - topic #6 (0.100): 0.005*\"dos\" + 0.004*\"people\" + 0.003*\"god\" + 0.003*\"time\" + 0.003*\"question\" + 0.002*\"bad\" + 0.002*\"wrong\" + 0.002*\"water\" + 0.002*\"address\" + 0.001*\"short\"\n",
      "2022-07-28 13:46:06,507 - topic #8 (0.100): 0.005*\"people\" + 0.003*\"time\" + 0.003*\"program\" + 0.003*\"law\" + 0.003*\"data\" + 0.002*\"green\" + 0.002*\"blue\" + 0.002*\"start\" + 0.002*\"ics\" + 0.002*\"president\"\n",
      "2022-07-28 13:46:06,516 - topic diff=8.813081, rho=1.000000\n",
      "2022-07-28 13:46:06,527 - PROGRESS: pass 0, dispatched chunk #67 = documents up to #6800/18846, outstanding queue size 53\n",
      "2022-07-28 13:46:06,546 - PROGRESS: pass 0, dispatched chunk #68 = documents up to #6900/18846, outstanding queue size 52\n",
      "2022-07-28 13:46:06,552 - PROGRESS: pass 0, dispatched chunk #69 = documents up to #7000/18846, outstanding queue size 53\n",
      "2022-07-28 13:46:06,554 - PROGRESS: pass 0, dispatched chunk #70 = documents up to #7100/18846, outstanding queue size 54\n",
      "2022-07-28 13:46:06,556 - PROGRESS: pass 0, dispatched chunk #71 = documents up to #7200/18846, outstanding queue size 55\n",
      "2022-07-28 13:46:06,558 - PROGRESS: pass 0, dispatched chunk #72 = documents up to #7300/18846, outstanding queue size 56\n",
      "2022-07-28 13:46:06,560 - PROGRESS: pass 0, dispatched chunk #73 = documents up to #7400/18846, outstanding queue size 57\n",
      "2022-07-28 13:46:06,562 - PROGRESS: pass 0, dispatched chunk #74 = documents up to #7500/18846, outstanding queue size 58\n",
      "2022-07-28 13:46:06,564 - PROGRESS: pass 0, dispatched chunk #75 = documents up to #7600/18846, outstanding queue size 59\n",
      "2022-07-28 13:46:06,567 - PROGRESS: pass 0, dispatched chunk #76 = documents up to #7700/18846, outstanding queue size 60\n",
      "2022-07-28 13:46:06,572 - PROGRESS: pass 0, dispatched chunk #77 = documents up to #7800/18846, outstanding queue size 61\n",
      "2022-07-28 13:46:06,590 - PROGRESS: pass 0, dispatched chunk #78 = documents up to #7900/18846, outstanding queue size 62\n",
      "2022-07-28 13:46:06,641 - PROGRESS: pass 0, dispatched chunk #79 = documents up to #8000/18846, outstanding queue size 63\n",
      "2022-07-28 13:46:06,668 - PROGRESS: pass 0, dispatched chunk #80 = documents up to #8100/18846, outstanding queue size 64\n",
      "2022-07-28 13:46:06,686 - PROGRESS: pass 0, dispatched chunk #81 = documents up to #8200/18846, outstanding queue size 64\n",
      "2022-07-28 13:46:06,700 - PROGRESS: pass 0, dispatched chunk #82 = documents up to #8300/18846, outstanding queue size 65\n",
      "2022-07-28 13:46:06,770 - PROGRESS: pass 0, dispatched chunk #83 = documents up to #8400/18846, outstanding queue size 64\n",
      "2022-07-28 13:46:06,773 - PROGRESS: pass 0, dispatched chunk #84 = documents up to #8500/18846, outstanding queue size 65\n",
      "2022-07-28 13:46:06,885 - PROGRESS: pass 0, dispatched chunk #85 = documents up to #8600/18846, outstanding queue size 65\n",
      "2022-07-28 13:46:07,006 - PROGRESS: pass 0, dispatched chunk #86 = documents up to #8700/18846, outstanding queue size 63\n",
      "2022-07-28 13:46:07,090 - PROGRESS: pass 0, dispatched chunk #87 = documents up to #8800/18846, outstanding queue size 60\n",
      "2022-07-28 13:46:07,095 - PROGRESS: pass 0, dispatched chunk #88 = documents up to #8900/18846, outstanding queue size 61\n",
      "2022-07-28 13:46:07,098 - PROGRESS: pass 0, dispatched chunk #89 = documents up to #9000/18846, outstanding queue size 62\n",
      "2022-07-28 13:46:07,128 - PROGRESS: pass 0, dispatched chunk #90 = documents up to #9100/18846, outstanding queue size 63\n",
      "2022-07-28 13:46:07,132 - PROGRESS: pass 0, dispatched chunk #91 = documents up to #9200/18846, outstanding queue size 64\n",
      "2022-07-28 13:46:07,154 - PROGRESS: pass 0, dispatched chunk #92 = documents up to #9300/18846, outstanding queue size 65\n",
      "2022-07-28 13:46:07,158 - PROGRESS: pass 0, dispatched chunk #93 = documents up to #9400/18846, outstanding queue size 66\n",
      "2022-07-28 13:46:07,192 - PROGRESS: pass 0, dispatched chunk #94 = documents up to #9500/18846, outstanding queue size 67\n",
      "2022-07-28 13:46:07,197 - PROGRESS: pass 0, dispatched chunk #95 = documents up to #9600/18846, outstanding queue size 68\n",
      "2022-07-28 13:46:07,215 - PROGRESS: pass 0, dispatched chunk #96 = documents up to #9700/18846, outstanding queue size 69\n",
      "2022-07-28 13:46:07,242 - PROGRESS: pass 0, dispatched chunk #97 = documents up to #9800/18846, outstanding queue size 70\n",
      "2022-07-28 13:46:07,255 - PROGRESS: pass 0, dispatched chunk #98 = documents up to #9900/18846, outstanding queue size 71\n",
      "2022-07-28 13:46:07,261 - PROGRESS: pass 0, dispatched chunk #99 = documents up to #10000/18846, outstanding queue size 71\n",
      "2022-07-28 13:46:07,500 - merging changes from 1500 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:07,598 - topic #3 (0.100): 0.004*\"people\" + 0.004*\"time\" + 0.003*\"god\" + 0.002*\"data\" + 0.002*\"idea\" + 0.002*\"server\" + 0.002*\"law\" + 0.002*\"question\" + 0.002*\"reason\" + 0.002*\"program\"\n",
      "2022-07-28 13:46:07,646 - topic #2 (0.100): 0.006*\"time\" + 0.005*\"people\" + 0.003*\"space\" + 0.003*\"read\" + 0.002*\"god\" + 0.002*\"card\" + 0.002*\"power\" + 0.002*\"key\" + 0.002*\"data\" + 0.002*\"real\"\n",
      "2022-07-28 13:46:07,663 - topic #9 (0.100): 0.006*\"people\" + 0.003*\"window\" + 0.002*\"time\" + 0.002*\"windows\" + 0.002*\"question\" + 0.002*\"god\" + 0.002*\"true\" + 0.002*\"set\" + 0.001*\"lost\" + 0.001*\"space\"\n",
      "2022-07-28 13:46:07,665 - topic #7 (0.100): 0.005*\"people\" + 0.004*\"time\" + 0.003*\"car\" + 0.002*\"question\" + 0.002*\"law\" + 0.002*\"true\" + 0.002*\"lot\" + 0.002*\"bit\" + 0.002*\"pc\" + 0.002*\"ndet\"\n",
      "2022-07-28 13:46:07,693 - topic #4 (0.100): 0.005*\"god\" + 0.005*\"people\" + 0.003*\"time\" + 0.003*\"key\" + 0.002*\"jesus\" + 0.002*\"program\" + 0.002*\"mb\" + 0.002*\"law\" + 0.002*\"true\" + 0.002*\"question\"\n",
      "2022-07-28 13:46:07,697 - topic diff=1.038296, rho=0.250000\n",
      "2022-07-28 13:46:07,699 - PROGRESS: pass 0, dispatched chunk #100 = documents up to #10100/18846, outstanding queue size 71\n",
      "2022-07-28 13:46:07,707 - PROGRESS: pass 0, dispatched chunk #101 = documents up to #10200/18846, outstanding queue size 71\n",
      "2022-07-28 13:46:07,720 - PROGRESS: pass 0, dispatched chunk #102 = documents up to #10300/18846, outstanding queue size 71\n",
      "2022-07-28 13:46:07,743 - PROGRESS: pass 0, dispatched chunk #103 = documents up to #10400/18846, outstanding queue size 72\n",
      "2022-07-28 13:46:07,744 - PROGRESS: pass 0, dispatched chunk #104 = documents up to #10500/18846, outstanding queue size 73\n",
      "2022-07-28 13:46:07,759 - PROGRESS: pass 0, dispatched chunk #105 = documents up to #10600/18846, outstanding queue size 72\n",
      "2022-07-28 13:46:07,761 - PROGRESS: pass 0, dispatched chunk #106 = documents up to #10700/18846, outstanding queue size 73\n",
      "2022-07-28 13:46:07,762 - PROGRESS: pass 0, dispatched chunk #107 = documents up to #10800/18846, outstanding queue size 74\n",
      "2022-07-28 13:46:07,763 - PROGRESS: pass 0, dispatched chunk #108 = documents up to #10900/18846, outstanding queue size 75\n",
      "2022-07-28 13:46:07,764 - PROGRESS: pass 0, dispatched chunk #109 = documents up to #11000/18846, outstanding queue size 76\n",
      "2022-07-28 13:46:07,765 - PROGRESS: pass 0, dispatched chunk #110 = documents up to #11100/18846, outstanding queue size 77\n",
      "2022-07-28 13:46:07,766 - PROGRESS: pass 0, dispatched chunk #111 = documents up to #11200/18846, outstanding queue size 78\n",
      "2022-07-28 13:46:07,767 - PROGRESS: pass 0, dispatched chunk #112 = documents up to #11300/18846, outstanding queue size 79\n",
      "2022-07-28 13:46:07,770 - PROGRESS: pass 0, dispatched chunk #113 = documents up to #11400/18846, outstanding queue size 80\n",
      "2022-07-28 13:46:07,770 - PROGRESS: pass 0, dispatched chunk #114 = documents up to #11500/18846, outstanding queue size 81\n",
      "2022-07-28 13:46:07,771 - PROGRESS: pass 0, dispatched chunk #115 = documents up to #11600/18846, outstanding queue size 82\n",
      "2022-07-28 13:46:07,796 - PROGRESS: pass 0, dispatched chunk #116 = documents up to #11700/18846, outstanding queue size 81\n",
      "2022-07-28 13:46:07,826 - PROGRESS: pass 0, dispatched chunk #117 = documents up to #11800/18846, outstanding queue size 82\n",
      "2022-07-28 13:46:07,842 - PROGRESS: pass 0, dispatched chunk #118 = documents up to #11900/18846, outstanding queue size 83\n",
      "2022-07-28 13:46:07,854 - PROGRESS: pass 0, dispatched chunk #119 = documents up to #12000/18846, outstanding queue size 84\n",
      "2022-07-28 13:46:07,896 - PROGRESS: pass 0, dispatched chunk #120 = documents up to #12100/18846, outstanding queue size 84\n",
      "2022-07-28 13:46:07,899 - PROGRESS: pass 0, dispatched chunk #121 = documents up to #12200/18846, outstanding queue size 85\n",
      "2022-07-28 13:46:07,925 - PROGRESS: pass 0, dispatched chunk #122 = documents up to #12300/18846, outstanding queue size 83\n",
      "2022-07-28 13:46:07,976 - PROGRESS: pass 0, dispatched chunk #123 = documents up to #12400/18846, outstanding queue size 84\n",
      "2022-07-28 13:46:07,994 - PROGRESS: pass 0, dispatched chunk #124 = documents up to #12500/18846, outstanding queue size 85\n",
      "2022-07-28 13:46:08,002 - PROGRESS: pass 0, dispatched chunk #125 = documents up to #12600/18846, outstanding queue size 86\n",
      "2022-07-28 13:46:08,007 - PROGRESS: pass 0, dispatched chunk #126 = documents up to #12700/18846, outstanding queue size 87\n",
      "2022-07-28 13:46:08,010 - PROGRESS: pass 0, dispatched chunk #127 = documents up to #12800/18846, outstanding queue size 88\n",
      "2022-07-28 13:46:08,099 - PROGRESS: pass 0, dispatched chunk #128 = documents up to #12900/18846, outstanding queue size 86\n",
      "2022-07-28 13:46:08,134 - PROGRESS: pass 0, dispatched chunk #129 = documents up to #13000/18846, outstanding queue size 86\n",
      "2022-07-28 13:46:08,313 - merging changes from 1500 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:08,453 - topic #3 (0.100): 0.004*\"people\" + 0.004*\"time\" + 0.003*\"file\" + 0.003*\"data\" + 0.002*\"god\" + 0.002*\"program\" + 0.002*\"output\" + 0.002*\"server\" + 0.002*\"law\" + 0.002*\"idea\"\n",
      "2022-07-28 13:46:08,455 - topic #6 (0.100): 0.005*\"dos\" + 0.004*\"people\" + 0.003*\"god\" + 0.003*\"time\" + 0.003*\"hz\" + 0.002*\"question\" + 0.002*\"windows\" + 0.002*\"wrong\" + 0.002*\"file\" + 0.002*\"bad\"\n",
      "2022-07-28 13:46:08,456 - topic #4 (0.100): 0.005*\"people\" + 0.005*\"god\" + 0.003*\"time\" + 0.002*\"program\" + 0.002*\"key\" + 0.002*\"jesus\" + 0.002*\"mb\" + 0.002*\"law\" + 0.002*\"mail\" + 0.002*\"true\"\n",
      "2022-07-28 13:46:08,457 - topic #7 (0.100): 0.005*\"people\" + 0.004*\"time\" + 0.003*\"car\" + 0.003*\"jpeg\" + 0.002*\"file\" + 0.002*\"bit\" + 0.002*\"pc\" + 0.002*\"question\" + 0.002*\"law\" + 0.002*\"lot\"\n",
      "2022-07-28 13:46:08,458 - topic #1 (0.100): 0.005*\"time\" + 0.004*\"people\" + 0.004*\"list\" + 0.004*\"game\" + 0.003*\"software\" + 0.003*\"bit\" + 0.003*\"mail\" + 0.002*\"file\" + 0.002*\"program\" + 0.002*\"card\"\n",
      "2022-07-28 13:46:08,460 - topic diff=0.576448, rho=0.179605\n",
      "2022-07-28 13:46:08,461 - PROGRESS: pass 0, dispatched chunk #130 = documents up to #13100/18846, outstanding queue size 86\n",
      "2022-07-28 13:46:08,482 - PROGRESS: pass 0, dispatched chunk #131 = documents up to #13200/18846, outstanding queue size 80\n",
      "2022-07-28 13:46:08,493 - PROGRESS: pass 0, dispatched chunk #132 = documents up to #13300/18846, outstanding queue size 78\n",
      "2022-07-28 13:46:08,494 - PROGRESS: pass 0, dispatched chunk #133 = documents up to #13400/18846, outstanding queue size 79\n",
      "2022-07-28 13:46:08,495 - PROGRESS: pass 0, dispatched chunk #134 = documents up to #13500/18846, outstanding queue size 80\n",
      "2022-07-28 13:46:08,496 - PROGRESS: pass 0, dispatched chunk #135 = documents up to #13600/18846, outstanding queue size 81\n",
      "2022-07-28 13:46:08,503 - PROGRESS: pass 0, dispatched chunk #136 = documents up to #13700/18846, outstanding queue size 82\n",
      "2022-07-28 13:46:08,532 - PROGRESS: pass 0, dispatched chunk #137 = documents up to #13800/18846, outstanding queue size 82\n",
      "2022-07-28 13:46:08,553 - PROGRESS: pass 0, dispatched chunk #138 = documents up to #13900/18846, outstanding queue size 82\n",
      "2022-07-28 13:46:08,580 - PROGRESS: pass 0, dispatched chunk #139 = documents up to #14000/18846, outstanding queue size 82\n",
      "2022-07-28 13:46:08,584 - PROGRESS: pass 0, dispatched chunk #140 = documents up to #14100/18846, outstanding queue size 83\n",
      "2022-07-28 13:46:08,667 - PROGRESS: pass 0, dispatched chunk #141 = documents up to #14200/18846, outstanding queue size 84\n",
      "2022-07-28 13:46:08,669 - PROGRESS: pass 0, dispatched chunk #142 = documents up to #14300/18846, outstanding queue size 85\n",
      "2022-07-28 13:46:08,676 - PROGRESS: pass 0, dispatched chunk #143 = documents up to #14400/18846, outstanding queue size 85\n",
      "2022-07-28 13:46:08,689 - PROGRESS: pass 0, dispatched chunk #144 = documents up to #14500/18846, outstanding queue size 86\n",
      "2022-07-28 13:46:08,691 - PROGRESS: pass 0, dispatched chunk #145 = documents up to #14600/18846, outstanding queue size 87\n",
      "2022-07-28 13:46:08,718 - PROGRESS: pass 0, dispatched chunk #146 = documents up to #14700/18846, outstanding queue size 88\n",
      "2022-07-28 13:46:08,767 - PROGRESS: pass 0, dispatched chunk #147 = documents up to #14800/18846, outstanding queue size 89\n",
      "2022-07-28 13:46:08,770 - PROGRESS: pass 0, dispatched chunk #148 = documents up to #14900/18846, outstanding queue size 90\n",
      "2022-07-28 13:46:08,874 - merging changes from 1500 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:08,964 - topic #3 (0.100): 0.004*\"time\" + 0.004*\"people\" + 0.003*\"god\" + 0.002*\"data\" + 0.002*\"file\" + 0.002*\"program\" + 0.002*\"server\" + 0.002*\"output\" + 0.002*\"law\" + 0.002*\"idea\"\n",
      "2022-07-28 13:46:08,967 - topic #6 (0.100): 0.063*\"ax\" + 0.005*\"max\" + 0.004*\"dos\" + 0.004*\"people\" + 0.003*\"god\" + 0.003*\"time\" + 0.002*\"hz\" + 0.002*\"question\" + 0.002*\"windows\" + 0.002*\"wrong\"\n",
      "2022-07-28 13:46:08,969 - topic #0 (0.100): 0.034*\"ax\" + 0.007*\"people\" + 0.005*\"god\" + 0.005*\"drive\" + 0.003*\"time\" + 0.003*\"windows\" + 0.003*\"card\" + 0.002*\"max\" + 0.002*\"bit\" + 0.002*\"file\"\n",
      "2022-07-28 13:46:08,972 - topic #8 (0.100): 0.006*\"people\" + 0.005*\"max\" + 0.004*\"program\" + 0.004*\"file\" + 0.003*\"time\" + 0.003*\"data\" + 0.002*\"image\" + 0.002*\"law\" + 0.002*\"president\" + 0.002*\"start\"\n",
      "2022-07-28 13:46:08,976 - topic #4 (0.100): 0.005*\"god\" + 0.005*\"people\" + 0.004*\"time\" + 0.002*\"key\" + 0.002*\"program\" + 0.002*\"jesus\" + 0.002*\"mb\" + 0.002*\"law\" + 0.002*\"power\" + 0.002*\"true\"\n",
      "2022-07-28 13:46:08,982 - topic diff=0.272754, rho=0.147442\n",
      "2022-07-28 13:46:08,997 - PROGRESS: pass 0, dispatched chunk #149 = documents up to #15000/18846, outstanding queue size 90\n",
      "2022-07-28 13:46:09,012 - PROGRESS: pass 0, dispatched chunk #150 = documents up to #15100/18846, outstanding queue size 87\n",
      "2022-07-28 13:46:09,050 - PROGRESS: pass 0, dispatched chunk #151 = documents up to #15200/18846, outstanding queue size 82\n",
      "2022-07-28 13:46:09,051 - PROGRESS: pass 0, dispatched chunk #152 = documents up to #15300/18846, outstanding queue size 83\n",
      "2022-07-28 13:46:09,051 - PROGRESS: pass 0, dispatched chunk #153 = documents up to #15400/18846, outstanding queue size 84\n",
      "2022-07-28 13:46:09,052 - PROGRESS: pass 0, dispatched chunk #154 = documents up to #15500/18846, outstanding queue size 85\n",
      "2022-07-28 13:46:09,053 - PROGRESS: pass 0, dispatched chunk #155 = documents up to #15600/18846, outstanding queue size 86\n",
      "2022-07-28 13:46:09,053 - PROGRESS: pass 0, dispatched chunk #156 = documents up to #15700/18846, outstanding queue size 87\n",
      "2022-07-28 13:46:09,054 - PROGRESS: pass 0, dispatched chunk #157 = documents up to #15800/18846, outstanding queue size 88\n",
      "2022-07-28 13:46:09,054 - PROGRESS: pass 0, dispatched chunk #158 = documents up to #15900/18846, outstanding queue size 89\n",
      "2022-07-28 13:46:09,055 - PROGRESS: pass 0, dispatched chunk #159 = documents up to #16000/18846, outstanding queue size 90\n",
      "2022-07-28 13:46:09,056 - PROGRESS: pass 0, dispatched chunk #160 = documents up to #16100/18846, outstanding queue size 91\n",
      "2022-07-28 13:46:09,056 - PROGRESS: pass 0, dispatched chunk #161 = documents up to #16200/18846, outstanding queue size 92\n",
      "2022-07-28 13:46:09,065 - PROGRESS: pass 0, dispatched chunk #162 = documents up to #16300/18846, outstanding queue size 91\n",
      "2022-07-28 13:46:09,075 - PROGRESS: pass 0, dispatched chunk #163 = documents up to #16400/18846, outstanding queue size 91\n",
      "2022-07-28 13:46:09,151 - merging changes from 1600 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:09,248 - topic #2 (0.100): 0.007*\"time\" + 0.005*\"people\" + 0.004*\"space\" + 0.002*\"read\" + 0.002*\"power\" + 0.002*\"key\" + 0.002*\"public\" + 0.002*\"phone\" + 0.002*\"data\" + 0.002*\"government\"\n",
      "2022-07-28 13:46:09,250 - topic #9 (0.100): 0.006*\"people\" + 0.003*\"window\" + 0.002*\"time\" + 0.002*\"question\" + 0.002*\"god\" + 0.002*\"true\" + 0.002*\"windows\" + 0.002*\"government\" + 0.002*\"lost\" + 0.001*\"life\"\n",
      "2022-07-28 13:46:09,252 - topic #4 (0.100): 0.007*\"db\" + 0.005*\"people\" + 0.005*\"god\" + 0.004*\"time\" + 0.002*\"key\" + 0.002*\"jesus\" + 0.002*\"program\" + 0.002*\"gun\" + 0.002*\"law\" + 0.002*\"mb\"\n",
      "2022-07-28 13:46:09,253 - topic #8 (0.100): 0.044*\"ax\" + 0.014*\"max\" + 0.005*\"people\" + 0.004*\"program\" + 0.003*\"file\" + 0.003*\"time\" + 0.002*\"data\" + 0.002*\"image\" + 0.002*\"president\" + 0.002*\"law\"\n",
      "2022-07-28 13:46:09,254 - topic #7 (0.100): 0.073*\"ax\" + 0.006*\"max\" + 0.005*\"people\" + 0.003*\"time\" + 0.003*\"car\" + 0.002*\"file\" + 0.002*\"jpeg\" + 0.002*\"question\" + 0.002*\"government\" + 0.002*\"law\"\n",
      "2022-07-28 13:46:09,256 - topic diff=0.118752, rho=0.128037\n",
      "2022-07-28 13:46:09,257 - PROGRESS: pass 0, dispatched chunk #164 = documents up to #16500/18846, outstanding queue size 89\n",
      "2022-07-28 13:46:09,268 - PROGRESS: pass 0, dispatched chunk #165 = documents up to #16600/18846, outstanding queue size 86\n",
      "2022-07-28 13:46:09,271 - PROGRESS: pass 0, dispatched chunk #166 = documents up to #16700/18846, outstanding queue size 87\n",
      "2022-07-28 13:46:09,272 - PROGRESS: pass 0, dispatched chunk #167 = documents up to #16800/18846, outstanding queue size 88\n",
      "2022-07-28 13:46:09,272 - PROGRESS: pass 0, dispatched chunk #168 = documents up to #16900/18846, outstanding queue size 89\n",
      "2022-07-28 13:46:09,273 - PROGRESS: pass 0, dispatched chunk #169 = documents up to #17000/18846, outstanding queue size 90\n",
      "2022-07-28 13:46:09,274 - PROGRESS: pass 0, dispatched chunk #170 = documents up to #17100/18846, outstanding queue size 91\n",
      "2022-07-28 13:46:09,291 - PROGRESS: pass 0, dispatched chunk #171 = documents up to #17200/18846, outstanding queue size 92\n",
      "2022-07-28 13:46:09,298 - PROGRESS: pass 0, dispatched chunk #172 = documents up to #17300/18846, outstanding queue size 92\n",
      "2022-07-28 13:46:09,308 - PROGRESS: pass 0, dispatched chunk #173 = documents up to #17400/18846, outstanding queue size 92\n",
      "2022-07-28 13:46:09,446 - merging changes from 1600 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:09,579 - topic #3 (0.100): 0.004*\"time\" + 0.004*\"people\" + 0.003*\"file\" + 0.003*\"god\" + 0.002*\"data\" + 0.002*\"program\" + 0.002*\"period\" + 0.002*\"server\" + 0.002*\"power\" + 0.002*\"law\"\n",
      "2022-07-28 13:46:09,594 - topic #5 (0.100): 0.013*\"ax\" + 0.005*\"max\" + 0.004*\"people\" + 0.004*\"time\" + 0.002*\"bit\" + 0.002*\"set\" + 0.002*\"file\" + 0.002*\"mail\" + 0.002*\"players\" + 0.002*\"program\"\n",
      "2022-07-28 13:46:09,596 - topic #9 (0.100): 0.006*\"people\" + 0.003*\"window\" + 0.003*\"time\" + 0.002*\"question\" + 0.002*\"god\" + 0.002*\"true\" + 0.002*\"lost\" + 0.002*\"windows\" + 0.002*\"life\" + 0.002*\"government\"\n",
      "2022-07-28 13:46:09,604 - topic #8 (0.100): 0.038*\"ax\" + 0.012*\"max\" + 0.005*\"people\" + 0.004*\"file\" + 0.004*\"program\" + 0.003*\"time\" + 0.002*\"president\" + 0.002*\"data\" + 0.002*\"image\" + 0.002*\"armenian\"\n",
      "2022-07-28 13:46:09,606 - topic #0 (0.100): 0.025*\"ax\" + 0.008*\"people\" + 0.005*\"god\" + 0.005*\"drive\" + 0.003*\"time\" + 0.003*\"windows\" + 0.003*\"card\" + 0.002*\"bit\" + 0.002*\"scsi\" + 0.002*\"file\"\n",
      "2022-07-28 13:46:09,607 - topic diff=0.098452, rho=0.113961\n",
      "2022-07-28 13:46:09,613 - PROGRESS: pass 0, dispatched chunk #174 = documents up to #17500/18846, outstanding queue size 83\n",
      "2022-07-28 13:46:09,625 - PROGRESS: pass 0, dispatched chunk #175 = documents up to #17600/18846, outstanding queue size 80\n",
      "2022-07-28 13:46:09,626 - PROGRESS: pass 0, dispatched chunk #176 = documents up to #17700/18846, outstanding queue size 81\n",
      "2022-07-28 13:46:09,627 - PROGRESS: pass 0, dispatched chunk #177 = documents up to #17800/18846, outstanding queue size 82\n",
      "2022-07-28 13:46:09,627 - PROGRESS: pass 0, dispatched chunk #178 = documents up to #17900/18846, outstanding queue size 83\n",
      "2022-07-28 13:46:09,628 - PROGRESS: pass 0, dispatched chunk #179 = documents up to #18000/18846, outstanding queue size 84\n",
      "2022-07-28 13:46:09,629 - PROGRESS: pass 0, dispatched chunk #180 = documents up to #18100/18846, outstanding queue size 85\n",
      "2022-07-28 13:46:09,629 - PROGRESS: pass 0, dispatched chunk #181 = documents up to #18200/18846, outstanding queue size 86\n",
      "2022-07-28 13:46:09,630 - PROGRESS: pass 0, dispatched chunk #182 = documents up to #18300/18846, outstanding queue size 87\n",
      "2022-07-28 13:46:09,631 - PROGRESS: pass 0, dispatched chunk #183 = documents up to #18400/18846, outstanding queue size 88\n",
      "2022-07-28 13:46:09,664 - PROGRESS: pass 0, dispatched chunk #184 = documents up to #18500/18846, outstanding queue size 88\n",
      "2022-07-28 13:46:09,666 - PROGRESS: pass 0, dispatched chunk #185 = documents up to #18600/18846, outstanding queue size 89\n",
      "2022-07-28 13:46:09,669 - PROGRESS: pass 0, dispatched chunk #186 = documents up to #18700/18846, outstanding queue size 90\n",
      "2022-07-28 13:46:09,688 - PROGRESS: pass 0, dispatched chunk #187 = documents up to #18800/18846, outstanding queue size 90\n",
      "2022-07-28 13:46:09,691 - PROGRESS: pass 0, dispatched chunk #188 = documents up to #18846/18846, outstanding queue size 91\n",
      "2022-07-28 13:46:10,305 - merging changes from 1500 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:10,382 - topic #7 (0.100): 0.061*\"ax\" + 0.005*\"max\" + 0.005*\"people\" + 0.004*\"car\" + 0.004*\"jpeg\" + 0.003*\"time\" + 0.003*\"file\" + 0.002*\"government\" + 0.002*\"files\" + 0.002*\"law\"\n",
      "2022-07-28 13:46:10,400 - topic #4 (0.100): 0.006*\"god\" + 0.006*\"db\" + 0.005*\"people\" + 0.004*\"time\" + 0.003*\"key\" + 0.002*\"jesus\" + 0.002*\"armenians\" + 0.002*\"gun\" + 0.002*\"program\" + 0.002*\"law\"\n",
      "2022-07-28 13:46:10,412 - topic #6 (0.100): 0.049*\"ax\" + 0.004*\"dos\" + 0.004*\"max\" + 0.004*\"people\" + 0.003*\"hz\" + 0.003*\"god\" + 0.002*\"time\" + 0.002*\"question\" + 0.002*\"water\" + 0.002*\"windows\"\n",
      "2022-07-28 13:46:10,413 - topic #0 (0.100): 0.023*\"ax\" + 0.008*\"people\" + 0.005*\"god\" + 0.005*\"drive\" + 0.003*\"time\" + 0.003*\"windows\" + 0.003*\"card\" + 0.002*\"scsi\" + 0.002*\"bit\" + 0.002*\"file\"\n",
      "2022-07-28 13:46:10,424 - topic #2 (0.100): 0.007*\"time\" + 0.005*\"people\" + 0.005*\"space\" + 0.002*\"power\" + 0.002*\"read\" + 0.002*\"key\" + 0.002*\"government\" + 0.002*\"public\" + 0.002*\"file\" + 0.002*\"real\"\n",
      "2022-07-28 13:46:10,426 - topic diff=0.097234, rho=0.103695\n",
      "2022-07-28 13:46:10,612 - -10.880 per-word bound, 1884.7 perplexity estimate based on a held-out corpus of 46 documents with 2932 words\n",
      "2022-07-28 13:46:10,747 - merging changes from 1546 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:10,790 - topic #2 (0.100): 0.007*\"time\" + 0.005*\"people\" + 0.005*\"space\" + 0.002*\"power\" + 0.002*\"read\" + 0.002*\"government\" + 0.002*\"key\" + 0.002*\"public\" + 0.002*\"real\" + 0.002*\"data\"\n",
      "2022-07-28 13:46:10,792 - topic #9 (0.100): 0.006*\"people\" + 0.003*\"window\" + 0.003*\"time\" + 0.002*\"question\" + 0.002*\"true\" + 0.002*\"god\" + 0.002*\"lost\" + 0.002*\"government\" + 0.002*\"life\" + 0.002*\"church\"\n",
      "2022-07-28 13:46:10,795 - topic #0 (0.100): 0.021*\"ax\" + 0.008*\"people\" + 0.006*\"god\" + 0.005*\"drive\" + 0.003*\"time\" + 0.003*\"windows\" + 0.003*\"card\" + 0.003*\"scsi\" + 0.002*\"bit\" + 0.002*\"mb\"\n",
      "2022-07-28 13:46:10,797 - topic #6 (0.100): 0.047*\"ax\" + 0.006*\"dos\" + 0.004*\"max\" + 0.004*\"people\" + 0.003*\"hz\" + 0.003*\"god\" + 0.002*\"time\" + 0.002*\"windows\" + 0.002*\"water\" + 0.002*\"question\"\n",
      "2022-07-28 13:46:10,799 - topic #4 (0.100): 0.006*\"god\" + 0.005*\"people\" + 0.005*\"db\" + 0.004*\"time\" + 0.003*\"key\" + 0.002*\"jesus\" + 0.002*\"gun\" + 0.002*\"armenians\" + 0.002*\"law\" + 0.002*\"program\"\n",
      "2022-07-28 13:46:10,800 - topic diff=0.085511, rho=0.096225\n",
      "2022-07-28 13:46:10,896 - -10.726 per-word bound, 1693.8 perplexity estimate based on a held-out corpus of 46 documents with 2932 words\n",
      "2022-07-28 13:46:11,072 - merging changes from 6600 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:11,103 - topic #1 (0.100): 0.006*\"game\" + 0.005*\"time\" + 0.004*\"software\" + 0.004*\"list\" + 0.004*\"dos\" + 0.004*\"windows\" + 0.003*\"people\" + 0.003*\"mail\" + 0.003*\"games\" + 0.003*\"bit\"\n",
      "2022-07-28 13:46:11,104 - topic #9 (0.100): 0.007*\"people\" + 0.003*\"window\" + 0.003*\"time\" + 0.002*\"question\" + 0.002*\"true\" + 0.002*\"lost\" + 0.002*\"god\" + 0.002*\"government\" + 0.002*\"life\" + 0.002*\"church\"\n",
      "2022-07-28 13:46:11,105 - topic #7 (0.100): 0.099*\"ax\" + 0.008*\"max\" + 0.004*\"people\" + 0.004*\"car\" + 0.003*\"time\" + 0.003*\"jpeg\" + 0.002*\"file\" + 0.002*\"di\" + 0.002*\"government\" + 0.002*\"law\"\n",
      "2022-07-28 13:46:11,107 - topic #6 (0.100): 0.059*\"ax\" + 0.006*\"dos\" + 0.005*\"max\" + 0.003*\"people\" + 0.003*\"hz\" + 0.003*\"god\" + 0.002*\"time\" + 0.002*\"windows\" + 0.002*\"water\" + 0.002*\"question\"\n",
      "2022-07-28 13:46:11,108 - topic #8 (0.100): 0.145*\"ax\" + 0.018*\"max\" + 0.004*\"people\" + 0.003*\"program\" + 0.003*\"file\" + 0.002*\"time\" + 0.002*\"president\" + 0.002*\"image\" + 0.002*\"armenian\" + 0.002*\"data\"\n",
      "2022-07-28 13:46:11,109 - topic diff=0.072815, rho=0.089999\n",
      "2022-07-28 13:46:11,186 - -10.710 per-word bound, 1675.2 perplexity estimate based on a held-out corpus of 46 documents with 2932 words\n",
      "2022-07-28 13:46:11,187 - PROGRESS: pass 1, dispatched chunk #0 = documents up to #100/18846, outstanding queue size 1\n",
      "2022-07-28 13:46:11,189 - PROGRESS: pass 1, dispatched chunk #1 = documents up to #200/18846, outstanding queue size 2\n",
      "2022-07-28 13:46:11,190 - PROGRESS: pass 1, dispatched chunk #2 = documents up to #300/18846, outstanding queue size 3\n",
      "2022-07-28 13:46:11,190 - PROGRESS: pass 1, dispatched chunk #3 = documents up to #400/18846, outstanding queue size 4\n",
      "2022-07-28 13:46:11,191 - PROGRESS: pass 1, dispatched chunk #4 = documents up to #500/18846, outstanding queue size 5\n",
      "2022-07-28 13:46:11,191 - PROGRESS: pass 1, dispatched chunk #5 = documents up to #600/18846, outstanding queue size 6\n",
      "2022-07-28 13:46:11,191 - PROGRESS: pass 1, dispatched chunk #6 = documents up to #700/18846, outstanding queue size 7\n",
      "2022-07-28 13:46:11,193 - PROGRESS: pass 1, dispatched chunk #7 = documents up to #800/18846, outstanding queue size 8\n",
      "2022-07-28 13:46:11,194 - PROGRESS: pass 1, dispatched chunk #8 = documents up to #900/18846, outstanding queue size 9\n",
      "2022-07-28 13:46:11,194 - PROGRESS: pass 1, dispatched chunk #9 = documents up to #1000/18846, outstanding queue size 10\n",
      "2022-07-28 13:46:11,194 - PROGRESS: pass 1, dispatched chunk #10 = documents up to #1100/18846, outstanding queue size 11\n",
      "2022-07-28 13:46:11,194 - PROGRESS: pass 1, dispatched chunk #11 = documents up to #1200/18846, outstanding queue size 12\n",
      "2022-07-28 13:46:11,195 - PROGRESS: pass 1, dispatched chunk #12 = documents up to #1300/18846, outstanding queue size 13\n",
      "2022-07-28 13:46:11,195 - PROGRESS: pass 1, dispatched chunk #13 = documents up to #1400/18846, outstanding queue size 14\n",
      "2022-07-28 13:46:11,197 - PROGRESS: pass 1, dispatched chunk #14 = documents up to #1500/18846, outstanding queue size 15\n",
      "2022-07-28 13:46:11,197 - PROGRESS: pass 1, dispatched chunk #15 = documents up to #1600/18846, outstanding queue size 16\n",
      "2022-07-28 13:46:11,198 - PROGRESS: pass 1, dispatched chunk #16 = documents up to #1700/18846, outstanding queue size 17\n",
      "2022-07-28 13:46:11,198 - PROGRESS: pass 1, dispatched chunk #17 = documents up to #1800/18846, outstanding queue size 18\n",
      "2022-07-28 13:46:11,198 - PROGRESS: pass 1, dispatched chunk #18 = documents up to #1900/18846, outstanding queue size 19\n",
      "2022-07-28 13:46:11,199 - PROGRESS: pass 1, dispatched chunk #19 = documents up to #2000/18846, outstanding queue size 20\n",
      "2022-07-28 13:46:11,199 - PROGRESS: pass 1, dispatched chunk #20 = documents up to #2100/18846, outstanding queue size 21\n",
      "2022-07-28 13:46:11,201 - PROGRESS: pass 1, dispatched chunk #21 = documents up to #2200/18846, outstanding queue size 22\n",
      "2022-07-28 13:46:11,202 - PROGRESS: pass 1, dispatched chunk #22 = documents up to #2300/18846, outstanding queue size 23\n",
      "2022-07-28 13:46:11,202 - PROGRESS: pass 1, dispatched chunk #23 = documents up to #2400/18846, outstanding queue size 24\n",
      "2022-07-28 13:46:11,203 - PROGRESS: pass 1, dispatched chunk #24 = documents up to #2500/18846, outstanding queue size 25\n",
      "2022-07-28 13:46:11,203 - PROGRESS: pass 1, dispatched chunk #25 = documents up to #2600/18846, outstanding queue size 26\n",
      "2022-07-28 13:46:11,203 - PROGRESS: pass 1, dispatched chunk #26 = documents up to #2700/18846, outstanding queue size 27\n",
      "2022-07-28 13:46:11,204 - PROGRESS: pass 1, dispatched chunk #27 = documents up to #2800/18846, outstanding queue size 28\n",
      "2022-07-28 13:46:11,206 - PROGRESS: pass 1, dispatched chunk #28 = documents up to #2900/18846, outstanding queue size 29\n",
      "2022-07-28 13:46:11,207 - PROGRESS: pass 1, dispatched chunk #29 = documents up to #3000/18846, outstanding queue size 30\n",
      "2022-07-28 13:46:11,207 - PROGRESS: pass 1, dispatched chunk #30 = documents up to #3100/18846, outstanding queue size 31\n",
      "2022-07-28 13:46:11,207 - PROGRESS: pass 1, dispatched chunk #31 = documents up to #3200/18846, outstanding queue size 32\n",
      "2022-07-28 13:46:11,208 - PROGRESS: pass 1, dispatched chunk #32 = documents up to #3300/18846, outstanding queue size 33\n",
      "2022-07-28 13:46:11,208 - PROGRESS: pass 1, dispatched chunk #33 = documents up to #3400/18846, outstanding queue size 34\n",
      "2022-07-28 13:46:11,209 - PROGRESS: pass 1, dispatched chunk #34 = documents up to #3500/18846, outstanding queue size 35\n",
      "2022-07-28 13:46:11,214 - PROGRESS: pass 1, dispatched chunk #35 = documents up to #3600/18846, outstanding queue size 36\n",
      "2022-07-28 13:46:11,219 - PROGRESS: pass 1, dispatched chunk #36 = documents up to #3700/18846, outstanding queue size 37\n",
      "2022-07-28 13:46:11,228 - PROGRESS: pass 1, dispatched chunk #37 = documents up to #3800/18846, outstanding queue size 38\n",
      "2022-07-28 13:46:11,233 - PROGRESS: pass 1, dispatched chunk #38 = documents up to #3900/18846, outstanding queue size 39\n",
      "2022-07-28 13:46:11,238 - PROGRESS: pass 1, dispatched chunk #39 = documents up to #4000/18846, outstanding queue size 40\n",
      "2022-07-28 13:46:11,243 - PROGRESS: pass 1, dispatched chunk #40 = documents up to #4100/18846, outstanding queue size 41\n",
      "2022-07-28 13:46:11,246 - PROGRESS: pass 1, dispatched chunk #41 = documents up to #4200/18846, outstanding queue size 42\n",
      "2022-07-28 13:46:11,273 - PROGRESS: pass 1, dispatched chunk #42 = documents up to #4300/18846, outstanding queue size 43\n",
      "2022-07-28 13:46:11,296 - PROGRESS: pass 1, dispatched chunk #43 = documents up to #4400/18846, outstanding queue size 39\n",
      "2022-07-28 13:46:11,297 - PROGRESS: pass 1, dispatched chunk #44 = documents up to #4500/18846, outstanding queue size 40\n",
      "2022-07-28 13:46:11,303 - PROGRESS: pass 1, dispatched chunk #45 = documents up to #4600/18846, outstanding queue size 41\n",
      "2022-07-28 13:46:11,308 - PROGRESS: pass 1, dispatched chunk #46 = documents up to #4700/18846, outstanding queue size 42\n",
      "2022-07-28 13:46:11,314 - PROGRESS: pass 1, dispatched chunk #47 = documents up to #4800/18846, outstanding queue size 43\n",
      "2022-07-28 13:46:11,325 - PROGRESS: pass 1, dispatched chunk #48 = documents up to #4900/18846, outstanding queue size 42\n",
      "2022-07-28 13:46:11,352 - PROGRESS: pass 1, dispatched chunk #49 = documents up to #5000/18846, outstanding queue size 42\n",
      "2022-07-28 13:46:11,354 - PROGRESS: pass 1, dispatched chunk #50 = documents up to #5100/18846, outstanding queue size 43\n",
      "2022-07-28 13:46:11,446 - PROGRESS: pass 1, dispatched chunk #51 = documents up to #5200/18846, outstanding queue size 40\n",
      "2022-07-28 13:46:11,450 - PROGRESS: pass 1, dispatched chunk #52 = documents up to #5300/18846, outstanding queue size 41\n",
      "2022-07-28 13:46:11,471 - PROGRESS: pass 1, dispatched chunk #53 = documents up to #5400/18846, outstanding queue size 41\n",
      "2022-07-28 13:46:11,472 - PROGRESS: pass 1, dispatched chunk #54 = documents up to #5500/18846, outstanding queue size 42\n",
      "2022-07-28 13:46:11,515 - PROGRESS: pass 1, dispatched chunk #55 = documents up to #5600/18846, outstanding queue size 43\n",
      "2022-07-28 13:46:11,527 - PROGRESS: pass 1, dispatched chunk #56 = documents up to #5700/18846, outstanding queue size 44\n",
      "2022-07-28 13:46:11,530 - PROGRESS: pass 1, dispatched chunk #57 = documents up to #5800/18846, outstanding queue size 45\n",
      "2022-07-28 13:46:11,561 - PROGRESS: pass 1, dispatched chunk #58 = documents up to #5900/18846, outstanding queue size 45\n",
      "2022-07-28 13:46:11,756 - merging changes from 1500 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:11,933 - topic #0 (0.100): 0.018*\"ax\" + 0.008*\"people\" + 0.006*\"god\" + 0.005*\"drive\" + 0.003*\"card\" + 0.003*\"windows\" + 0.003*\"time\" + 0.003*\"scsi\" + 0.002*\"bit\" + 0.002*\"mb\"\n",
      "2022-07-28 13:46:11,942 - topic #5 (0.100): 0.009*\"ax\" + 0.004*\"people\" + 0.004*\"time\" + 0.004*\"max\" + 0.002*\"set\" + 0.002*\"bit\" + 0.002*\"players\" + 0.002*\"file\" + 0.002*\"mail\" + 0.002*\"armenian\"\n",
      "2022-07-28 13:46:11,948 - topic #1 (0.100): 0.006*\"game\" + 0.005*\"time\" + 0.004*\"software\" + 0.004*\"list\" + 0.004*\"windows\" + 0.004*\"dos\" + 0.003*\"mail\" + 0.003*\"people\" + 0.003*\"games\" + 0.003*\"bit\"\n",
      "2022-07-28 13:46:11,952 - topic #8 (0.100): 0.136*\"ax\" + 0.017*\"max\" + 0.004*\"people\" + 0.003*\"program\" + 0.003*\"file\" + 0.003*\"president\" + 0.002*\"time\" + 0.002*\"armenian\" + 0.002*\"image\" + 0.002*\"university\"\n",
      "2022-07-28 13:46:11,955 - topic #3 (0.100): 0.004*\"time\" + 0.004*\"people\" + 0.003*\"file\" + 0.002*\"god\" + 0.002*\"data\" + 0.002*\"period\" + 0.002*\"server\" + 0.002*\"det\" + 0.002*\"program\" + 0.002*\"pit\"\n",
      "2022-07-28 13:46:11,960 - topic diff=0.058537, rho=0.072460\n",
      "2022-07-28 13:46:11,965 - PROGRESS: pass 1, dispatched chunk #59 = documents up to #6000/18846, outstanding queue size 45\n",
      "2022-07-28 13:46:11,970 - PROGRESS: pass 1, dispatched chunk #60 = documents up to #6100/18846, outstanding queue size 45\n",
      "2022-07-28 13:46:11,979 - PROGRESS: pass 1, dispatched chunk #61 = documents up to #6200/18846, outstanding queue size 46\n",
      "2022-07-28 13:46:11,980 - PROGRESS: pass 1, dispatched chunk #62 = documents up to #6300/18846, outstanding queue size 47\n",
      "2022-07-28 13:46:11,980 - PROGRESS: pass 1, dispatched chunk #63 = documents up to #6400/18846, outstanding queue size 48\n",
      "2022-07-28 13:46:11,983 - PROGRESS: pass 1, dispatched chunk #64 = documents up to #6500/18846, outstanding queue size 49\n",
      "2022-07-28 13:46:11,984 - PROGRESS: pass 1, dispatched chunk #65 = documents up to #6600/18846, outstanding queue size 50\n",
      "2022-07-28 13:46:11,984 - PROGRESS: pass 1, dispatched chunk #66 = documents up to #6700/18846, outstanding queue size 51\n",
      "2022-07-28 13:46:11,985 - PROGRESS: pass 1, dispatched chunk #67 = documents up to #6800/18846, outstanding queue size 52\n",
      "2022-07-28 13:46:11,992 - PROGRESS: pass 1, dispatched chunk #68 = documents up to #6900/18846, outstanding queue size 53\n",
      "2022-07-28 13:46:12,014 - PROGRESS: pass 1, dispatched chunk #69 = documents up to #7000/18846, outstanding queue size 52\n",
      "2022-07-28 13:46:12,033 - PROGRESS: pass 1, dispatched chunk #70 = documents up to #7100/18846, outstanding queue size 49\n",
      "2022-07-28 13:46:12,037 - PROGRESS: pass 1, dispatched chunk #71 = documents up to #7200/18846, outstanding queue size 49\n",
      "2022-07-28 13:46:12,057 - PROGRESS: pass 1, dispatched chunk #72 = documents up to #7300/18846, outstanding queue size 48\n",
      "2022-07-28 13:46:12,059 - PROGRESS: pass 1, dispatched chunk #73 = documents up to #7400/18846, outstanding queue size 49\n",
      "2022-07-28 13:46:12,060 - PROGRESS: pass 1, dispatched chunk #74 = documents up to #7500/18846, outstanding queue size 50\n",
      "2022-07-28 13:46:12,060 - PROGRESS: pass 1, dispatched chunk #75 = documents up to #7600/18846, outstanding queue size 51\n",
      "2022-07-28 13:46:12,129 - PROGRESS: pass 1, dispatched chunk #76 = documents up to #7700/18846, outstanding queue size 51\n",
      "2022-07-28 13:46:12,140 - PROGRESS: pass 1, dispatched chunk #77 = documents up to #7800/18846, outstanding queue size 52\n",
      "2022-07-28 13:46:12,166 - PROGRESS: pass 1, dispatched chunk #78 = documents up to #7900/18846, outstanding queue size 52\n",
      "2022-07-28 13:46:12,182 - PROGRESS: pass 1, dispatched chunk #79 = documents up to #8000/18846, outstanding queue size 53\n",
      "2022-07-28 13:46:12,184 - PROGRESS: pass 1, dispatched chunk #80 = documents up to #8100/18846, outstanding queue size 54\n",
      "2022-07-28 13:46:12,231 - PROGRESS: pass 1, dispatched chunk #81 = documents up to #8200/18846, outstanding queue size 54\n",
      "2022-07-28 13:46:12,236 - PROGRESS: pass 1, dispatched chunk #82 = documents up to #8300/18846, outstanding queue size 55\n",
      "2022-07-28 13:46:12,395 - merging changes from 1800 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:12,628 - topic #0 (0.100): 0.017*\"ax\" + 0.008*\"people\" + 0.006*\"god\" + 0.005*\"drive\" + 0.003*\"card\" + 0.003*\"time\" + 0.003*\"windows\" + 0.003*\"scsi\" + 0.002*\"mb\" + 0.002*\"bit\"\n",
      "2022-07-28 13:46:12,630 - topic #2 (0.100): 0.007*\"time\" + 0.005*\"people\" + 0.005*\"space\" + 0.003*\"power\" + 0.002*\"government\" + 0.002*\"read\" + 0.002*\"key\" + 0.002*\"public\" + 0.002*\"real\" + 0.002*\"data\"\n",
      "2022-07-28 13:46:12,656 - topic #3 (0.100): 0.004*\"time\" + 0.004*\"people\" + 0.002*\"file\" + 0.002*\"god\" + 0.002*\"data\" + 0.002*\"period\" + 0.002*\"server\" + 0.002*\"program\" + 0.002*\"det\" + 0.002*\"play\"\n",
      "2022-07-28 13:46:12,673 - topic #6 (0.100): 0.051*\"ax\" + 0.006*\"dos\" + 0.004*\"max\" + 0.003*\"people\" + 0.003*\"hz\" + 0.002*\"god\" + 0.002*\"time\" + 0.002*\"water\" + 0.002*\"question\" + 0.002*\"windows\"\n",
      "2022-07-28 13:46:12,677 - topic #5 (0.100): 0.009*\"ax\" + 0.004*\"people\" + 0.004*\"time\" + 0.004*\"max\" + 0.002*\"set\" + 0.002*\"bit\" + 0.002*\"players\" + 0.002*\"file\" + 0.002*\"mail\" + 0.002*\"armenian\"\n",
      "2022-07-28 13:46:12,682 - topic diff=0.083590, rho=0.072460\n",
      "2022-07-28 13:46:12,688 - PROGRESS: pass 1, dispatched chunk #83 = documents up to #8400/18846, outstanding queue size 51\n",
      "2022-07-28 13:46:12,701 - PROGRESS: pass 1, dispatched chunk #84 = documents up to #8500/18846, outstanding queue size 51\n",
      "2022-07-28 13:46:12,709 - PROGRESS: pass 1, dispatched chunk #85 = documents up to #8600/18846, outstanding queue size 52\n",
      "2022-07-28 13:46:12,710 - PROGRESS: pass 1, dispatched chunk #86 = documents up to #8700/18846, outstanding queue size 53\n",
      "2022-07-28 13:46:12,715 - PROGRESS: pass 1, dispatched chunk #87 = documents up to #8800/18846, outstanding queue size 54\n",
      "2022-07-28 13:46:12,716 - PROGRESS: pass 1, dispatched chunk #88 = documents up to #8900/18846, outstanding queue size 55\n",
      "2022-07-28 13:46:12,716 - PROGRESS: pass 1, dispatched chunk #89 = documents up to #9000/18846, outstanding queue size 56\n",
      "2022-07-28 13:46:12,717 - PROGRESS: pass 1, dispatched chunk #90 = documents up to #9100/18846, outstanding queue size 57\n",
      "2022-07-28 13:46:12,723 - PROGRESS: pass 1, dispatched chunk #91 = documents up to #9200/18846, outstanding queue size 58\n",
      "2022-07-28 13:46:12,723 - PROGRESS: pass 1, dispatched chunk #92 = documents up to #9300/18846, outstanding queue size 59\n",
      "2022-07-28 13:46:12,724 - PROGRESS: pass 1, dispatched chunk #93 = documents up to #9400/18846, outstanding queue size 60\n",
      "2022-07-28 13:46:12,725 - PROGRESS: pass 1, dispatched chunk #94 = documents up to #9500/18846, outstanding queue size 61\n",
      "2022-07-28 13:46:12,726 - PROGRESS: pass 1, dispatched chunk #95 = documents up to #9600/18846, outstanding queue size 62\n",
      "2022-07-28 13:46:12,727 - PROGRESS: pass 1, dispatched chunk #96 = documents up to #9700/18846, outstanding queue size 63\n",
      "2022-07-28 13:46:12,727 - PROGRESS: pass 1, dispatched chunk #97 = documents up to #9800/18846, outstanding queue size 64\n",
      "2022-07-28 13:46:12,786 - PROGRESS: pass 1, dispatched chunk #98 = documents up to #9900/18846, outstanding queue size 65\n",
      "2022-07-28 13:46:12,906 - PROGRESS: pass 1, dispatched chunk #99 = documents up to #10000/18846, outstanding queue size 64\n",
      "2022-07-28 13:46:12,906 - PROGRESS: pass 1, dispatched chunk #100 = documents up to #10100/18846, outstanding queue size 65\n",
      "2022-07-28 13:46:12,907 - PROGRESS: pass 1, dispatched chunk #101 = documents up to #10200/18846, outstanding queue size 66\n",
      "2022-07-28 13:46:12,907 - PROGRESS: pass 1, dispatched chunk #102 = documents up to #10300/18846, outstanding queue size 67\n",
      "2022-07-28 13:46:13,013 - PROGRESS: pass 1, dispatched chunk #103 = documents up to #10400/18846, outstanding queue size 65\n",
      "2022-07-28 13:46:13,014 - PROGRESS: pass 1, dispatched chunk #104 = documents up to #10500/18846, outstanding queue size 66\n",
      "2022-07-28 13:46:13,019 - PROGRESS: pass 1, dispatched chunk #105 = documents up to #10600/18846, outstanding queue size 67\n",
      "2022-07-28 13:46:13,040 - PROGRESS: pass 1, dispatched chunk #106 = documents up to #10700/18846, outstanding queue size 66\n",
      "2022-07-28 13:46:13,061 - PROGRESS: pass 1, dispatched chunk #107 = documents up to #10800/18846, outstanding queue size 65\n",
      "2022-07-28 13:46:13,065 - PROGRESS: pass 1, dispatched chunk #108 = documents up to #10900/18846, outstanding queue size 66\n",
      "2022-07-28 13:46:13,128 - PROGRESS: pass 1, dispatched chunk #109 = documents up to #11000/18846, outstanding queue size 66\n",
      "2022-07-28 13:46:13,133 - PROGRESS: pass 1, dispatched chunk #110 = documents up to #11100/18846, outstanding queue size 66\n",
      "2022-07-28 13:46:13,158 - PROGRESS: pass 1, dispatched chunk #111 = documents up to #11200/18846, outstanding queue size 66\n",
      "2022-07-28 13:46:13,164 - PROGRESS: pass 1, dispatched chunk #112 = documents up to #11300/18846, outstanding queue size 67\n",
      "2022-07-28 13:46:13,175 - PROGRESS: pass 1, dispatched chunk #113 = documents up to #11400/18846, outstanding queue size 68\n",
      "2022-07-28 13:46:13,179 - PROGRESS: pass 1, dispatched chunk #114 = documents up to #11500/18846, outstanding queue size 69\n",
      "2022-07-28 13:46:13,182 - PROGRESS: pass 1, dispatched chunk #115 = documents up to #11600/18846, outstanding queue size 70\n",
      "2022-07-28 13:46:13,313 - merging changes from 1500 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:13,459 - topic #6 (0.100): 0.048*\"ax\" + 0.006*\"dos\" + 0.004*\"max\" + 0.004*\"hz\" + 0.003*\"people\" + 0.002*\"god\" + 0.002*\"time\" + 0.002*\"water\" + 0.002*\"question\" + 0.002*\"windows\"\n",
      "2022-07-28 13:46:13,465 - topic #1 (0.100): 0.005*\"game\" + 0.005*\"software\" + 0.004*\"time\" + 0.004*\"windows\" + 0.004*\"list\" + 0.004*\"mail\" + 0.004*\"dos\" + 0.003*\"file\" + 0.003*\"ftp\" + 0.003*\"bit\"\n",
      "2022-07-28 13:46:13,473 - topic #7 (0.100): 0.082*\"ax\" + 0.007*\"max\" + 0.006*\"jpeg\" + 0.004*\"car\" + 0.004*\"people\" + 0.003*\"time\" + 0.003*\"file\" + 0.002*\"image\" + 0.002*\"files\" + 0.002*\"bit\"\n",
      "2022-07-28 13:46:13,474 - topic #8 (0.100): 0.214*\"ax\" + 0.022*\"max\" + 0.004*\"file\" + 0.004*\"people\" + 0.004*\"program\" + 0.002*\"president\" + 0.002*\"time\" + 0.002*\"output\" + 0.002*\"armenian\" + 0.002*\"turkish\"\n",
      "2022-07-28 13:46:13,507 - topic #3 (0.100): 0.004*\"time\" + 0.004*\"people\" + 0.003*\"file\" + 0.002*\"god\" + 0.002*\"period\" + 0.002*\"data\" + 0.002*\"server\" + 0.002*\"program\" + 0.002*\"det\" + 0.002*\"play\"\n",
      "2022-07-28 13:46:13,509 - topic diff=0.089284, rho=0.072460\n",
      "2022-07-28 13:46:13,514 - PROGRESS: pass 1, dispatched chunk #116 = documents up to #11700/18846, outstanding queue size 69\n",
      "2022-07-28 13:46:13,522 - PROGRESS: pass 1, dispatched chunk #117 = documents up to #11800/18846, outstanding queue size 68\n",
      "2022-07-28 13:46:13,523 - PROGRESS: pass 1, dispatched chunk #118 = documents up to #11900/18846, outstanding queue size 69\n",
      "2022-07-28 13:46:13,523 - PROGRESS: pass 1, dispatched chunk #119 = documents up to #12000/18846, outstanding queue size 70\n",
      "2022-07-28 13:46:13,525 - PROGRESS: pass 1, dispatched chunk #120 = documents up to #12100/18846, outstanding queue size 71\n",
      "2022-07-28 13:46:13,526 - PROGRESS: pass 1, dispatched chunk #121 = documents up to #12200/18846, outstanding queue size 72\n",
      "2022-07-28 13:46:13,527 - PROGRESS: pass 1, dispatched chunk #122 = documents up to #12300/18846, outstanding queue size 73\n",
      "2022-07-28 13:46:13,529 - PROGRESS: pass 1, dispatched chunk #123 = documents up to #12400/18846, outstanding queue size 74\n",
      "2022-07-28 13:46:13,530 - PROGRESS: pass 1, dispatched chunk #124 = documents up to #12500/18846, outstanding queue size 75\n",
      "2022-07-28 13:46:13,531 - PROGRESS: pass 1, dispatched chunk #125 = documents up to #12600/18846, outstanding queue size 76\n",
      "2022-07-28 13:46:13,532 - PROGRESS: pass 1, dispatched chunk #126 = documents up to #12700/18846, outstanding queue size 77\n",
      "2022-07-28 13:46:13,533 - PROGRESS: pass 1, dispatched chunk #127 = documents up to #12800/18846, outstanding queue size 78\n",
      "2022-07-28 13:46:13,556 - PROGRESS: pass 1, dispatched chunk #128 = documents up to #12900/18846, outstanding queue size 79\n",
      "2022-07-28 13:46:13,595 - PROGRESS: pass 1, dispatched chunk #129 = documents up to #13000/18846, outstanding queue size 80\n",
      "2022-07-28 13:46:13,607 - PROGRESS: pass 1, dispatched chunk #130 = documents up to #13100/18846, outstanding queue size 81\n",
      "2022-07-28 13:46:13,614 - PROGRESS: pass 1, dispatched chunk #131 = documents up to #13200/18846, outstanding queue size 82\n",
      "2022-07-28 13:46:13,636 - PROGRESS: pass 1, dispatched chunk #132 = documents up to #13300/18846, outstanding queue size 83\n",
      "2022-07-28 13:46:13,649 - PROGRESS: pass 1, dispatched chunk #133 = documents up to #13400/18846, outstanding queue size 83\n",
      "2022-07-28 13:46:13,684 - PROGRESS: pass 1, dispatched chunk #134 = documents up to #13500/18846, outstanding queue size 83\n",
      "2022-07-28 13:46:13,685 - PROGRESS: pass 1, dispatched chunk #135 = documents up to #13600/18846, outstanding queue size 84\n",
      "2022-07-28 13:46:13,742 - PROGRESS: pass 1, dispatched chunk #136 = documents up to #13700/18846, outstanding queue size 85\n",
      "2022-07-28 13:46:13,774 - PROGRESS: pass 1, dispatched chunk #137 = documents up to #13800/18846, outstanding queue size 86\n",
      "2022-07-28 13:46:13,861 - PROGRESS: pass 1, dispatched chunk #138 = documents up to #13900/18846, outstanding queue size 85\n",
      "2022-07-28 13:46:13,881 - PROGRESS: pass 1, dispatched chunk #139 = documents up to #14000/18846, outstanding queue size 85\n",
      "2022-07-28 13:46:13,943 - PROGRESS: pass 1, dispatched chunk #140 = documents up to #14100/18846, outstanding queue size 85\n",
      "2022-07-28 13:46:13,947 - PROGRESS: pass 1, dispatched chunk #141 = documents up to #14200/18846, outstanding queue size 86\n",
      "2022-07-28 13:46:13,949 - PROGRESS: pass 1, dispatched chunk #142 = documents up to #14300/18846, outstanding queue size 87\n",
      "2022-07-28 13:46:14,001 - PROGRESS: pass 1, dispatched chunk #143 = documents up to #14400/18846, outstanding queue size 85\n",
      "2022-07-28 13:46:14,020 - PROGRESS: pass 1, dispatched chunk #144 = documents up to #14500/18846, outstanding queue size 86\n",
      "2022-07-28 13:46:14,034 - PROGRESS: pass 1, dispatched chunk #145 = documents up to #14600/18846, outstanding queue size 87\n",
      "2022-07-28 13:46:14,070 - PROGRESS: pass 1, dispatched chunk #146 = documents up to #14700/18846, outstanding queue size 88\n",
      "2022-07-28 13:46:14,088 - PROGRESS: pass 1, dispatched chunk #147 = documents up to #14800/18846, outstanding queue size 88\n",
      "2022-07-28 13:46:14,113 - PROGRESS: pass 1, dispatched chunk #148 = documents up to #14900/18846, outstanding queue size 88\n",
      "2022-07-28 13:46:14,153 - PROGRESS: pass 1, dispatched chunk #149 = documents up to #15000/18846, outstanding queue size 89\n",
      "2022-07-28 13:46:14,156 - PROGRESS: pass 1, dispatched chunk #150 = documents up to #15100/18846, outstanding queue size 90\n",
      "2022-07-28 13:46:14,180 - PROGRESS: pass 1, dispatched chunk #151 = documents up to #15200/18846, outstanding queue size 90\n",
      "2022-07-28 13:46:14,184 - PROGRESS: pass 1, dispatched chunk #152 = documents up to #15300/18846, outstanding queue size 91\n",
      "2022-07-28 13:46:14,251 - PROGRESS: pass 1, dispatched chunk #153 = documents up to #15400/18846, outstanding queue size 92\n",
      "2022-07-28 13:46:14,254 - PROGRESS: pass 1, dispatched chunk #154 = documents up to #15500/18846, outstanding queue size 93\n",
      "2022-07-28 13:46:14,263 - PROGRESS: pass 1, dispatched chunk #155 = documents up to #15600/18846, outstanding queue size 94\n",
      "2022-07-28 13:46:14,386 - merging changes from 1700 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:14,464 - topic #6 (0.100): 0.045*\"ax\" + 0.006*\"dos\" + 0.004*\"hz\" + 0.004*\"max\" + 0.003*\"people\" + 0.002*\"time\" + 0.002*\"god\" + 0.002*\"ww\" + 0.002*\"appears\" + 0.002*\"water\"\n",
      "2022-07-28 13:46:14,465 - topic #9 (0.100): 0.007*\"people\" + 0.003*\"window\" + 0.003*\"time\" + 0.002*\"question\" + 0.002*\"israel\" + 0.002*\"true\" + 0.002*\"government\" + 0.002*\"life\" + 0.002*\"lost\" + 0.002*\"god\"\n",
      "2022-07-28 13:46:14,466 - topic #1 (0.100): 0.005*\"game\" + 0.005*\"software\" + 0.004*\"windows\" + 0.004*\"time\" + 0.004*\"list\" + 0.004*\"dos\" + 0.004*\"mail\" + 0.003*\"file\" + 0.003*\"ftp\" + 0.003*\"bit\"\n",
      "2022-07-28 13:46:14,468 - topic #8 (0.100): 0.227*\"ax\" + 0.023*\"max\" + 0.004*\"file\" + 0.004*\"people\" + 0.004*\"program\" + 0.002*\"president\" + 0.002*\"armenian\" + 0.002*\"time\" + 0.002*\"turkish\" + 0.002*\"output\"\n",
      "2022-07-28 13:46:14,469 - topic #2 (0.100): 0.007*\"time\" + 0.005*\"space\" + 0.005*\"people\" + 0.003*\"government\" + 0.002*\"power\" + 0.002*\"key\" + 0.002*\"public\" + 0.002*\"read\" + 0.002*\"data\" + 0.002*\"encryption\"\n",
      "2022-07-28 13:46:14,471 - topic diff=0.064525, rho=0.072460\n",
      "2022-07-28 13:46:14,472 - PROGRESS: pass 1, dispatched chunk #156 = documents up to #15700/18846, outstanding queue size 92\n",
      "2022-07-28 13:46:14,498 - PROGRESS: pass 1, dispatched chunk #157 = documents up to #15800/18846, outstanding queue size 89\n",
      "2022-07-28 13:46:14,498 - PROGRESS: pass 1, dispatched chunk #158 = documents up to #15900/18846, outstanding queue size 90\n",
      "2022-07-28 13:46:14,499 - PROGRESS: pass 1, dispatched chunk #159 = documents up to #16000/18846, outstanding queue size 91\n",
      "2022-07-28 13:46:14,499 - PROGRESS: pass 1, dispatched chunk #160 = documents up to #16100/18846, outstanding queue size 92\n",
      "2022-07-28 13:46:14,500 - PROGRESS: pass 1, dispatched chunk #161 = documents up to #16200/18846, outstanding queue size 93\n",
      "2022-07-28 13:46:14,500 - PROGRESS: pass 1, dispatched chunk #162 = documents up to #16300/18846, outstanding queue size 94\n",
      "2022-07-28 13:46:14,526 - PROGRESS: pass 1, dispatched chunk #163 = documents up to #16400/18846, outstanding queue size 95\n",
      "2022-07-28 13:46:14,546 - PROGRESS: pass 1, dispatched chunk #164 = documents up to #16500/18846, outstanding queue size 92\n",
      "2022-07-28 13:46:14,547 - PROGRESS: pass 1, dispatched chunk #165 = documents up to #16600/18846, outstanding queue size 93\n",
      "2022-07-28 13:46:14,549 - PROGRESS: pass 1, dispatched chunk #166 = documents up to #16700/18846, outstanding queue size 94\n",
      "2022-07-28 13:46:14,570 - PROGRESS: pass 1, dispatched chunk #167 = documents up to #16800/18846, outstanding queue size 95\n",
      "2022-07-28 13:46:14,581 - PROGRESS: pass 1, dispatched chunk #168 = documents up to #16900/18846, outstanding queue size 96\n",
      "2022-07-28 13:46:14,596 - PROGRESS: pass 1, dispatched chunk #169 = documents up to #17000/18846, outstanding queue size 97\n",
      "2022-07-28 13:46:14,686 - PROGRESS: pass 1, dispatched chunk #170 = documents up to #17100/18846, outstanding queue size 96\n",
      "2022-07-28 13:46:14,687 - PROGRESS: pass 1, dispatched chunk #171 = documents up to #17200/18846, outstanding queue size 97\n",
      "2022-07-28 13:46:14,705 - PROGRESS: pass 1, dispatched chunk #172 = documents up to #17300/18846, outstanding queue size 97\n",
      "2022-07-28 13:46:14,706 - PROGRESS: pass 1, dispatched chunk #173 = documents up to #17400/18846, outstanding queue size 98\n",
      "2022-07-28 13:46:14,727 - PROGRESS: pass 1, dispatched chunk #174 = documents up to #17500/18846, outstanding queue size 98\n",
      "2022-07-28 13:46:14,754 - PROGRESS: pass 1, dispatched chunk #175 = documents up to #17600/18846, outstanding queue size 98\n",
      "2022-07-28 13:46:14,778 - PROGRESS: pass 1, dispatched chunk #176 = documents up to #17700/18846, outstanding queue size 99\n",
      "2022-07-28 13:46:14,780 - PROGRESS: pass 1, dispatched chunk #177 = documents up to #17800/18846, outstanding queue size 100\n",
      "2022-07-28 13:46:14,954 - merging changes from 2400 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:15,025 - topic #7 (0.100): 0.078*\"ax\" + 0.006*\"max\" + 0.005*\"jpeg\" + 0.004*\"car\" + 0.004*\"people\" + 0.003*\"time\" + 0.003*\"file\" + 0.002*\"image\" + 0.002*\"files\" + 0.002*\"bit\"\n",
      "2022-07-28 13:46:15,030 - topic #0 (0.100): 0.014*\"ax\" + 0.008*\"people\" + 0.006*\"drive\" + 0.006*\"god\" + 0.004*\"scsi\" + 0.003*\"card\" + 0.003*\"time\" + 0.003*\"windows\" + 0.003*\"mb\" + 0.003*\"bit\"\n",
      "2022-07-28 13:46:15,033 - topic #2 (0.100): 0.007*\"time\" + 0.006*\"space\" + 0.005*\"people\" + 0.003*\"government\" + 0.003*\"power\" + 0.002*\"key\" + 0.002*\"public\" + 0.002*\"read\" + 0.002*\"data\" + 0.002*\"encryption\"\n",
      "2022-07-28 13:46:15,036 - topic #9 (0.100): 0.007*\"people\" + 0.003*\"window\" + 0.003*\"time\" + 0.002*\"question\" + 0.002*\"israel\" + 0.002*\"true\" + 0.002*\"government\" + 0.002*\"lost\" + 0.002*\"life\" + 0.002*\"jews\"\n",
      "2022-07-28 13:46:15,039 - topic #4 (0.100): 0.007*\"god\" + 0.006*\"people\" + 0.006*\"db\" + 0.004*\"time\" + 0.003*\"jesus\" + 0.003*\"key\" + 0.003*\"gun\" + 0.002*\"law\" + 0.002*\"armenians\" + 0.002*\"christ\"\n",
      "2022-07-28 13:46:15,041 - topic diff=0.065758, rho=0.072460\n",
      "2022-07-28 13:46:15,044 - PROGRESS: pass 1, dispatched chunk #178 = documents up to #17900/18846, outstanding queue size 90\n",
      "2022-07-28 13:46:15,053 - PROGRESS: pass 1, dispatched chunk #179 = documents up to #18000/18846, outstanding queue size 89\n",
      "2022-07-28 13:46:15,059 - PROGRESS: pass 1, dispatched chunk #180 = documents up to #18100/18846, outstanding queue size 89\n",
      "2022-07-28 13:46:15,070 - PROGRESS: pass 1, dispatched chunk #181 = documents up to #18200/18846, outstanding queue size 87\n",
      "2022-07-28 13:46:15,073 - PROGRESS: pass 1, dispatched chunk #182 = documents up to #18300/18846, outstanding queue size 88\n",
      "2022-07-28 13:46:15,076 - PROGRESS: pass 1, dispatched chunk #183 = documents up to #18400/18846, outstanding queue size 89\n",
      "2022-07-28 13:46:15,077 - PROGRESS: pass 1, dispatched chunk #184 = documents up to #18500/18846, outstanding queue size 90\n",
      "2022-07-28 13:46:15,079 - PROGRESS: pass 1, dispatched chunk #185 = documents up to #18600/18846, outstanding queue size 91\n",
      "2022-07-28 13:46:15,081 - PROGRESS: pass 1, dispatched chunk #186 = documents up to #18700/18846, outstanding queue size 92\n",
      "2022-07-28 13:46:15,083 - PROGRESS: pass 1, dispatched chunk #187 = documents up to #18800/18846, outstanding queue size 93\n",
      "2022-07-28 13:46:15,146 - PROGRESS: pass 1, dispatched chunk #188 = documents up to #18846/18846, outstanding queue size 92\n",
      "2022-07-28 13:46:15,334 - merging changes from 1500 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:15,404 - topic #7 (0.100): 0.076*\"ax\" + 0.006*\"max\" + 0.005*\"jpeg\" + 0.005*\"car\" + 0.004*\"people\" + 0.003*\"time\" + 0.003*\"file\" + 0.002*\"image\" + 0.002*\"files\" + 0.002*\"bit\"\n",
      "2022-07-28 13:46:15,406 - topic #8 (0.100): 0.304*\"ax\" + 0.027*\"max\" + 0.003*\"people\" + 0.003*\"file\" + 0.003*\"program\" + 0.002*\"armenian\" + 0.002*\"president\" + 0.002*\"turkish\" + 0.002*\"di\" + 0.002*\"university\"\n",
      "2022-07-28 13:46:15,409 - topic #3 (0.100): 0.004*\"time\" + 0.004*\"people\" + 0.003*\"period\" + 0.002*\"file\" + 0.002*\"god\" + 0.002*\"play\" + 0.002*\"data\" + 0.002*\"team\" + 0.002*\"power\" + 0.002*\"server\"\n",
      "2022-07-28 13:46:15,411 - topic #4 (0.100): 0.008*\"god\" + 0.007*\"people\" + 0.005*\"db\" + 0.004*\"time\" + 0.003*\"jesus\" + 0.003*\"key\" + 0.003*\"gun\" + 0.002*\"armenians\" + 0.002*\"law\" + 0.002*\"christ\"\n",
      "2022-07-28 13:46:15,414 - topic #1 (0.100): 0.005*\"game\" + 0.005*\"windows\" + 0.005*\"software\" + 0.004*\"time\" + 0.004*\"list\" + 0.004*\"mail\" + 0.004*\"dos\" + 0.004*\"file\" + 0.003*\"program\" + 0.003*\"bit\"\n",
      "2022-07-28 13:46:15,416 - topic diff=0.062237, rho=0.072460\n",
      "2022-07-28 13:46:15,749 - -10.681 per-word bound, 1641.8 perplexity estimate based on a held-out corpus of 46 documents with 2932 words\n",
      "2022-07-28 13:46:16,106 - merging changes from 1600 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:16,136 - topic #8 (0.100): 0.308*\"ax\" + 0.028*\"max\" + 0.003*\"people\" + 0.003*\"file\" + 0.003*\"program\" + 0.002*\"di\" + 0.002*\"armenian\" + 0.002*\"turkish\" + 0.002*\"president\" + 0.002*\"university\"\n",
      "2022-07-28 13:46:16,138 - topic #3 (0.100): 0.004*\"time\" + 0.004*\"people\" + 0.003*\"file\" + 0.003*\"period\" + 0.002*\"god\" + 0.002*\"play\" + 0.002*\"pit\" + 0.002*\"data\" + 0.002*\"det\" + 0.002*\"team\"\n",
      "2022-07-28 13:46:16,140 - topic #9 (0.100): 0.008*\"people\" + 0.003*\"window\" + 0.003*\"time\" + 0.002*\"israel\" + 0.002*\"question\" + 0.002*\"true\" + 0.002*\"lost\" + 0.002*\"government\" + 0.002*\"jews\" + 0.002*\"life\"\n",
      "2022-07-28 13:46:16,141 - topic #6 (0.100): 0.040*\"ax\" + 0.005*\"dos\" + 0.004*\"hz\" + 0.003*\"max\" + 0.003*\"people\" + 0.002*\"water\" + 0.002*\"time\" + 0.002*\"battery\" + 0.002*\"ww\" + 0.002*\"god\"\n",
      "2022-07-28 13:46:16,142 - topic #1 (0.100): 0.005*\"game\" + 0.005*\"windows\" + 0.005*\"software\" + 0.004*\"time\" + 0.004*\"list\" + 0.004*\"mail\" + 0.004*\"file\" + 0.004*\"dos\" + 0.003*\"program\" + 0.003*\"image\"\n",
      "2022-07-28 13:46:16,143 - topic diff=0.063846, rho=0.072460\n",
      "2022-07-28 13:46:16,219 - -10.676 per-word bound, 1635.6 perplexity estimate based on a held-out corpus of 46 documents with 2932 words\n",
      "2022-07-28 13:46:16,399 - merging changes from 6846 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:16,430 - topic #1 (0.100): 0.005*\"game\" + 0.005*\"windows\" + 0.005*\"software\" + 0.004*\"time\" + 0.004*\"mail\" + 0.004*\"list\" + 0.004*\"dos\" + 0.004*\"file\" + 0.003*\"program\" + 0.003*\"image\"\n",
      "2022-07-28 13:46:16,432 - topic #9 (0.100): 0.008*\"people\" + 0.003*\"time\" + 0.003*\"window\" + 0.003*\"israel\" + 0.002*\"question\" + 0.002*\"true\" + 0.002*\"jews\" + 0.002*\"government\" + 0.002*\"israeli\" + 0.002*\"lost\"\n",
      "2022-07-28 13:46:16,433 - topic #5 (0.100): 0.006*\"ax\" + 0.004*\"time\" + 0.004*\"people\" + 0.003*\"max\" + 0.002*\"set\" + 0.002*\"players\" + 0.002*\"file\" + 0.002*\"book\" + 0.002*\"bit\" + 0.002*\"armenian\"\n",
      "2022-07-28 13:46:16,434 - topic #0 (0.100): 0.011*\"ax\" + 0.008*\"people\" + 0.007*\"drive\" + 0.006*\"god\" + 0.004*\"scsi\" + 0.004*\"card\" + 0.003*\"disk\" + 0.003*\"time\" + 0.003*\"mb\" + 0.003*\"windows\"\n",
      "2022-07-28 13:46:16,436 - topic #4 (0.100): 0.008*\"god\" + 0.007*\"people\" + 0.004*\"db\" + 0.004*\"time\" + 0.003*\"jesus\" + 0.003*\"gun\" + 0.003*\"key\" + 0.002*\"law\" + 0.002*\"armenians\" + 0.002*\"christ\"\n",
      "2022-07-28 13:46:16,437 - topic diff=0.056275, rho=0.072460\n",
      "2022-07-28 13:46:16,512 - -10.633 per-word bound, 1588.2 perplexity estimate based on a held-out corpus of 46 documents with 2932 words\n",
      "2022-07-28 13:46:16,513 - PROGRESS: pass 2, dispatched chunk #0 = documents up to #100/18846, outstanding queue size 1\n",
      "2022-07-28 13:46:16,516 - PROGRESS: pass 2, dispatched chunk #1 = documents up to #200/18846, outstanding queue size 2\n",
      "2022-07-28 13:46:16,516 - PROGRESS: pass 2, dispatched chunk #2 = documents up to #300/18846, outstanding queue size 3\n",
      "2022-07-28 13:46:16,517 - PROGRESS: pass 2, dispatched chunk #3 = documents up to #400/18846, outstanding queue size 4\n",
      "2022-07-28 13:46:16,517 - PROGRESS: pass 2, dispatched chunk #4 = documents up to #500/18846, outstanding queue size 5\n",
      "2022-07-28 13:46:16,517 - PROGRESS: pass 2, dispatched chunk #5 = documents up to #600/18846, outstanding queue size 6\n",
      "2022-07-28 13:46:16,517 - PROGRESS: pass 2, dispatched chunk #6 = documents up to #700/18846, outstanding queue size 7\n",
      "2022-07-28 13:46:16,518 - PROGRESS: pass 2, dispatched chunk #7 = documents up to #800/18846, outstanding queue size 8\n",
      "2022-07-28 13:46:16,520 - PROGRESS: pass 2, dispatched chunk #8 = documents up to #900/18846, outstanding queue size 9\n",
      "2022-07-28 13:46:16,521 - PROGRESS: pass 2, dispatched chunk #9 = documents up to #1000/18846, outstanding queue size 10\n",
      "2022-07-28 13:46:16,521 - PROGRESS: pass 2, dispatched chunk #10 = documents up to #1100/18846, outstanding queue size 11\n",
      "2022-07-28 13:46:16,521 - PROGRESS: pass 2, dispatched chunk #11 = documents up to #1200/18846, outstanding queue size 12\n",
      "2022-07-28 13:46:16,522 - PROGRESS: pass 2, dispatched chunk #12 = documents up to #1300/18846, outstanding queue size 13\n",
      "2022-07-28 13:46:16,522 - PROGRESS: pass 2, dispatched chunk #13 = documents up to #1400/18846, outstanding queue size 14\n",
      "2022-07-28 13:46:16,522 - PROGRESS: pass 2, dispatched chunk #14 = documents up to #1500/18846, outstanding queue size 15\n",
      "2022-07-28 13:46:16,523 - PROGRESS: pass 2, dispatched chunk #15 = documents up to #1600/18846, outstanding queue size 16\n",
      "2022-07-28 13:46:16,525 - PROGRESS: pass 2, dispatched chunk #16 = documents up to #1700/18846, outstanding queue size 17\n",
      "2022-07-28 13:46:16,525 - PROGRESS: pass 2, dispatched chunk #17 = documents up to #1800/18846, outstanding queue size 18\n",
      "2022-07-28 13:46:16,526 - PROGRESS: pass 2, dispatched chunk #18 = documents up to #1900/18846, outstanding queue size 19\n",
      "2022-07-28 13:46:16,526 - PROGRESS: pass 2, dispatched chunk #19 = documents up to #2000/18846, outstanding queue size 20\n",
      "2022-07-28 13:46:16,527 - PROGRESS: pass 2, dispatched chunk #20 = documents up to #2100/18846, outstanding queue size 21\n",
      "2022-07-28 13:46:16,527 - PROGRESS: pass 2, dispatched chunk #21 = documents up to #2200/18846, outstanding queue size 22\n",
      "2022-07-28 13:46:16,527 - PROGRESS: pass 2, dispatched chunk #22 = documents up to #2300/18846, outstanding queue size 23\n",
      "2022-07-28 13:46:16,528 - PROGRESS: pass 2, dispatched chunk #23 = documents up to #2400/18846, outstanding queue size 24\n",
      "2022-07-28 13:46:16,530 - PROGRESS: pass 2, dispatched chunk #24 = documents up to #2500/18846, outstanding queue size 25\n",
      "2022-07-28 13:46:16,531 - PROGRESS: pass 2, dispatched chunk #25 = documents up to #2600/18846, outstanding queue size 26\n",
      "2022-07-28 13:46:16,531 - PROGRESS: pass 2, dispatched chunk #26 = documents up to #2700/18846, outstanding queue size 27\n",
      "2022-07-28 13:46:16,532 - PROGRESS: pass 2, dispatched chunk #27 = documents up to #2800/18846, outstanding queue size 28\n",
      "2022-07-28 13:46:16,532 - PROGRESS: pass 2, dispatched chunk #28 = documents up to #2900/18846, outstanding queue size 29\n",
      "2022-07-28 13:46:16,532 - PROGRESS: pass 2, dispatched chunk #29 = documents up to #3000/18846, outstanding queue size 30\n",
      "2022-07-28 13:46:16,532 - PROGRESS: pass 2, dispatched chunk #30 = documents up to #3100/18846, outstanding queue size 31\n",
      "2022-07-28 13:46:16,537 - PROGRESS: pass 2, dispatched chunk #31 = documents up to #3200/18846, outstanding queue size 32\n",
      "2022-07-28 13:46:16,540 - PROGRESS: pass 2, dispatched chunk #32 = documents up to #3300/18846, outstanding queue size 33\n",
      "2022-07-28 13:46:16,540 - PROGRESS: pass 2, dispatched chunk #33 = documents up to #3400/18846, outstanding queue size 34\n",
      "2022-07-28 13:46:16,541 - PROGRESS: pass 2, dispatched chunk #34 = documents up to #3500/18846, outstanding queue size 35\n",
      "2022-07-28 13:46:16,542 - PROGRESS: pass 2, dispatched chunk #35 = documents up to #3600/18846, outstanding queue size 36\n",
      "2022-07-28 13:46:16,550 - PROGRESS: pass 2, dispatched chunk #36 = documents up to #3700/18846, outstanding queue size 37\n",
      "2022-07-28 13:46:16,553 - PROGRESS: pass 2, dispatched chunk #37 = documents up to #3800/18846, outstanding queue size 38\n",
      "2022-07-28 13:46:16,557 - PROGRESS: pass 2, dispatched chunk #38 = documents up to #3900/18846, outstanding queue size 39\n",
      "2022-07-28 13:46:16,562 - PROGRESS: pass 2, dispatched chunk #39 = documents up to #4000/18846, outstanding queue size 40\n",
      "2022-07-28 13:46:16,566 - PROGRESS: pass 2, dispatched chunk #40 = documents up to #4100/18846, outstanding queue size 41\n",
      "2022-07-28 13:46:16,589 - PROGRESS: pass 2, dispatched chunk #41 = documents up to #4200/18846, outstanding queue size 42\n",
      "2022-07-28 13:46:16,631 - PROGRESS: pass 2, dispatched chunk #42 = documents up to #4300/18846, outstanding queue size 38\n",
      "2022-07-28 13:46:16,652 - PROGRESS: pass 2, dispatched chunk #43 = documents up to #4400/18846, outstanding queue size 39\n",
      "2022-07-28 13:46:16,669 - PROGRESS: pass 2, dispatched chunk #44 = documents up to #4500/18846, outstanding queue size 37\n",
      "2022-07-28 13:46:16,670 - PROGRESS: pass 2, dispatched chunk #45 = documents up to #4600/18846, outstanding queue size 38\n",
      "2022-07-28 13:46:16,678 - PROGRESS: pass 2, dispatched chunk #46 = documents up to #4700/18846, outstanding queue size 37\n",
      "2022-07-28 13:46:16,679 - PROGRESS: pass 2, dispatched chunk #47 = documents up to #4800/18846, outstanding queue size 38\n",
      "2022-07-28 13:46:16,681 - PROGRESS: pass 2, dispatched chunk #48 = documents up to #4900/18846, outstanding queue size 39\n",
      "2022-07-28 13:46:16,703 - PROGRESS: pass 2, dispatched chunk #49 = documents up to #5000/18846, outstanding queue size 39\n",
      "2022-07-28 13:46:16,712 - PROGRESS: pass 2, dispatched chunk #50 = documents up to #5100/18846, outstanding queue size 39\n",
      "2022-07-28 13:46:16,746 - PROGRESS: pass 2, dispatched chunk #51 = documents up to #5200/18846, outstanding queue size 39\n",
      "2022-07-28 13:46:16,760 - PROGRESS: pass 2, dispatched chunk #52 = documents up to #5300/18846, outstanding queue size 39\n",
      "2022-07-28 13:46:16,901 - merging changes from 1700 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:16,994 - topic #6 (0.100): 0.037*\"ax\" + 0.006*\"dos\" + 0.004*\"hz\" + 0.003*\"max\" + 0.003*\"people\" + 0.002*\"water\" + 0.002*\"battery\" + 0.002*\"time\" + 0.002*\"st\" + 0.002*\"armenian\"\n",
      "2022-07-28 13:46:17,001 - topic #8 (0.100): 0.310*\"ax\" + 0.028*\"max\" + 0.003*\"people\" + 0.003*\"file\" + 0.003*\"program\" + 0.002*\"di\" + 0.002*\"armenian\" + 0.002*\"turkish\" + 0.002*\"university\" + 0.002*\"president\"\n",
      "2022-07-28 13:46:17,007 - topic #7 (0.100): 0.069*\"ax\" + 0.006*\"max\" + 0.005*\"car\" + 0.005*\"jpeg\" + 0.004*\"people\" + 0.003*\"time\" + 0.003*\"file\" + 0.002*\"image\" + 0.002*\"files\" + 0.002*\"gif\"\n",
      "2022-07-28 13:46:17,010 - topic #0 (0.100): 0.011*\"ax\" + 0.008*\"people\" + 0.007*\"drive\" + 0.006*\"god\" + 0.004*\"scsi\" + 0.004*\"card\" + 0.003*\"mb\" + 0.003*\"disk\" + 0.003*\"time\" + 0.003*\"windows\"\n",
      "2022-07-28 13:46:17,015 - topic #5 (0.100): 0.006*\"ax\" + 0.004*\"time\" + 0.004*\"people\" + 0.002*\"max\" + 0.002*\"set\" + 0.002*\"players\" + 0.002*\"armenian\" + 0.002*\"book\" + 0.002*\"file\" + 0.002*\"bit\"\n",
      "2022-07-28 13:46:17,041 - topic diff=0.058867, rho=0.072270\n",
      "2022-07-28 13:46:17,042 - PROGRESS: pass 2, dispatched chunk #53 = documents up to #5400/18846, outstanding queue size 37\n",
      "2022-07-28 13:46:17,045 - PROGRESS: pass 2, dispatched chunk #54 = documents up to #5500/18846, outstanding queue size 37\n",
      "2022-07-28 13:46:17,046 - PROGRESS: pass 2, dispatched chunk #55 = documents up to #5600/18846, outstanding queue size 38\n",
      "2022-07-28 13:46:17,067 - PROGRESS: pass 2, dispatched chunk #56 = documents up to #5700/18846, outstanding queue size 31\n",
      "2022-07-28 13:46:17,069 - PROGRESS: pass 2, dispatched chunk #57 = documents up to #5800/18846, outstanding queue size 32\n",
      "2022-07-28 13:46:17,070 - PROGRESS: pass 2, dispatched chunk #58 = documents up to #5900/18846, outstanding queue size 33\n",
      "2022-07-28 13:46:17,071 - PROGRESS: pass 2, dispatched chunk #59 = documents up to #6000/18846, outstanding queue size 34\n",
      "2022-07-28 13:46:17,071 - PROGRESS: pass 2, dispatched chunk #60 = documents up to #6100/18846, outstanding queue size 35\n",
      "2022-07-28 13:46:17,072 - PROGRESS: pass 2, dispatched chunk #61 = documents up to #6200/18846, outstanding queue size 36\n",
      "2022-07-28 13:46:17,073 - PROGRESS: pass 2, dispatched chunk #62 = documents up to #6300/18846, outstanding queue size 37\n",
      "2022-07-28 13:46:17,073 - PROGRESS: pass 2, dispatched chunk #63 = documents up to #6400/18846, outstanding queue size 38\n",
      "2022-07-28 13:46:17,131 - PROGRESS: pass 2, dispatched chunk #64 = documents up to #6500/18846, outstanding queue size 37\n",
      "2022-07-28 13:46:17,133 - PROGRESS: pass 2, dispatched chunk #65 = documents up to #6600/18846, outstanding queue size 38\n",
      "2022-07-28 13:46:17,156 - PROGRESS: pass 2, dispatched chunk #66 = documents up to #6700/18846, outstanding queue size 38\n",
      "2022-07-28 13:46:17,222 - PROGRESS: pass 2, dispatched chunk #67 = documents up to #6800/18846, outstanding queue size 38\n",
      "2022-07-28 13:46:17,334 - merging changes from 1500 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:17,488 - topic #4 (0.100): 0.009*\"god\" + 0.007*\"people\" + 0.004*\"time\" + 0.004*\"db\" + 0.004*\"jesus\" + 0.003*\"key\" + 0.003*\"gun\" + 0.003*\"law\" + 0.002*\"christ\" + 0.002*\"armenians\"\n",
      "2022-07-28 13:46:17,496 - topic #3 (0.100): 0.004*\"time\" + 0.003*\"people\" + 0.003*\"period\" + 0.003*\"file\" + 0.002*\"play\" + 0.002*\"pit\" + 0.002*\"god\" + 0.002*\"team\" + 0.002*\"det\" + 0.002*\"data\"\n",
      "2022-07-28 13:46:17,497 - topic #2 (0.100): 0.007*\"time\" + 0.006*\"space\" + 0.005*\"people\" + 0.003*\"government\" + 0.003*\"power\" + 0.002*\"key\" + 0.002*\"public\" + 0.002*\"read\" + 0.002*\"data\" + 0.002*\"car\"\n",
      "2022-07-28 13:46:17,498 - topic #8 (0.100): 0.326*\"ax\" + 0.029*\"max\" + 0.003*\"di\" + 0.003*\"people\" + 0.002*\"program\" + 0.002*\"file\" + 0.002*\"armenian\" + 0.002*\"turkish\" + 0.002*\"university\" + 0.002*\"ei\"\n",
      "2022-07-28 13:46:17,500 - topic #6 (0.100): 0.033*\"ax\" + 0.006*\"dos\" + 0.004*\"hz\" + 0.003*\"max\" + 0.003*\"people\" + 0.002*\"appears\" + 0.002*\"ww\" + 0.002*\"water\" + 0.002*\"st\" + 0.002*\"battery\"\n",
      "2022-07-28 13:46:17,502 - topic diff=0.070207, rho=0.072270\n",
      "2022-07-28 13:46:17,511 - PROGRESS: pass 2, dispatched chunk #68 = documents up to #6900/18846, outstanding queue size 37\n",
      "2022-07-28 13:46:17,559 - PROGRESS: pass 2, dispatched chunk #69 = documents up to #7000/18846, outstanding queue size 30\n",
      "2022-07-28 13:46:17,562 - PROGRESS: pass 2, dispatched chunk #70 = documents up to #7100/18846, outstanding queue size 31\n",
      "2022-07-28 13:46:17,562 - PROGRESS: pass 2, dispatched chunk #71 = documents up to #7200/18846, outstanding queue size 32\n",
      "2022-07-28 13:46:17,563 - PROGRESS: pass 2, dispatched chunk #72 = documents up to #7300/18846, outstanding queue size 33\n",
      "2022-07-28 13:46:17,564 - PROGRESS: pass 2, dispatched chunk #73 = documents up to #7400/18846, outstanding queue size 34\n",
      "2022-07-28 13:46:17,564 - PROGRESS: pass 2, dispatched chunk #74 = documents up to #7500/18846, outstanding queue size 35\n",
      "2022-07-28 13:46:17,565 - PROGRESS: pass 2, dispatched chunk #75 = documents up to #7600/18846, outstanding queue size 36\n",
      "2022-07-28 13:46:17,566 - PROGRESS: pass 2, dispatched chunk #76 = documents up to #7700/18846, outstanding queue size 37\n",
      "2022-07-28 13:46:17,566 - PROGRESS: pass 2, dispatched chunk #77 = documents up to #7800/18846, outstanding queue size 38\n",
      "2022-07-28 13:46:17,567 - PROGRESS: pass 2, dispatched chunk #78 = documents up to #7900/18846, outstanding queue size 39\n",
      "2022-07-28 13:46:17,630 - PROGRESS: pass 2, dispatched chunk #79 = documents up to #8000/18846, outstanding queue size 39\n",
      "2022-07-28 13:46:17,637 - PROGRESS: pass 2, dispatched chunk #80 = documents up to #8100/18846, outstanding queue size 39\n",
      "2022-07-28 13:46:17,656 - PROGRESS: pass 2, dispatched chunk #81 = documents up to #8200/18846, outstanding queue size 39\n",
      "2022-07-28 13:46:17,733 - PROGRESS: pass 2, dispatched chunk #82 = documents up to #8300/18846, outstanding queue size 40\n",
      "2022-07-28 13:46:17,899 - merging changes from 1600 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:18,070 - topic #2 (0.100): 0.007*\"time\" + 0.006*\"space\" + 0.005*\"people\" + 0.003*\"government\" + 0.003*\"power\" + 0.002*\"key\" + 0.002*\"public\" + 0.002*\"read\" + 0.002*\"car\" + 0.002*\"data\"\n",
      "2022-07-28 13:46:18,080 - topic #0 (0.100): 0.009*\"ax\" + 0.008*\"people\" + 0.007*\"drive\" + 0.006*\"god\" + 0.004*\"scsi\" + 0.004*\"card\" + 0.004*\"mb\" + 0.003*\"disk\" + 0.003*\"time\" + 0.003*\"windows\"\n",
      "2022-07-28 13:46:18,104 - topic #7 (0.100): 0.060*\"ax\" + 0.009*\"jpeg\" + 0.005*\"car\" + 0.005*\"max\" + 0.004*\"people\" + 0.004*\"file\" + 0.003*\"gif\" + 0.003*\"image\" + 0.003*\"time\" + 0.003*\"files\"\n",
      "2022-07-28 13:46:18,110 - topic #4 (0.100): 0.009*\"god\" + 0.007*\"people\" + 0.004*\"jesus\" + 0.004*\"time\" + 0.003*\"db\" + 0.003*\"key\" + 0.003*\"gun\" + 0.003*\"christ\" + 0.003*\"law\" + 0.003*\"lord\"\n",
      "2022-07-28 13:46:18,113 - topic #8 (0.100): 0.316*\"ax\" + 0.028*\"max\" + 0.003*\"di\" + 0.003*\"file\" + 0.003*\"people\" + 0.003*\"program\" + 0.002*\"armenian\" + 0.002*\"turkish\" + 0.002*\"output\" + 0.002*\"genocide\"\n",
      "2022-07-28 13:46:18,126 - topic diff=0.071350, rho=0.072270\n",
      "2022-07-28 13:46:18,135 - PROGRESS: pass 2, dispatched chunk #83 = documents up to #8400/18846, outstanding queue size 36\n",
      "2022-07-28 13:46:18,146 - PROGRESS: pass 2, dispatched chunk #84 = documents up to #8500/18846, outstanding queue size 36\n",
      "2022-07-28 13:46:18,148 - PROGRESS: pass 2, dispatched chunk #85 = documents up to #8600/18846, outstanding queue size 37\n",
      "2022-07-28 13:46:18,149 - PROGRESS: pass 2, dispatched chunk #86 = documents up to #8700/18846, outstanding queue size 38\n",
      "2022-07-28 13:46:18,151 - PROGRESS: pass 2, dispatched chunk #87 = documents up to #8800/18846, outstanding queue size 39\n",
      "2022-07-28 13:46:18,152 - PROGRESS: pass 2, dispatched chunk #88 = documents up to #8900/18846, outstanding queue size 40\n",
      "2022-07-28 13:46:18,154 - PROGRESS: pass 2, dispatched chunk #89 = documents up to #9000/18846, outstanding queue size 41\n",
      "2022-07-28 13:46:18,155 - PROGRESS: pass 2, dispatched chunk #90 = documents up to #9100/18846, outstanding queue size 42\n",
      "2022-07-28 13:46:18,163 - PROGRESS: pass 2, dispatched chunk #91 = documents up to #9200/18846, outstanding queue size 43\n",
      "2022-07-28 13:46:18,164 - PROGRESS: pass 2, dispatched chunk #92 = documents up to #9300/18846, outstanding queue size 44\n",
      "2022-07-28 13:46:18,166 - PROGRESS: pass 2, dispatched chunk #93 = documents up to #9400/18846, outstanding queue size 45\n",
      "2022-07-28 13:46:18,167 - PROGRESS: pass 2, dispatched chunk #94 = documents up to #9500/18846, outstanding queue size 46\n",
      "2022-07-28 13:46:18,169 - PROGRESS: pass 2, dispatched chunk #95 = documents up to #9600/18846, outstanding queue size 47\n",
      "2022-07-28 13:46:18,170 - PROGRESS: pass 2, dispatched chunk #96 = documents up to #9700/18846, outstanding queue size 48\n",
      "2022-07-28 13:46:18,172 - PROGRESS: pass 2, dispatched chunk #97 = documents up to #9800/18846, outstanding queue size 49\n",
      "2022-07-28 13:46:18,174 - PROGRESS: pass 2, dispatched chunk #98 = documents up to #9900/18846, outstanding queue size 50\n",
      "2022-07-28 13:46:18,176 - PROGRESS: pass 2, dispatched chunk #99 = documents up to #10000/18846, outstanding queue size 51\n",
      "2022-07-28 13:46:18,204 - PROGRESS: pass 2, dispatched chunk #100 = documents up to #10100/18846, outstanding queue size 50\n",
      "2022-07-28 13:46:18,226 - PROGRESS: pass 2, dispatched chunk #101 = documents up to #10200/18846, outstanding queue size 50\n",
      "2022-07-28 13:46:18,252 - PROGRESS: pass 2, dispatched chunk #102 = documents up to #10300/18846, outstanding queue size 51\n",
      "2022-07-28 13:46:18,256 - PROGRESS: pass 2, dispatched chunk #103 = documents up to #10400/18846, outstanding queue size 52\n",
      "2022-07-28 13:46:18,307 - PROGRESS: pass 2, dispatched chunk #104 = documents up to #10500/18846, outstanding queue size 50\n",
      "2022-07-28 13:46:18,309 - PROGRESS: pass 2, dispatched chunk #105 = documents up to #10600/18846, outstanding queue size 51\n",
      "2022-07-28 13:46:18,311 - PROGRESS: pass 2, dispatched chunk #106 = documents up to #10700/18846, outstanding queue size 52\n",
      "2022-07-28 13:46:18,429 - PROGRESS: pass 2, dispatched chunk #107 = documents up to #10800/18846, outstanding queue size 51\n",
      "2022-07-28 13:46:18,433 - PROGRESS: pass 2, dispatched chunk #108 = documents up to #10900/18846, outstanding queue size 52\n",
      "2022-07-28 13:46:18,435 - PROGRESS: pass 2, dispatched chunk #109 = documents up to #11000/18846, outstanding queue size 53\n",
      "2022-07-28 13:46:18,437 - PROGRESS: pass 2, dispatched chunk #110 = documents up to #11100/18846, outstanding queue size 54\n",
      "2022-07-28 13:46:18,464 - PROGRESS: pass 2, dispatched chunk #111 = documents up to #11200/18846, outstanding queue size 54\n",
      "2022-07-28 13:46:18,469 - PROGRESS: pass 2, dispatched chunk #112 = documents up to #11300/18846, outstanding queue size 55\n",
      "2022-07-28 13:46:18,473 - PROGRESS: pass 2, dispatched chunk #113 = documents up to #11400/18846, outstanding queue size 55\n",
      "2022-07-28 13:46:18,515 - PROGRESS: pass 2, dispatched chunk #114 = documents up to #11500/18846, outstanding queue size 55\n",
      "2022-07-28 13:46:18,524 - PROGRESS: pass 2, dispatched chunk #115 = documents up to #11600/18846, outstanding queue size 56\n",
      "2022-07-28 13:46:18,665 - merging changes from 1500 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:18,750 - topic #5 (0.100): 0.005*\"ax\" + 0.004*\"time\" + 0.003*\"people\" + 0.002*\"players\" + 0.002*\"set\" + 0.002*\"armenian\" + 0.002*\"source\" + 0.002*\"book\" + 0.002*\"max\" + 0.002*\"file\"\n",
      "2022-07-28 13:46:18,764 - topic #4 (0.100): 0.009*\"god\" + 0.007*\"people\" + 0.004*\"jesus\" + 0.004*\"time\" + 0.003*\"db\" + 0.003*\"gun\" + 0.003*\"key\" + 0.003*\"christ\" + 0.003*\"law\" + 0.002*\"lord\"\n",
      "2022-07-28 13:46:18,778 - topic #2 (0.100): 0.007*\"time\" + 0.006*\"space\" + 0.005*\"people\" + 0.003*\"government\" + 0.003*\"power\" + 0.002*\"key\" + 0.002*\"public\" + 0.002*\"car\" + 0.002*\"read\" + 0.002*\"data\"\n",
      "2022-07-28 13:46:18,780 - topic #9 (0.100): 0.009*\"people\" + 0.003*\"israel\" + 0.003*\"time\" + 0.002*\"jews\" + 0.002*\"question\" + 0.002*\"window\" + 0.002*\"true\" + 0.002*\"israeli\" + 0.002*\"government\" + 0.002*\"president\"\n",
      "2022-07-28 13:46:18,781 - topic #8 (0.100): 0.374*\"ax\" + 0.032*\"max\" + 0.003*\"di\" + 0.003*\"file\" + 0.003*\"program\" + 0.002*\"output\" + 0.002*\"people\" + 0.002*\"armenian\" + 0.002*\"turkish\" + 0.002*\"ei\"\n",
      "2022-07-28 13:46:18,783 - topic diff=0.071594, rho=0.072270\n",
      "2022-07-28 13:46:18,784 - PROGRESS: pass 2, dispatched chunk #116 = documents up to #11700/18846, outstanding queue size 54\n",
      "2022-07-28 13:46:18,837 - PROGRESS: pass 2, dispatched chunk #117 = documents up to #11800/18846, outstanding queue size 46\n",
      "2022-07-28 13:46:18,840 - PROGRESS: pass 2, dispatched chunk #118 = documents up to #11900/18846, outstanding queue size 47\n",
      "2022-07-28 13:46:18,840 - PROGRESS: pass 2, dispatched chunk #119 = documents up to #12000/18846, outstanding queue size 48\n",
      "2022-07-28 13:46:18,842 - PROGRESS: pass 2, dispatched chunk #120 = documents up to #12100/18846, outstanding queue size 49\n",
      "2022-07-28 13:46:18,842 - PROGRESS: pass 2, dispatched chunk #121 = documents up to #12200/18846, outstanding queue size 50\n",
      "2022-07-28 13:46:18,846 - PROGRESS: pass 2, dispatched chunk #122 = documents up to #12300/18846, outstanding queue size 50\n",
      "2022-07-28 13:46:18,848 - PROGRESS: pass 2, dispatched chunk #123 = documents up to #12400/18846, outstanding queue size 51\n",
      "2022-07-28 13:46:19,105 - merging changes from 1500 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:19,170 - topic #8 (0.100): 0.364*\"ax\" + 0.031*\"max\" + 0.003*\"di\" + 0.003*\"file\" + 0.003*\"armenian\" + 0.003*\"program\" + 0.003*\"people\" + 0.002*\"output\" + 0.002*\"turkish\" + 0.002*\"ei\"\n",
      "2022-07-28 13:46:19,173 - topic #4 (0.100): 0.009*\"god\" + 0.007*\"people\" + 0.004*\"jesus\" + 0.004*\"time\" + 0.003*\"gun\" + 0.003*\"key\" + 0.003*\"db\" + 0.003*\"law\" + 0.003*\"christ\" + 0.002*\"lord\"\n",
      "2022-07-28 13:46:19,176 - topic #5 (0.100): 0.005*\"ax\" + 0.004*\"time\" + 0.003*\"people\" + 0.002*\"players\" + 0.002*\"set\" + 0.002*\"armenian\" + 0.002*\"source\" + 0.002*\"book\" + 0.002*\"max\" + 0.002*\"bit\"\n",
      "2022-07-28 13:46:19,180 - topic #1 (0.100): 0.006*\"windows\" + 0.005*\"file\" + 0.005*\"software\" + 0.005*\"game\" + 0.004*\"mail\" + 0.004*\"program\" + 0.004*\"time\" + 0.004*\"list\" + 0.004*\"dos\" + 0.004*\"graphics\"\n",
      "2022-07-28 13:46:19,182 - topic #0 (0.100): 0.008*\"ax\" + 0.008*\"people\" + 0.007*\"drive\" + 0.006*\"god\" + 0.005*\"scsi\" + 0.004*\"card\" + 0.004*\"mb\" + 0.003*\"disk\" + 0.003*\"time\" + 0.003*\"bit\"\n",
      "2022-07-28 13:46:19,186 - topic diff=0.059914, rho=0.072270\n",
      "2022-07-28 13:46:19,190 - PROGRESS: pass 2, dispatched chunk #124 = documents up to #12500/18846, outstanding queue size 47\n",
      "2022-07-28 13:46:19,251 - PROGRESS: pass 2, dispatched chunk #125 = documents up to #12600/18846, outstanding queue size 42\n",
      "2022-07-28 13:46:19,255 - PROGRESS: pass 2, dispatched chunk #126 = documents up to #12700/18846, outstanding queue size 43\n",
      "2022-07-28 13:46:19,256 - PROGRESS: pass 2, dispatched chunk #127 = documents up to #12800/18846, outstanding queue size 44\n",
      "2022-07-28 13:46:19,256 - PROGRESS: pass 2, dispatched chunk #128 = documents up to #12900/18846, outstanding queue size 45\n",
      "2022-07-28 13:46:19,278 - PROGRESS: pass 2, dispatched chunk #129 = documents up to #13000/18846, outstanding queue size 45\n",
      "2022-07-28 13:46:19,288 - PROGRESS: pass 2, dispatched chunk #130 = documents up to #13100/18846, outstanding queue size 43\n",
      "2022-07-28 13:46:19,289 - PROGRESS: pass 2, dispatched chunk #131 = documents up to #13200/18846, outstanding queue size 44\n",
      "2022-07-28 13:46:19,289 - PROGRESS: pass 2, dispatched chunk #132 = documents up to #13300/18846, outstanding queue size 45\n",
      "2022-07-28 13:46:19,290 - PROGRESS: pass 2, dispatched chunk #133 = documents up to #13400/18846, outstanding queue size 46\n",
      "2022-07-28 13:46:19,290 - PROGRESS: pass 2, dispatched chunk #134 = documents up to #13500/18846, outstanding queue size 47\n",
      "2022-07-28 13:46:19,291 - PROGRESS: pass 2, dispatched chunk #135 = documents up to #13600/18846, outstanding queue size 48\n",
      "2022-07-28 13:46:19,291 - PROGRESS: pass 2, dispatched chunk #136 = documents up to #13700/18846, outstanding queue size 49\n",
      "2022-07-28 13:46:19,291 - PROGRESS: pass 2, dispatched chunk #137 = documents up to #13800/18846, outstanding queue size 50\n",
      "2022-07-28 13:46:19,292 - PROGRESS: pass 2, dispatched chunk #138 = documents up to #13900/18846, outstanding queue size 51\n",
      "2022-07-28 13:46:19,292 - PROGRESS: pass 2, dispatched chunk #139 = documents up to #14000/18846, outstanding queue size 52\n",
      "2022-07-28 13:46:19,293 - PROGRESS: pass 2, dispatched chunk #140 = documents up to #14100/18846, outstanding queue size 53\n",
      "2022-07-28 13:46:19,294 - PROGRESS: pass 2, dispatched chunk #141 = documents up to #14200/18846, outstanding queue size 54\n",
      "2022-07-28 13:46:19,294 - PROGRESS: pass 2, dispatched chunk #142 = documents up to #14300/18846, outstanding queue size 55\n",
      "2022-07-28 13:46:19,295 - PROGRESS: pass 2, dispatched chunk #143 = documents up to #14400/18846, outstanding queue size 56\n",
      "2022-07-28 13:46:19,308 - PROGRESS: pass 2, dispatched chunk #144 = documents up to #14500/18846, outstanding queue size 57\n",
      "2022-07-28 13:46:19,314 - PROGRESS: pass 2, dispatched chunk #145 = documents up to #14600/18846, outstanding queue size 58\n",
      "2022-07-28 13:46:19,363 - PROGRESS: pass 2, dispatched chunk #146 = documents up to #14700/18846, outstanding queue size 58\n",
      "2022-07-28 13:46:19,372 - PROGRESS: pass 2, dispatched chunk #147 = documents up to #14800/18846, outstanding queue size 58\n",
      "2022-07-28 13:46:19,465 - PROGRESS: pass 2, dispatched chunk #148 = documents up to #14900/18846, outstanding queue size 58\n",
      "2022-07-28 13:46:19,489 - PROGRESS: pass 2, dispatched chunk #149 = documents up to #15000/18846, outstanding queue size 59\n",
      "2022-07-28 13:46:19,492 - PROGRESS: pass 2, dispatched chunk #150 = documents up to #15100/18846, outstanding queue size 60\n",
      "2022-07-28 13:46:19,522 - PROGRESS: pass 2, dispatched chunk #151 = documents up to #15200/18846, outstanding queue size 61\n",
      "2022-07-28 13:46:19,525 - PROGRESS: pass 2, dispatched chunk #152 = documents up to #15300/18846, outstanding queue size 62\n",
      "2022-07-28 13:46:19,548 - PROGRESS: pass 2, dispatched chunk #153 = documents up to #15400/18846, outstanding queue size 63\n",
      "2022-07-28 13:46:19,576 - PROGRESS: pass 2, dispatched chunk #154 = documents up to #15500/18846, outstanding queue size 63\n",
      "2022-07-28 13:46:19,743 - merging changes from 1500 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:19,801 - topic #2 (0.100): 0.007*\"time\" + 0.006*\"space\" + 0.005*\"people\" + 0.004*\"government\" + 0.003*\"power\" + 0.002*\"key\" + 0.002*\"public\" + 0.002*\"encryption\" + 0.002*\"car\" + 0.002*\"data\"\n",
      "2022-07-28 13:46:19,808 - topic #7 (0.100): 0.054*\"ax\" + 0.008*\"jpeg\" + 0.006*\"car\" + 0.005*\"max\" + 0.004*\"people\" + 0.004*\"file\" + 0.003*\"gif\" + 0.003*\"image\" + 0.003*\"time\" + 0.003*\"files\"\n",
      "2022-07-28 13:46:19,809 - topic #5 (0.100): 0.004*\"ax\" + 0.004*\"time\" + 0.003*\"people\" + 0.002*\"armenian\" + 0.002*\"players\" + 0.002*\"book\" + 0.002*\"set\" + 0.002*\"source\" + 0.002*\"bit\" + 0.002*\"max\"\n",
      "2022-07-28 13:46:19,812 - topic #9 (0.100): 0.009*\"people\" + 0.003*\"israel\" + 0.003*\"time\" + 0.003*\"question\" + 0.003*\"jews\" + 0.002*\"president\" + 0.002*\"true\" + 0.002*\"government\" + 0.002*\"israeli\" + 0.002*\"window\"\n",
      "2022-07-28 13:46:19,814 - topic #0 (0.100): 0.008*\"ax\" + 0.008*\"drive\" + 0.008*\"people\" + 0.006*\"god\" + 0.005*\"scsi\" + 0.004*\"card\" + 0.004*\"mb\" + 0.003*\"disk\" + 0.003*\"time\" + 0.003*\"bit\"\n",
      "2022-07-28 13:46:19,816 - topic diff=0.061661, rho=0.072270\n",
      "2022-07-28 13:46:19,817 - PROGRESS: pass 2, dispatched chunk #155 = documents up to #15600/18846, outstanding queue size 63\n",
      "2022-07-28 13:46:19,820 - PROGRESS: pass 2, dispatched chunk #156 = documents up to #15700/18846, outstanding queue size 63\n",
      "2022-07-28 13:46:19,820 - PROGRESS: pass 2, dispatched chunk #157 = documents up to #15800/18846, outstanding queue size 64\n",
      "2022-07-28 13:46:19,821 - PROGRESS: pass 2, dispatched chunk #158 = documents up to #15900/18846, outstanding queue size 65\n",
      "2022-07-28 13:46:19,821 - PROGRESS: pass 2, dispatched chunk #159 = documents up to #16000/18846, outstanding queue size 66\n",
      "2022-07-28 13:46:19,822 - PROGRESS: pass 2, dispatched chunk #160 = documents up to #16100/18846, outstanding queue size 67\n",
      "2022-07-28 13:46:19,825 - PROGRESS: pass 2, dispatched chunk #161 = documents up to #16200/18846, outstanding queue size 68\n",
      "2022-07-28 13:46:19,920 - PROGRESS: pass 2, dispatched chunk #162 = documents up to #16300/18846, outstanding queue size 60\n",
      "2022-07-28 13:46:19,921 - PROGRESS: pass 2, dispatched chunk #163 = documents up to #16400/18846, outstanding queue size 61\n",
      "2022-07-28 13:46:19,923 - PROGRESS: pass 2, dispatched chunk #164 = documents up to #16500/18846, outstanding queue size 62\n",
      "2022-07-28 13:46:19,924 - PROGRESS: pass 2, dispatched chunk #165 = documents up to #16600/18846, outstanding queue size 63\n",
      "2022-07-28 13:46:19,946 - PROGRESS: pass 2, dispatched chunk #166 = documents up to #16700/18846, outstanding queue size 60\n",
      "2022-07-28 13:46:19,947 - PROGRESS: pass 2, dispatched chunk #167 = documents up to #16800/18846, outstanding queue size 61\n",
      "2022-07-28 13:46:20,109 - merging changes from 1800 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:20,159 - topic #9 (0.100): 0.009*\"people\" + 0.003*\"israel\" + 0.003*\"time\" + 0.003*\"jews\" + 0.003*\"question\" + 0.002*\"president\" + 0.002*\"government\" + 0.002*\"israeli\" + 0.002*\"true\" + 0.002*\"children\"\n",
      "2022-07-28 13:46:20,163 - topic #2 (0.100): 0.006*\"space\" + 0.006*\"time\" + 0.005*\"people\" + 0.004*\"government\" + 0.003*\"power\" + 0.002*\"key\" + 0.002*\"car\" + 0.002*\"public\" + 0.002*\"encryption\" + 0.002*\"data\"\n",
      "2022-07-28 13:46:20,166 - topic #6 (0.100): 0.026*\"ax\" + 0.005*\"hz\" + 0.005*\"dos\" + 0.004*\"ww\" + 0.003*\"uw\" + 0.003*\"st\" + 0.003*\"appears\" + 0.003*\"water\" + 0.002*\"art\" + 0.002*\"scx\"\n",
      "2022-07-28 13:46:20,168 - topic #1 (0.100): 0.006*\"windows\" + 0.006*\"file\" + 0.005*\"software\" + 0.005*\"game\" + 0.005*\"mail\" + 0.004*\"program\" + 0.004*\"list\" + 0.004*\"time\" + 0.004*\"dos\" + 0.004*\"graphics\"\n",
      "2022-07-28 13:46:20,173 - topic #4 (0.100): 0.009*\"god\" + 0.008*\"people\" + 0.005*\"db\" + 0.004*\"jesus\" + 0.004*\"time\" + 0.004*\"gun\" + 0.003*\"key\" + 0.003*\"law\" + 0.003*\"christ\" + 0.003*\"armenians\"\n",
      "2022-07-28 13:46:20,188 - topic diff=0.069596, rho=0.072270\n",
      "2022-07-28 13:46:20,195 - PROGRESS: pass 2, dispatched chunk #168 = documents up to #16900/18846, outstanding queue size 58\n",
      "2022-07-28 13:46:20,224 - PROGRESS: pass 2, dispatched chunk #169 = documents up to #17000/18846, outstanding queue size 54\n",
      "2022-07-28 13:46:20,224 - PROGRESS: pass 2, dispatched chunk #170 = documents up to #17100/18846, outstanding queue size 55\n",
      "2022-07-28 13:46:20,225 - PROGRESS: pass 2, dispatched chunk #171 = documents up to #17200/18846, outstanding queue size 56\n",
      "2022-07-28 13:46:20,225 - PROGRESS: pass 2, dispatched chunk #172 = documents up to #17300/18846, outstanding queue size 57\n",
      "2022-07-28 13:46:20,226 - PROGRESS: pass 2, dispatched chunk #173 = documents up to #17400/18846, outstanding queue size 58\n",
      "2022-07-28 13:46:20,226 - PROGRESS: pass 2, dispatched chunk #174 = documents up to #17500/18846, outstanding queue size 59\n",
      "2022-07-28 13:46:20,227 - PROGRESS: pass 2, dispatched chunk #175 = documents up to #17600/18846, outstanding queue size 60\n",
      "2022-07-28 13:46:20,227 - PROGRESS: pass 2, dispatched chunk #176 = documents up to #17700/18846, outstanding queue size 61\n",
      "2022-07-28 13:46:20,228 - PROGRESS: pass 2, dispatched chunk #177 = documents up to #17800/18846, outstanding queue size 62\n",
      "2022-07-28 13:46:20,228 - PROGRESS: pass 2, dispatched chunk #178 = documents up to #17900/18846, outstanding queue size 63\n",
      "2022-07-28 13:46:20,228 - PROGRESS: pass 2, dispatched chunk #179 = documents up to #18000/18846, outstanding queue size 64\n",
      "2022-07-28 13:46:20,323 - PROGRESS: pass 2, dispatched chunk #180 = documents up to #18100/18846, outstanding queue size 57\n",
      "2022-07-28 13:46:20,419 - merging changes from 1500 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:20,575 - topic #1 (0.100): 0.006*\"file\" + 0.006*\"windows\" + 0.005*\"software\" + 0.005*\"game\" + 0.005*\"mail\" + 0.004*\"list\" + 0.004*\"program\" + 0.004*\"graphics\" + 0.004*\"time\" + 0.004*\"dos\"\n",
      "2022-07-28 13:46:20,583 - topic #7 (0.100): 0.049*\"ax\" + 0.011*\"jpeg\" + 0.007*\"car\" + 0.004*\"gif\" + 0.004*\"max\" + 0.004*\"image\" + 0.004*\"file\" + 0.003*\"people\" + 0.003*\"files\" + 0.003*\"time\"\n",
      "2022-07-28 13:46:20,588 - topic #0 (0.100): 0.008*\"drive\" + 0.007*\"people\" + 0.007*\"ax\" + 0.006*\"god\" + 0.005*\"scsi\" + 0.004*\"card\" + 0.004*\"mb\" + 0.004*\"disk\" + 0.003*\"time\" + 0.003*\"hard\"\n",
      "2022-07-28 13:46:20,590 - topic #9 (0.100): 0.009*\"people\" + 0.004*\"israel\" + 0.003*\"jews\" + 0.003*\"time\" + 0.003*\"president\" + 0.003*\"question\" + 0.002*\"government\" + 0.002*\"israeli\" + 0.002*\"true\" + 0.002*\"children\"\n",
      "2022-07-28 13:46:20,594 - topic #2 (0.100): 0.006*\"space\" + 0.006*\"time\" + 0.005*\"people\" + 0.004*\"government\" + 0.003*\"power\" + 0.003*\"key\" + 0.002*\"car\" + 0.002*\"public\" + 0.002*\"encryption\" + 0.002*\"data\"\n",
      "2022-07-28 13:46:20,606 - topic diff=0.065954, rho=0.072270\n",
      "2022-07-28 13:46:20,610 - PROGRESS: pass 2, dispatched chunk #181 = documents up to #18200/18846, outstanding queue size 56\n",
      "2022-07-28 13:46:20,614 - PROGRESS: pass 2, dispatched chunk #182 = documents up to #18300/18846, outstanding queue size 56\n",
      "2022-07-28 13:46:20,617 - PROGRESS: pass 2, dispatched chunk #183 = documents up to #18400/18846, outstanding queue size 57\n",
      "2022-07-28 13:46:20,618 - PROGRESS: pass 2, dispatched chunk #184 = documents up to #18500/18846, outstanding queue size 58\n",
      "2022-07-28 13:46:20,618 - PROGRESS: pass 2, dispatched chunk #185 = documents up to #18600/18846, outstanding queue size 59\n",
      "2022-07-28 13:46:20,618 - PROGRESS: pass 2, dispatched chunk #186 = documents up to #18700/18846, outstanding queue size 60\n",
      "2022-07-28 13:46:20,619 - PROGRESS: pass 2, dispatched chunk #187 = documents up to #18800/18846, outstanding queue size 61\n",
      "2022-07-28 13:46:20,619 - PROGRESS: pass 2, dispatched chunk #188 = documents up to #18846/18846, outstanding queue size 62\n",
      "2022-07-28 13:46:21,120 - merging changes from 1500 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:21,212 - topic #5 (0.100): 0.004*\"ax\" + 0.004*\"time\" + 0.003*\"people\" + 0.003*\"armenian\" + 0.002*\"book\" + 0.002*\"players\" + 0.002*\"set\" + 0.002*\"source\" + 0.002*\"sun\" + 0.002*\"file\"\n",
      "2022-07-28 13:46:21,249 - topic #6 (0.100): 0.023*\"ax\" + 0.005*\"hz\" + 0.004*\"dos\" + 0.003*\"ww\" + 0.003*\"st\" + 0.003*\"uw\" + 0.003*\"water\" + 0.003*\"appears\" + 0.002*\"battery\" + 0.002*\"art\"\n",
      "2022-07-28 13:46:21,254 - topic #2 (0.100): 0.006*\"time\" + 0.006*\"space\" + 0.005*\"people\" + 0.004*\"government\" + 0.003*\"power\" + 0.003*\"key\" + 0.002*\"car\" + 0.002*\"public\" + 0.002*\"encryption\" + 0.002*\"data\"\n",
      "2022-07-28 13:46:21,263 - topic #9 (0.100): 0.010*\"people\" + 0.004*\"israel\" + 0.003*\"jews\" + 0.003*\"time\" + 0.003*\"question\" + 0.002*\"president\" + 0.002*\"israeli\" + 0.002*\"government\" + 0.002*\"war\" + 0.002*\"true\"\n",
      "2022-07-28 13:46:21,268 - topic #8 (0.100): 0.489*\"ax\" + 0.040*\"max\" + 0.004*\"di\" + 0.003*\"ei\" + 0.002*\"armenian\" + 0.002*\"turkish\" + 0.002*\"bhj\" + 0.002*\"giz\" + 0.002*\"tm\" + 0.002*\"university\"\n",
      "2022-07-28 13:46:21,274 - topic diff=0.062304, rho=0.072270\n",
      "2022-07-28 13:46:21,472 - -10.575 per-word bound, 1525.4 perplexity estimate based on a held-out corpus of 46 documents with 2932 words\n",
      "2022-07-28 13:46:21,606 - merging changes from 4746 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:21,637 - topic #9 (0.100): 0.010*\"people\" + 0.004*\"israel\" + 0.003*\"jews\" + 0.003*\"time\" + 0.003*\"israeli\" + 0.003*\"question\" + 0.003*\"president\" + 0.002*\"government\" + 0.002*\"war\" + 0.002*\"true\"\n",
      "2022-07-28 13:46:21,639 - topic #8 (0.100): 0.484*\"ax\" + 0.040*\"max\" + 0.004*\"di\" + 0.003*\"ei\" + 0.002*\"armenian\" + 0.002*\"turkish\" + 0.002*\"bhj\" + 0.002*\"giz\" + 0.002*\"tm\" + 0.002*\"university\"\n",
      "2022-07-28 13:46:21,641 - topic #3 (0.100): 0.004*\"time\" + 0.004*\"team\" + 0.004*\"period\" + 0.003*\"play\" + 0.003*\"people\" + 0.003*\"pit\" + 0.002*\"file\" + 0.002*\"hockey\" + 0.002*\"goal\" + 0.002*\"det\"\n",
      "2022-07-28 13:46:21,642 - topic #0 (0.100): 0.009*\"drive\" + 0.007*\"people\" + 0.006*\"ax\" + 0.006*\"god\" + 0.005*\"scsi\" + 0.004*\"card\" + 0.004*\"mb\" + 0.004*\"disk\" + 0.004*\"hard\" + 0.003*\"time\"\n",
      "2022-07-28 13:46:21,643 - topic #7 (0.100): 0.047*\"ax\" + 0.010*\"jpeg\" + 0.007*\"car\" + 0.004*\"gif\" + 0.004*\"max\" + 0.004*\"image\" + 0.004*\"file\" + 0.003*\"people\" + 0.003*\"files\" + 0.003*\"time\"\n",
      "2022-07-28 13:46:21,644 - topic diff=0.054023, rho=0.072270\n",
      "2022-07-28 13:46:21,719 - -10.539 per-word bound, 1487.4 perplexity estimate based on a held-out corpus of 46 documents with 2932 words\n",
      "2022-07-28 13:46:21,720 - PROGRESS: pass 3, dispatched chunk #0 = documents up to #100/18846, outstanding queue size 1\n",
      "2022-07-28 13:46:21,722 - PROGRESS: pass 3, dispatched chunk #1 = documents up to #200/18846, outstanding queue size 2\n",
      "2022-07-28 13:46:21,722 - PROGRESS: pass 3, dispatched chunk #2 = documents up to #300/18846, outstanding queue size 3\n",
      "2022-07-28 13:46:21,723 - PROGRESS: pass 3, dispatched chunk #3 = documents up to #400/18846, outstanding queue size 4\n",
      "2022-07-28 13:46:21,723 - PROGRESS: pass 3, dispatched chunk #4 = documents up to #500/18846, outstanding queue size 5\n",
      "2022-07-28 13:46:21,723 - PROGRESS: pass 3, dispatched chunk #5 = documents up to #600/18846, outstanding queue size 6\n",
      "2022-07-28 13:46:21,724 - PROGRESS: pass 3, dispatched chunk #6 = documents up to #700/18846, outstanding queue size 7\n",
      "2022-07-28 13:46:21,724 - PROGRESS: pass 3, dispatched chunk #7 = documents up to #800/18846, outstanding queue size 8\n",
      "2022-07-28 13:46:21,726 - PROGRESS: pass 3, dispatched chunk #8 = documents up to #900/18846, outstanding queue size 9\n",
      "2022-07-28 13:46:21,726 - PROGRESS: pass 3, dispatched chunk #9 = documents up to #1000/18846, outstanding queue size 10\n",
      "2022-07-28 13:46:21,727 - PROGRESS: pass 3, dispatched chunk #10 = documents up to #1100/18846, outstanding queue size 11\n",
      "2022-07-28 13:46:21,727 - PROGRESS: pass 3, dispatched chunk #11 = documents up to #1200/18846, outstanding queue size 12\n",
      "2022-07-28 13:46:21,730 - PROGRESS: pass 3, dispatched chunk #12 = documents up to #1300/18846, outstanding queue size 13\n",
      "2022-07-28 13:46:21,731 - PROGRESS: pass 3, dispatched chunk #13 = documents up to #1400/18846, outstanding queue size 14\n",
      "2022-07-28 13:46:21,731 - PROGRESS: pass 3, dispatched chunk #14 = documents up to #1500/18846, outstanding queue size 15\n",
      "2022-07-28 13:46:21,732 - PROGRESS: pass 3, dispatched chunk #15 = documents up to #1600/18846, outstanding queue size 16\n",
      "2022-07-28 13:46:21,734 - PROGRESS: pass 3, dispatched chunk #16 = documents up to #1700/18846, outstanding queue size 17\n",
      "2022-07-28 13:46:21,734 - PROGRESS: pass 3, dispatched chunk #17 = documents up to #1800/18846, outstanding queue size 18\n",
      "2022-07-28 13:46:21,735 - PROGRESS: pass 3, dispatched chunk #18 = documents up to #1900/18846, outstanding queue size 19\n",
      "2022-07-28 13:46:21,735 - PROGRESS: pass 3, dispatched chunk #19 = documents up to #2000/18846, outstanding queue size 20\n",
      "2022-07-28 13:46:21,735 - PROGRESS: pass 3, dispatched chunk #20 = documents up to #2100/18846, outstanding queue size 21\n",
      "2022-07-28 13:46:21,736 - PROGRESS: pass 3, dispatched chunk #21 = documents up to #2200/18846, outstanding queue size 22\n",
      "2022-07-28 13:46:21,738 - PROGRESS: pass 3, dispatched chunk #22 = documents up to #2300/18846, outstanding queue size 23\n",
      "2022-07-28 13:46:21,739 - PROGRESS: pass 3, dispatched chunk #23 = documents up to #2400/18846, outstanding queue size 24\n",
      "2022-07-28 13:46:21,739 - PROGRESS: pass 3, dispatched chunk #24 = documents up to #2500/18846, outstanding queue size 25\n",
      "2022-07-28 13:46:21,739 - PROGRESS: pass 3, dispatched chunk #25 = documents up to #2600/18846, outstanding queue size 26\n",
      "2022-07-28 13:46:21,740 - PROGRESS: pass 3, dispatched chunk #26 = documents up to #2700/18846, outstanding queue size 27\n",
      "2022-07-28 13:46:21,740 - PROGRESS: pass 3, dispatched chunk #27 = documents up to #2800/18846, outstanding queue size 28\n",
      "2022-07-28 13:46:21,742 - PROGRESS: pass 3, dispatched chunk #28 = documents up to #2900/18846, outstanding queue size 29\n",
      "2022-07-28 13:46:21,743 - PROGRESS: pass 3, dispatched chunk #29 = documents up to #3000/18846, outstanding queue size 30\n",
      "2022-07-28 13:46:21,743 - PROGRESS: pass 3, dispatched chunk #30 = documents up to #3100/18846, outstanding queue size 31\n",
      "2022-07-28 13:46:21,744 - PROGRESS: pass 3, dispatched chunk #31 = documents up to #3200/18846, outstanding queue size 32\n",
      "2022-07-28 13:46:21,744 - PROGRESS: pass 3, dispatched chunk #32 = documents up to #3300/18846, outstanding queue size 33\n",
      "2022-07-28 13:46:21,748 - PROGRESS: pass 3, dispatched chunk #33 = documents up to #3400/18846, outstanding queue size 34\n",
      "2022-07-28 13:46:21,749 - PROGRESS: pass 3, dispatched chunk #34 = documents up to #3500/18846, outstanding queue size 35\n",
      "2022-07-28 13:46:21,749 - PROGRESS: pass 3, dispatched chunk #35 = documents up to #3600/18846, outstanding queue size 36\n",
      "2022-07-28 13:46:21,750 - PROGRESS: pass 3, dispatched chunk #36 = documents up to #3700/18846, outstanding queue size 37\n",
      "2022-07-28 13:46:21,765 - PROGRESS: pass 3, dispatched chunk #37 = documents up to #3800/18846, outstanding queue size 38\n",
      "2022-07-28 13:46:21,769 - PROGRESS: pass 3, dispatched chunk #38 = documents up to #3900/18846, outstanding queue size 39\n",
      "2022-07-28 13:46:21,771 - PROGRESS: pass 3, dispatched chunk #39 = documents up to #4000/18846, outstanding queue size 40\n",
      "2022-07-28 13:46:21,776 - PROGRESS: pass 3, dispatched chunk #40 = documents up to #4100/18846, outstanding queue size 41\n",
      "2022-07-28 13:46:21,783 - PROGRESS: pass 3, dispatched chunk #41 = documents up to #4200/18846, outstanding queue size 42\n",
      "2022-07-28 13:46:21,803 - PROGRESS: pass 3, dispatched chunk #42 = documents up to #4300/18846, outstanding queue size 41\n",
      "2022-07-28 13:46:21,905 - PROGRESS: pass 3, dispatched chunk #43 = documents up to #4400/18846, outstanding queue size 33\n",
      "2022-07-28 13:46:21,911 - PROGRESS: pass 3, dispatched chunk #44 = documents up to #4500/18846, outstanding queue size 34\n",
      "2022-07-28 13:46:21,912 - PROGRESS: pass 3, dispatched chunk #45 = documents up to #4600/18846, outstanding queue size 35\n",
      "2022-07-28 13:46:21,914 - PROGRESS: pass 3, dispatched chunk #46 = documents up to #4700/18846, outstanding queue size 36\n",
      "2022-07-28 13:46:21,916 - PROGRESS: pass 3, dispatched chunk #47 = documents up to #4800/18846, outstanding queue size 37\n",
      "2022-07-28 13:46:21,916 - PROGRESS: pass 3, dispatched chunk #48 = documents up to #4900/18846, outstanding queue size 38\n",
      "2022-07-28 13:46:21,917 - PROGRESS: pass 3, dispatched chunk #49 = documents up to #5000/18846, outstanding queue size 39\n",
      "2022-07-28 13:46:21,917 - PROGRESS: pass 3, dispatched chunk #50 = documents up to #5100/18846, outstanding queue size 40\n",
      "2022-07-28 13:46:21,933 - PROGRESS: pass 3, dispatched chunk #51 = documents up to #5200/18846, outstanding queue size 41\n",
      "2022-07-28 13:46:21,937 - PROGRESS: pass 3, dispatched chunk #52 = documents up to #5300/18846, outstanding queue size 42\n",
      "2022-07-28 13:46:21,946 - PROGRESS: pass 3, dispatched chunk #53 = documents up to #5400/18846, outstanding queue size 43\n",
      "2022-07-28 13:46:22,134 - merging changes from 1500 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:22,261 - topic #3 (0.100): 0.004*\"time\" + 0.004*\"team\" + 0.004*\"period\" + 0.003*\"play\" + 0.003*\"people\" + 0.003*\"pit\" + 0.002*\"det\" + 0.002*\"hockey\" + 0.002*\"file\" + 0.002*\"goal\"\n",
      "2022-07-28 13:46:22,269 - topic #2 (0.100): 0.006*\"space\" + 0.006*\"time\" + 0.005*\"people\" + 0.004*\"government\" + 0.003*\"power\" + 0.003*\"key\" + 0.002*\"car\" + 0.002*\"public\" + 0.002*\"encryption\" + 0.002*\"data\"\n",
      "2022-07-28 13:46:22,274 - topic #9 (0.100): 0.010*\"people\" + 0.004*\"israel\" + 0.003*\"jews\" + 0.003*\"time\" + 0.003*\"president\" + 0.003*\"israeli\" + 0.002*\"question\" + 0.002*\"government\" + 0.002*\"war\" + 0.002*\"true\"\n",
      "2022-07-28 13:46:22,278 - topic #6 (0.100): 0.021*\"ax\" + 0.005*\"hz\" + 0.005*\"dos\" + 0.003*\"st\" + 0.003*\"ww\" + 0.003*\"water\" + 0.003*\"battery\" + 0.003*\"uw\" + 0.002*\"appears\" + 0.002*\"art\"\n",
      "2022-07-28 13:46:22,282 - topic #4 (0.100): 0.010*\"god\" + 0.008*\"people\" + 0.005*\"jesus\" + 0.004*\"time\" + 0.004*\"db\" + 0.003*\"gun\" + 0.003*\"law\" + 0.003*\"key\" + 0.003*\"christ\" + 0.003*\"armenians\"\n",
      "2022-07-28 13:46:22,286 - topic diff=0.057174, rho=0.072082\n",
      "2022-07-28 13:46:22,290 - PROGRESS: pass 3, dispatched chunk #54 = documents up to #5500/18846, outstanding queue size 40\n",
      "2022-07-28 13:46:22,295 - PROGRESS: pass 3, dispatched chunk #55 = documents up to #5600/18846, outstanding queue size 40\n",
      "2022-07-28 13:46:22,299 - PROGRESS: pass 3, dispatched chunk #56 = documents up to #5700/18846, outstanding queue size 41\n",
      "2022-07-28 13:46:22,300 - PROGRESS: pass 3, dispatched chunk #57 = documents up to #5800/18846, outstanding queue size 42\n",
      "2022-07-28 13:46:22,303 - PROGRESS: pass 3, dispatched chunk #58 = documents up to #5900/18846, outstanding queue size 43\n",
      "2022-07-28 13:46:22,303 - PROGRESS: pass 3, dispatched chunk #59 = documents up to #6000/18846, outstanding queue size 44\n",
      "2022-07-28 13:46:22,304 - PROGRESS: pass 3, dispatched chunk #60 = documents up to #6100/18846, outstanding queue size 45\n",
      "2022-07-28 13:46:22,305 - PROGRESS: pass 3, dispatched chunk #61 = documents up to #6200/18846, outstanding queue size 46\n",
      "2022-07-28 13:46:22,311 - PROGRESS: pass 3, dispatched chunk #62 = documents up to #6300/18846, outstanding queue size 47\n",
      "2022-07-28 13:46:22,315 - PROGRESS: pass 3, dispatched chunk #63 = documents up to #6400/18846, outstanding queue size 48\n",
      "2022-07-28 13:46:22,353 - PROGRESS: pass 3, dispatched chunk #64 = documents up to #6500/18846, outstanding queue size 48\n",
      "2022-07-28 13:46:22,386 - PROGRESS: pass 3, dispatched chunk #65 = documents up to #6600/18846, outstanding queue size 47\n",
      "2022-07-28 13:46:22,394 - PROGRESS: pass 3, dispatched chunk #66 = documents up to #6700/18846, outstanding queue size 48\n",
      "2022-07-28 13:46:22,400 - PROGRESS: pass 3, dispatched chunk #67 = documents up to #6800/18846, outstanding queue size 48\n",
      "2022-07-28 13:46:22,434 - PROGRESS: pass 3, dispatched chunk #68 = documents up to #6900/18846, outstanding queue size 49\n",
      "2022-07-28 13:46:22,493 - PROGRESS: pass 3, dispatched chunk #69 = documents up to #7000/18846, outstanding queue size 48\n",
      "2022-07-28 13:46:22,565 - PROGRESS: pass 3, dispatched chunk #70 = documents up to #7100/18846, outstanding queue size 47\n",
      "2022-07-28 13:46:22,572 - PROGRESS: pass 3, dispatched chunk #71 = documents up to #7200/18846, outstanding queue size 48\n",
      "2022-07-28 13:46:22,573 - PROGRESS: pass 3, dispatched chunk #72 = documents up to #7300/18846, outstanding queue size 49\n",
      "2022-07-28 13:46:22,581 - PROGRESS: pass 3, dispatched chunk #73 = documents up to #7400/18846, outstanding queue size 49\n",
      "2022-07-28 13:46:22,605 - PROGRESS: pass 3, dispatched chunk #74 = documents up to #7500/18846, outstanding queue size 49\n",
      "2022-07-28 13:46:22,646 - PROGRESS: pass 3, dispatched chunk #75 = documents up to #7600/18846, outstanding queue size 50\n",
      "2022-07-28 13:46:22,685 - PROGRESS: pass 3, dispatched chunk #76 = documents up to #7700/18846, outstanding queue size 49\n",
      "2022-07-28 13:46:22,713 - PROGRESS: pass 3, dispatched chunk #77 = documents up to #7800/18846, outstanding queue size 49\n",
      "2022-07-28 13:46:22,723 - PROGRESS: pass 3, dispatched chunk #78 = documents up to #7900/18846, outstanding queue size 50\n",
      "2022-07-28 13:46:22,958 - merging changes from 1500 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:23,084 - topic #8 (0.100): 0.478*\"ax\" + 0.039*\"max\" + 0.004*\"di\" + 0.003*\"ei\" + 0.002*\"armenian\" + 0.002*\"tm\" + 0.002*\"turkish\" + 0.002*\"giz\" + 0.002*\"bhj\" + 0.002*\"university\"\n",
      "2022-07-28 13:46:23,089 - topic #0 (0.100): 0.009*\"drive\" + 0.007*\"people\" + 0.006*\"god\" + 0.005*\"ax\" + 0.005*\"scsi\" + 0.005*\"card\" + 0.004*\"mb\" + 0.004*\"disk\" + 0.003*\"hard\" + 0.003*\"bus\"\n",
      "2022-07-28 13:46:23,095 - topic #4 (0.100): 0.010*\"god\" + 0.008*\"people\" + 0.005*\"jesus\" + 0.004*\"time\" + 0.003*\"gun\" + 0.003*\"db\" + 0.003*\"key\" + 0.003*\"law\" + 0.003*\"christ\" + 0.003*\"life\"\n",
      "2022-07-28 13:46:23,098 - topic #2 (0.100): 0.006*\"time\" + 0.006*\"space\" + 0.005*\"people\" + 0.004*\"government\" + 0.003*\"power\" + 0.003*\"key\" + 0.002*\"car\" + 0.002*\"public\" + 0.002*\"encryption\" + 0.002*\"data\"\n",
      "2022-07-28 13:46:23,101 - topic #5 (0.100): 0.003*\"time\" + 0.003*\"armenian\" + 0.003*\"ax\" + 0.003*\"people\" + 0.002*\"players\" + 0.002*\"book\" + 0.002*\"set\" + 0.002*\"source\" + 0.002*\"azerbaijan\" + 0.002*\"mail\"\n",
      "2022-07-28 13:46:23,105 - topic diff=0.069537, rho=0.072082\n",
      "2022-07-28 13:46:23,108 - PROGRESS: pass 3, dispatched chunk #79 = documents up to #8000/18846, outstanding queue size 50\n",
      "2022-07-28 13:46:23,113 - PROGRESS: pass 3, dispatched chunk #80 = documents up to #8100/18846, outstanding queue size 50\n",
      "2022-07-28 13:46:23,115 - PROGRESS: pass 3, dispatched chunk #81 = documents up to #8200/18846, outstanding queue size 51\n",
      "2022-07-28 13:46:23,117 - PROGRESS: pass 3, dispatched chunk #82 = documents up to #8300/18846, outstanding queue size 52\n",
      "2022-07-28 13:46:23,118 - PROGRESS: pass 3, dispatched chunk #83 = documents up to #8400/18846, outstanding queue size 53\n",
      "2022-07-28 13:46:23,122 - PROGRESS: pass 3, dispatched chunk #84 = documents up to #8500/18846, outstanding queue size 54\n",
      "2022-07-28 13:46:23,152 - PROGRESS: pass 3, dispatched chunk #85 = documents up to #8600/18846, outstanding queue size 55\n",
      "2022-07-28 13:46:23,157 - PROGRESS: pass 3, dispatched chunk #86 = documents up to #8700/18846, outstanding queue size 56\n",
      "2022-07-28 13:46:23,216 - PROGRESS: pass 3, dispatched chunk #87 = documents up to #8800/18846, outstanding queue size 50\n",
      "2022-07-28 13:46:23,218 - PROGRESS: pass 3, dispatched chunk #88 = documents up to #8900/18846, outstanding queue size 51\n",
      "2022-07-28 13:46:23,218 - PROGRESS: pass 3, dispatched chunk #89 = documents up to #9000/18846, outstanding queue size 52\n",
      "2022-07-28 13:46:23,219 - PROGRESS: pass 3, dispatched chunk #90 = documents up to #9100/18846, outstanding queue size 53\n",
      "2022-07-28 13:46:23,231 - PROGRESS: pass 3, dispatched chunk #91 = documents up to #9200/18846, outstanding queue size 53\n",
      "2022-07-28 13:46:23,350 - PROGRESS: pass 3, dispatched chunk #92 = documents up to #9300/18846, outstanding queue size 50\n",
      "2022-07-28 13:46:23,350 - PROGRESS: pass 3, dispatched chunk #93 = documents up to #9400/18846, outstanding queue size 51\n",
      "2022-07-28 13:46:23,363 - PROGRESS: pass 3, dispatched chunk #94 = documents up to #9500/18846, outstanding queue size 52\n",
      "2022-07-28 13:46:23,370 - PROGRESS: pass 3, dispatched chunk #95 = documents up to #9600/18846, outstanding queue size 53\n",
      "2022-07-28 13:46:23,384 - PROGRESS: pass 3, dispatched chunk #96 = documents up to #9700/18846, outstanding queue size 54\n",
      "2022-07-28 13:46:23,551 - merging changes from 1600 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:23,651 - topic #5 (0.100): 0.003*\"time\" + 0.003*\"armenian\" + 0.003*\"people\" + 0.003*\"ax\" + 0.003*\"players\" + 0.002*\"book\" + 0.002*\"source\" + 0.002*\"set\" + 0.002*\"azerbaijan\" + 0.002*\"mail\"\n",
      "2022-07-28 13:46:23,653 - topic #7 (0.100): 0.036*\"ax\" + 0.014*\"jpeg\" + 0.007*\"car\" + 0.006*\"gif\" + 0.005*\"image\" + 0.005*\"file\" + 0.003*\"format\" + 0.003*\"color\" + 0.003*\"max\" + 0.003*\"images\"\n",
      "2022-07-28 13:46:23,656 - topic #0 (0.100): 0.009*\"drive\" + 0.007*\"people\" + 0.006*\"scsi\" + 0.005*\"god\" + 0.005*\"ax\" + 0.005*\"mb\" + 0.005*\"card\" + 0.004*\"disk\" + 0.004*\"hard\" + 0.003*\"bus\"\n",
      "2022-07-28 13:46:23,658 - topic #1 (0.100): 0.006*\"file\" + 0.006*\"windows\" + 0.005*\"software\" + 0.005*\"mail\" + 0.005*\"program\" + 0.004*\"game\" + 0.004*\"ftp\" + 0.004*\"dos\" + 0.004*\"graphics\" + 0.004*\"list\"\n",
      "2022-07-28 13:46:23,661 - topic #8 (0.100): 0.467*\"ax\" + 0.038*\"max\" + 0.004*\"di\" + 0.003*\"ei\" + 0.002*\"armenian\" + 0.002*\"turkish\" + 0.002*\"tm\" + 0.002*\"giz\" + 0.002*\"bhj\" + 0.002*\"genocide\"\n",
      "2022-07-28 13:46:23,662 - topic diff=0.064321, rho=0.072082\n",
      "2022-07-28 13:46:23,663 - PROGRESS: pass 3, dispatched chunk #97 = documents up to #9800/18846, outstanding queue size 52\n",
      "2022-07-28 13:46:23,686 - PROGRESS: pass 3, dispatched chunk #98 = documents up to #9900/18846, outstanding queue size 52\n",
      "2022-07-28 13:46:23,686 - PROGRESS: pass 3, dispatched chunk #99 = documents up to #10000/18846, outstanding queue size 53\n",
      "2022-07-28 13:46:23,687 - PROGRESS: pass 3, dispatched chunk #100 = documents up to #10100/18846, outstanding queue size 54\n",
      "2022-07-28 13:46:23,687 - PROGRESS: pass 3, dispatched chunk #101 = documents up to #10200/18846, outstanding queue size 55\n",
      "2022-07-28 13:46:23,688 - PROGRESS: pass 3, dispatched chunk #102 = documents up to #10300/18846, outstanding queue size 56\n",
      "2022-07-28 13:46:23,688 - PROGRESS: pass 3, dispatched chunk #103 = documents up to #10400/18846, outstanding queue size 57\n",
      "2022-07-28 13:46:23,689 - PROGRESS: pass 3, dispatched chunk #104 = documents up to #10500/18846, outstanding queue size 58\n",
      "2022-07-28 13:46:23,689 - PROGRESS: pass 3, dispatched chunk #105 = documents up to #10600/18846, outstanding queue size 59\n",
      "2022-07-28 13:46:23,690 - PROGRESS: pass 3, dispatched chunk #106 = documents up to #10700/18846, outstanding queue size 60\n",
      "2022-07-28 13:46:23,690 - PROGRESS: pass 3, dispatched chunk #107 = documents up to #10800/18846, outstanding queue size 61\n",
      "2022-07-28 13:46:23,727 - PROGRESS: pass 3, dispatched chunk #108 = documents up to #10900/18846, outstanding queue size 53\n",
      "2022-07-28 13:46:23,760 - PROGRESS: pass 3, dispatched chunk #109 = documents up to #11000/18846, outstanding queue size 51\n",
      "2022-07-28 13:46:23,761 - PROGRESS: pass 3, dispatched chunk #110 = documents up to #11100/18846, outstanding queue size 52\n",
      "2022-07-28 13:46:23,761 - PROGRESS: pass 3, dispatched chunk #111 = documents up to #11200/18846, outstanding queue size 53\n",
      "2022-07-28 13:46:23,763 - PROGRESS: pass 3, dispatched chunk #112 = documents up to #11300/18846, outstanding queue size 54\n",
      "2022-07-28 13:46:23,997 - merging changes from 1800 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:24,067 - topic #9 (0.100): 0.010*\"people\" + 0.004*\"israel\" + 0.003*\"jews\" + 0.003*\"time\" + 0.003*\"president\" + 0.003*\"government\" + 0.003*\"question\" + 0.003*\"israeli\" + 0.002*\"war\" + 0.002*\"true\"\n",
      "2022-07-28 13:46:24,069 - topic #0 (0.100): 0.009*\"drive\" + 0.007*\"people\" + 0.006*\"scsi\" + 0.005*\"god\" + 0.005*\"mb\" + 0.005*\"ax\" + 0.005*\"card\" + 0.004*\"disk\" + 0.004*\"hard\" + 0.003*\"bus\"\n",
      "2022-07-28 13:46:24,071 - topic #4 (0.100): 0.011*\"god\" + 0.008*\"people\" + 0.005*\"jesus\" + 0.004*\"time\" + 0.003*\"christ\" + 0.003*\"gun\" + 0.003*\"law\" + 0.003*\"key\" + 0.003*\"db\" + 0.003*\"life\"\n",
      "2022-07-28 13:46:24,072 - topic #1 (0.100): 0.007*\"file\" + 0.006*\"windows\" + 0.005*\"software\" + 0.005*\"program\" + 0.005*\"mail\" + 0.004*\"ftp\" + 0.004*\"game\" + 0.004*\"dos\" + 0.004*\"graphics\" + 0.004*\"list\"\n",
      "2022-07-28 13:46:24,074 - topic #6 (0.100): 0.016*\"ax\" + 0.007*\"hz\" + 0.005*\"ww\" + 0.004*\"dos\" + 0.004*\"uw\" + 0.004*\"scx\" + 0.003*\"st\" + 0.003*\"zd\" + 0.003*\"cj\" + 0.003*\"tl\"\n",
      "2022-07-28 13:46:24,076 - topic diff=0.060899, rho=0.072082\n",
      "2022-07-28 13:46:24,087 - PROGRESS: pass 3, dispatched chunk #113 = documents up to #11400/18846, outstanding queue size 50\n",
      "2022-07-28 13:46:24,112 - PROGRESS: pass 3, dispatched chunk #114 = documents up to #11500/18846, outstanding queue size 44\n",
      "2022-07-28 13:46:24,116 - PROGRESS: pass 3, dispatched chunk #115 = documents up to #11600/18846, outstanding queue size 45\n",
      "2022-07-28 13:46:24,118 - PROGRESS: pass 3, dispatched chunk #116 = documents up to #11700/18846, outstanding queue size 46\n",
      "2022-07-28 13:46:24,120 - PROGRESS: pass 3, dispatched chunk #117 = documents up to #11800/18846, outstanding queue size 47\n",
      "2022-07-28 13:46:24,121 - PROGRESS: pass 3, dispatched chunk #118 = documents up to #11900/18846, outstanding queue size 48\n",
      "2022-07-28 13:46:24,123 - PROGRESS: pass 3, dispatched chunk #119 = documents up to #12000/18846, outstanding queue size 49\n",
      "2022-07-28 13:46:24,124 - PROGRESS: pass 3, dispatched chunk #120 = documents up to #12100/18846, outstanding queue size 50\n",
      "2022-07-28 13:46:24,125 - PROGRESS: pass 3, dispatched chunk #121 = documents up to #12200/18846, outstanding queue size 51\n",
      "2022-07-28 13:46:24,127 - PROGRESS: pass 3, dispatched chunk #122 = documents up to #12300/18846, outstanding queue size 52\n",
      "2022-07-28 13:46:24,129 - PROGRESS: pass 3, dispatched chunk #123 = documents up to #12400/18846, outstanding queue size 53\n",
      "2022-07-28 13:46:24,131 - PROGRESS: pass 3, dispatched chunk #124 = documents up to #12500/18846, outstanding queue size 54\n",
      "2022-07-28 13:46:24,133 - PROGRESS: pass 3, dispatched chunk #125 = documents up to #12600/18846, outstanding queue size 55\n",
      "2022-07-28 13:46:24,135 - PROGRESS: pass 3, dispatched chunk #126 = documents up to #12700/18846, outstanding queue size 56\n",
      "2022-07-28 13:46:24,137 - PROGRESS: pass 3, dispatched chunk #127 = documents up to #12800/18846, outstanding queue size 57\n",
      "2022-07-28 13:46:24,160 - PROGRESS: pass 3, dispatched chunk #128 = documents up to #12900/18846, outstanding queue size 57\n",
      "2022-07-28 13:46:24,163 - PROGRESS: pass 3, dispatched chunk #129 = documents up to #13000/18846, outstanding queue size 58\n",
      "2022-07-28 13:46:24,183 - PROGRESS: pass 3, dispatched chunk #130 = documents up to #13100/18846, outstanding queue size 57\n",
      "2022-07-28 13:46:24,197 - PROGRESS: pass 3, dispatched chunk #131 = documents up to #13200/18846, outstanding queue size 58\n",
      "2022-07-28 13:46:24,219 - PROGRESS: pass 3, dispatched chunk #132 = documents up to #13300/18846, outstanding queue size 59\n",
      "2022-07-28 13:46:24,219 - PROGRESS: pass 3, dispatched chunk #133 = documents up to #13400/18846, outstanding queue size 60\n",
      "2022-07-28 13:46:24,220 - PROGRESS: pass 3, dispatched chunk #134 = documents up to #13500/18846, outstanding queue size 61\n",
      "2022-07-28 13:46:24,230 - PROGRESS: pass 3, dispatched chunk #135 = documents up to #13600/18846, outstanding queue size 60\n",
      "2022-07-28 13:46:24,236 - PROGRESS: pass 3, dispatched chunk #136 = documents up to #13700/18846, outstanding queue size 61\n",
      "2022-07-28 13:46:24,242 - PROGRESS: pass 3, dispatched chunk #137 = documents up to #13800/18846, outstanding queue size 62\n",
      "2022-07-28 13:46:24,499 - merging changes from 1800 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:24,573 - topic #6 (0.100): 0.016*\"ax\" + 0.007*\"hz\" + 0.005*\"ww\" + 0.004*\"dos\" + 0.004*\"uw\" + 0.004*\"scx\" + 0.003*\"st\" + 0.003*\"zd\" + 0.003*\"cj\" + 0.003*\"battery\"\n",
      "2022-07-28 13:46:24,576 - topic #7 (0.100): 0.034*\"ax\" + 0.013*\"jpeg\" + 0.007*\"car\" + 0.006*\"gif\" + 0.005*\"image\" + 0.005*\"file\" + 0.003*\"format\" + 0.003*\"color\" + 0.003*\"files\" + 0.003*\"people\"\n",
      "2022-07-28 13:46:24,584 - topic #9 (0.100): 0.010*\"people\" + 0.004*\"israel\" + 0.003*\"jews\" + 0.003*\"time\" + 0.003*\"president\" + 0.003*\"government\" + 0.003*\"question\" + 0.003*\"israeli\" + 0.002*\"war\" + 0.002*\"children\"\n",
      "2022-07-28 13:46:24,586 - topic #5 (0.100): 0.003*\"time\" + 0.003*\"armenian\" + 0.003*\"people\" + 0.003*\"ax\" + 0.003*\"players\" + 0.002*\"book\" + 0.002*\"source\" + 0.002*\"set\" + 0.002*\"azerbaijan\" + 0.002*\"sun\"\n",
      "2022-07-28 13:46:24,589 - topic #4 (0.100): 0.011*\"god\" + 0.008*\"people\" + 0.005*\"jesus\" + 0.004*\"time\" + 0.003*\"gun\" + 0.003*\"law\" + 0.003*\"christ\" + 0.003*\"key\" + 0.003*\"life\" + 0.003*\"db\"\n",
      "2022-07-28 13:46:24,592 - topic diff=0.054545, rho=0.072082\n",
      "2022-07-28 13:46:24,595 - PROGRESS: pass 3, dispatched chunk #138 = documents up to #13900/18846, outstanding queue size 57\n",
      "2022-07-28 13:46:24,600 - PROGRESS: pass 3, dispatched chunk #139 = documents up to #14000/18846, outstanding queue size 57\n",
      "2022-07-28 13:46:24,602 - PROGRESS: pass 3, dispatched chunk #140 = documents up to #14100/18846, outstanding queue size 58\n",
      "2022-07-28 13:46:24,603 - PROGRESS: pass 3, dispatched chunk #141 = documents up to #14200/18846, outstanding queue size 59\n",
      "2022-07-28 13:46:24,603 - PROGRESS: pass 3, dispatched chunk #142 = documents up to #14300/18846, outstanding queue size 60\n",
      "2022-07-28 13:46:24,604 - PROGRESS: pass 3, dispatched chunk #143 = documents up to #14400/18846, outstanding queue size 61\n",
      "2022-07-28 13:46:24,604 - PROGRESS: pass 3, dispatched chunk #144 = documents up to #14500/18846, outstanding queue size 62\n",
      "2022-07-28 13:46:24,604 - PROGRESS: pass 3, dispatched chunk #145 = documents up to #14600/18846, outstanding queue size 63\n",
      "2022-07-28 13:46:24,605 - PROGRESS: pass 3, dispatched chunk #146 = documents up to #14700/18846, outstanding queue size 64\n",
      "2022-07-28 13:46:24,605 - PROGRESS: pass 3, dispatched chunk #147 = documents up to #14800/18846, outstanding queue size 65\n",
      "2022-07-28 13:46:24,606 - PROGRESS: pass 3, dispatched chunk #148 = documents up to #14900/18846, outstanding queue size 66\n",
      "2022-07-28 13:46:24,606 - PROGRESS: pass 3, dispatched chunk #149 = documents up to #15000/18846, outstanding queue size 67\n",
      "2022-07-28 13:46:24,607 - PROGRESS: pass 3, dispatched chunk #150 = documents up to #15100/18846, outstanding queue size 68\n",
      "2022-07-28 13:46:24,611 - PROGRESS: pass 3, dispatched chunk #151 = documents up to #15200/18846, outstanding queue size 69\n",
      "2022-07-28 13:46:24,656 - PROGRESS: pass 3, dispatched chunk #152 = documents up to #15300/18846, outstanding queue size 69\n",
      "2022-07-28 13:46:24,660 - PROGRESS: pass 3, dispatched chunk #153 = documents up to #15400/18846, outstanding queue size 70\n",
      "2022-07-28 13:46:24,663 - PROGRESS: pass 3, dispatched chunk #154 = documents up to #15500/18846, outstanding queue size 71\n",
      "2022-07-28 13:46:24,670 - PROGRESS: pass 3, dispatched chunk #155 = documents up to #15600/18846, outstanding queue size 72\n",
      "2022-07-28 13:46:24,703 - PROGRESS: pass 3, dispatched chunk #156 = documents up to #15700/18846, outstanding queue size 73\n",
      "2022-07-28 13:46:24,724 - PROGRESS: pass 3, dispatched chunk #157 = documents up to #15800/18846, outstanding queue size 72\n",
      "2022-07-28 13:46:24,728 - PROGRESS: pass 3, dispatched chunk #158 = documents up to #15900/18846, outstanding queue size 73\n",
      "2022-07-28 13:46:24,757 - PROGRESS: pass 3, dispatched chunk #159 = documents up to #16000/18846, outstanding queue size 68\n",
      "2022-07-28 13:46:24,770 - PROGRESS: pass 3, dispatched chunk #160 = documents up to #16100/18846, outstanding queue size 69\n",
      "2022-07-28 13:46:24,794 - PROGRESS: pass 3, dispatched chunk #161 = documents up to #16200/18846, outstanding queue size 68\n",
      "2022-07-28 13:46:24,795 - PROGRESS: pass 3, dispatched chunk #162 = documents up to #16300/18846, outstanding queue size 69\n",
      "2022-07-28 13:46:24,825 - PROGRESS: pass 3, dispatched chunk #163 = documents up to #16400/18846, outstanding queue size 70\n",
      "2022-07-28 13:46:24,889 - merging changes from 1500 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:24,946 - topic #1 (0.100): 0.006*\"file\" + 0.006*\"windows\" + 0.005*\"software\" + 0.005*\"program\" + 0.005*\"mail\" + 0.004*\"graphics\" + 0.004*\"image\" + 0.004*\"ftp\" + 0.004*\"list\" + 0.004*\"dos\"\n",
      "2022-07-28 13:46:24,953 - topic #0 (0.100): 0.010*\"drive\" + 0.007*\"people\" + 0.006*\"scsi\" + 0.005*\"mb\" + 0.005*\"god\" + 0.005*\"card\" + 0.004*\"disk\" + 0.004*\"ax\" + 0.004*\"hard\" + 0.004*\"bus\"\n",
      "2022-07-28 13:46:24,956 - topic #2 (0.100): 0.007*\"space\" + 0.006*\"time\" + 0.005*\"people\" + 0.004*\"government\" + 0.003*\"power\" + 0.003*\"key\" + 0.003*\"car\" + 0.002*\"encryption\" + 0.002*\"public\" + 0.002*\"data\"\n",
      "2022-07-28 13:46:24,960 - topic #6 (0.100): 0.015*\"ax\" + 0.007*\"hz\" + 0.005*\"ww\" + 0.004*\"dos\" + 0.004*\"uw\" + 0.004*\"scx\" + 0.003*\"st\" + 0.003*\"zd\" + 0.003*\"cj\" + 0.003*\"battery\"\n",
      "2022-07-28 13:46:24,965 - topic #5 (0.100): 0.003*\"time\" + 0.003*\"armenian\" + 0.003*\"people\" + 0.003*\"book\" + 0.002*\"ax\" + 0.002*\"players\" + 0.002*\"source\" + 0.002*\"set\" + 0.002*\"azerbaijan\" + 0.002*\"sun\"\n",
      "2022-07-28 13:46:24,968 - topic diff=0.055750, rho=0.072082\n",
      "2022-07-28 13:46:24,971 - PROGRESS: pass 3, dispatched chunk #164 = documents up to #16500/18846, outstanding queue size 68\n",
      "2022-07-28 13:46:24,977 - PROGRESS: pass 3, dispatched chunk #165 = documents up to #16600/18846, outstanding queue size 68\n",
      "2022-07-28 13:46:24,980 - PROGRESS: pass 3, dispatched chunk #166 = documents up to #16700/18846, outstanding queue size 69\n",
      "2022-07-28 13:46:24,981 - PROGRESS: pass 3, dispatched chunk #167 = documents up to #16800/18846, outstanding queue size 70\n",
      "2022-07-28 13:46:24,988 - PROGRESS: pass 3, dispatched chunk #168 = documents up to #16900/18846, outstanding queue size 70\n",
      "2022-07-28 13:46:24,990 - PROGRESS: pass 3, dispatched chunk #169 = documents up to #17000/18846, outstanding queue size 71\n",
      "2022-07-28 13:46:24,992 - PROGRESS: pass 3, dispatched chunk #170 = documents up to #17100/18846, outstanding queue size 72\n",
      "2022-07-28 13:46:24,993 - PROGRESS: pass 3, dispatched chunk #171 = documents up to #17200/18846, outstanding queue size 73\n",
      "2022-07-28 13:46:24,995 - PROGRESS: pass 3, dispatched chunk #172 = documents up to #17300/18846, outstanding queue size 74\n",
      "2022-07-28 13:46:24,997 - PROGRESS: pass 3, dispatched chunk #173 = documents up to #17400/18846, outstanding queue size 75\n",
      "2022-07-28 13:46:25,000 - PROGRESS: pass 3, dispatched chunk #174 = documents up to #17500/18846, outstanding queue size 76\n",
      "2022-07-28 13:46:25,013 - PROGRESS: pass 3, dispatched chunk #175 = documents up to #17600/18846, outstanding queue size 77\n",
      "2022-07-28 13:46:25,035 - PROGRESS: pass 3, dispatched chunk #176 = documents up to #17700/18846, outstanding queue size 78\n",
      "2022-07-28 13:46:25,040 - PROGRESS: pass 3, dispatched chunk #177 = documents up to #17800/18846, outstanding queue size 79\n",
      "2022-07-28 13:46:25,073 - PROGRESS: pass 3, dispatched chunk #178 = documents up to #17900/18846, outstanding queue size 80\n",
      "2022-07-28 13:46:25,157 - PROGRESS: pass 3, dispatched chunk #179 = documents up to #18000/18846, outstanding queue size 80\n",
      "2022-07-28 13:46:25,192 - PROGRESS: pass 3, dispatched chunk #180 = documents up to #18100/18846, outstanding queue size 80\n",
      "2022-07-28 13:46:25,212 - PROGRESS: pass 3, dispatched chunk #181 = documents up to #18200/18846, outstanding queue size 81\n",
      "2022-07-28 13:46:25,217 - PROGRESS: pass 3, dispatched chunk #182 = documents up to #18300/18846, outstanding queue size 82\n",
      "2022-07-28 13:46:25,237 - PROGRESS: pass 3, dispatched chunk #183 = documents up to #18400/18846, outstanding queue size 83\n",
      "2022-07-28 13:46:25,253 - PROGRESS: pass 3, dispatched chunk #184 = documents up to #18500/18846, outstanding queue size 84\n",
      "2022-07-28 13:46:25,287 - PROGRESS: pass 3, dispatched chunk #185 = documents up to #18600/18846, outstanding queue size 85\n",
      "2022-07-28 13:46:25,315 - PROGRESS: pass 3, dispatched chunk #186 = documents up to #18700/18846, outstanding queue size 85\n",
      "2022-07-28 13:46:25,358 - PROGRESS: pass 3, dispatched chunk #187 = documents up to #18800/18846, outstanding queue size 81\n",
      "2022-07-28 13:46:25,361 - PROGRESS: pass 3, dispatched chunk #188 = documents up to #18846/18846, outstanding queue size 82\n",
      "2022-07-28 13:46:25,703 - merging changes from 1500 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:25,768 - topic #5 (0.100): 0.004*\"armenian\" + 0.003*\"time\" + 0.003*\"people\" + 0.003*\"book\" + 0.002*\"players\" + 0.002*\"ax\" + 0.002*\"source\" + 0.002*\"azerbaijan\" + 0.002*\"set\" + 0.002*\"sun\"\n",
      "2022-07-28 13:46:25,770 - topic #3 (0.100): 0.005*\"team\" + 0.004*\"period\" + 0.004*\"play\" + 0.004*\"time\" + 0.003*\"game\" + 0.003*\"hockey\" + 0.003*\"pit\" + 0.002*\"people\" + 0.002*\"goal\" + 0.002*\"power\"\n",
      "2022-07-28 13:46:25,772 - topic #4 (0.100): 0.011*\"god\" + 0.009*\"people\" + 0.005*\"jesus\" + 0.005*\"db\" + 0.004*\"time\" + 0.004*\"gun\" + 0.003*\"law\" + 0.003*\"christ\" + 0.003*\"key\" + 0.003*\"life\"\n",
      "2022-07-28 13:46:25,773 - topic #9 (0.100): 0.011*\"people\" + 0.004*\"israel\" + 0.004*\"jews\" + 0.003*\"president\" + 0.003*\"time\" + 0.003*\"government\" + 0.003*\"war\" + 0.003*\"question\" + 0.003*\"israeli\" + 0.002*\"children\"\n",
      "2022-07-28 13:46:25,775 - topic #0 (0.100): 0.010*\"drive\" + 0.007*\"people\" + 0.006*\"scsi\" + 0.005*\"mb\" + 0.005*\"card\" + 0.005*\"god\" + 0.004*\"disk\" + 0.004*\"ax\" + 0.004*\"hard\" + 0.004*\"bus\"\n",
      "2022-07-28 13:46:25,776 - topic diff=0.070403, rho=0.072082\n",
      "2022-07-28 13:46:26,071 - -10.540 per-word bound, 1489.2 perplexity estimate based on a held-out corpus of 46 documents with 2932 words\n",
      "2022-07-28 13:46:26,555 - merging changes from 7646 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:26,586 - topic #2 (0.100): 0.006*\"space\" + 0.006*\"time\" + 0.005*\"people\" + 0.004*\"government\" + 0.003*\"power\" + 0.003*\"car\" + 0.003*\"key\" + 0.002*\"encryption\" + 0.002*\"public\" + 0.002*\"data\"\n",
      "2022-07-28 13:46:26,587 - topic #3 (0.100): 0.005*\"team\" + 0.004*\"play\" + 0.004*\"period\" + 0.004*\"time\" + 0.003*\"game\" + 0.003*\"hockey\" + 0.003*\"pit\" + 0.002*\"goal\" + 0.002*\"people\" + 0.002*\"season\"\n",
      "2022-07-28 13:46:26,589 - topic #1 (0.100): 0.007*\"file\" + 0.006*\"windows\" + 0.005*\"software\" + 0.005*\"mail\" + 0.005*\"program\" + 0.004*\"dos\" + 0.004*\"ftp\" + 0.004*\"list\" + 0.004*\"graphics\" + 0.004*\"image\"\n",
      "2022-07-28 13:46:26,590 - topic #7 (0.100): 0.030*\"ax\" + 0.013*\"jpeg\" + 0.008*\"car\" + 0.006*\"gif\" + 0.005*\"image\" + 0.004*\"file\" + 0.003*\"format\" + 0.003*\"images\" + 0.003*\"color\" + 0.003*\"files\"\n",
      "2022-07-28 13:46:26,591 - topic #4 (0.100): 0.011*\"god\" + 0.009*\"people\" + 0.005*\"jesus\" + 0.004*\"time\" + 0.004*\"db\" + 0.004*\"gun\" + 0.003*\"law\" + 0.003*\"christ\" + 0.003*\"life\" + 0.003*\"key\"\n",
      "2022-07-28 13:46:26,592 - topic diff=0.045619, rho=0.072082\n",
      "2022-07-28 13:46:26,666 - -10.512 per-word bound, 1460.0 perplexity estimate based on a held-out corpus of 46 documents with 2932 words\n",
      "2022-07-28 13:46:26,667 - PROGRESS: pass 4, dispatched chunk #0 = documents up to #100/18846, outstanding queue size 1\n",
      "2022-07-28 13:46:26,670 - PROGRESS: pass 4, dispatched chunk #1 = documents up to #200/18846, outstanding queue size 2\n",
      "2022-07-28 13:46:26,670 - PROGRESS: pass 4, dispatched chunk #2 = documents up to #300/18846, outstanding queue size 3\n",
      "2022-07-28 13:46:26,671 - PROGRESS: pass 4, dispatched chunk #3 = documents up to #400/18846, outstanding queue size 4\n",
      "2022-07-28 13:46:26,671 - PROGRESS: pass 4, dispatched chunk #4 = documents up to #500/18846, outstanding queue size 5\n",
      "2022-07-28 13:46:26,672 - PROGRESS: pass 4, dispatched chunk #5 = documents up to #600/18846, outstanding queue size 6\n",
      "2022-07-28 13:46:26,672 - PROGRESS: pass 4, dispatched chunk #6 = documents up to #700/18846, outstanding queue size 7\n",
      "2022-07-28 13:46:26,674 - PROGRESS: pass 4, dispatched chunk #7 = documents up to #800/18846, outstanding queue size 8\n",
      "2022-07-28 13:46:26,675 - PROGRESS: pass 4, dispatched chunk #8 = documents up to #900/18846, outstanding queue size 9\n",
      "2022-07-28 13:46:26,675 - PROGRESS: pass 4, dispatched chunk #9 = documents up to #1000/18846, outstanding queue size 10\n",
      "2022-07-28 13:46:26,675 - PROGRESS: pass 4, dispatched chunk #10 = documents up to #1100/18846, outstanding queue size 11\n",
      "2022-07-28 13:46:26,676 - PROGRESS: pass 4, dispatched chunk #11 = documents up to #1200/18846, outstanding queue size 12\n",
      "2022-07-28 13:46:26,676 - PROGRESS: pass 4, dispatched chunk #12 = documents up to #1300/18846, outstanding queue size 13\n",
      "2022-07-28 13:46:26,679 - PROGRESS: pass 4, dispatched chunk #13 = documents up to #1400/18846, outstanding queue size 14\n",
      "2022-07-28 13:46:26,679 - PROGRESS: pass 4, dispatched chunk #14 = documents up to #1500/18846, outstanding queue size 15\n",
      "2022-07-28 13:46:26,679 - PROGRESS: pass 4, dispatched chunk #15 = documents up to #1600/18846, outstanding queue size 16\n",
      "2022-07-28 13:46:26,680 - PROGRESS: pass 4, dispatched chunk #16 = documents up to #1700/18846, outstanding queue size 17\n",
      "2022-07-28 13:46:26,680 - PROGRESS: pass 4, dispatched chunk #17 = documents up to #1800/18846, outstanding queue size 18\n",
      "2022-07-28 13:46:26,681 - PROGRESS: pass 4, dispatched chunk #18 = documents up to #1900/18846, outstanding queue size 19\n",
      "2022-07-28 13:46:26,683 - PROGRESS: pass 4, dispatched chunk #19 = documents up to #2000/18846, outstanding queue size 20\n",
      "2022-07-28 13:46:26,683 - PROGRESS: pass 4, dispatched chunk #20 = documents up to #2100/18846, outstanding queue size 21\n",
      "2022-07-28 13:46:26,684 - PROGRESS: pass 4, dispatched chunk #21 = documents up to #2200/18846, outstanding queue size 22\n",
      "2022-07-28 13:46:26,684 - PROGRESS: pass 4, dispatched chunk #22 = documents up to #2300/18846, outstanding queue size 23\n",
      "2022-07-28 13:46:26,684 - PROGRESS: pass 4, dispatched chunk #23 = documents up to #2400/18846, outstanding queue size 24\n",
      "2022-07-28 13:46:26,685 - PROGRESS: pass 4, dispatched chunk #24 = documents up to #2500/18846, outstanding queue size 25\n",
      "2022-07-28 13:46:26,687 - PROGRESS: pass 4, dispatched chunk #25 = documents up to #2600/18846, outstanding queue size 26\n",
      "2022-07-28 13:46:26,688 - PROGRESS: pass 4, dispatched chunk #26 = documents up to #2700/18846, outstanding queue size 27\n",
      "2022-07-28 13:46:26,688 - PROGRESS: pass 4, dispatched chunk #27 = documents up to #2800/18846, outstanding queue size 28\n",
      "2022-07-28 13:46:26,689 - PROGRESS: pass 4, dispatched chunk #28 = documents up to #2900/18846, outstanding queue size 29\n",
      "2022-07-28 13:46:26,689 - PROGRESS: pass 4, dispatched chunk #29 = documents up to #3000/18846, outstanding queue size 30\n",
      "2022-07-28 13:46:26,691 - PROGRESS: pass 4, dispatched chunk #30 = documents up to #3100/18846, outstanding queue size 31\n",
      "2022-07-28 13:46:26,692 - PROGRESS: pass 4, dispatched chunk #31 = documents up to #3200/18846, outstanding queue size 32\n",
      "2022-07-28 13:46:26,692 - PROGRESS: pass 4, dispatched chunk #32 = documents up to #3300/18846, outstanding queue size 33\n",
      "2022-07-28 13:46:26,692 - PROGRESS: pass 4, dispatched chunk #33 = documents up to #3400/18846, outstanding queue size 34\n",
      "2022-07-28 13:46:26,693 - PROGRESS: pass 4, dispatched chunk #34 = documents up to #3500/18846, outstanding queue size 35\n",
      "2022-07-28 13:46:26,697 - PROGRESS: pass 4, dispatched chunk #35 = documents up to #3600/18846, outstanding queue size 36\n",
      "2022-07-28 13:46:26,699 - PROGRESS: pass 4, dispatched chunk #36 = documents up to #3700/18846, outstanding queue size 37\n",
      "2022-07-28 13:46:26,706 - PROGRESS: pass 4, dispatched chunk #37 = documents up to #3800/18846, outstanding queue size 38\n",
      "2022-07-28 13:46:26,711 - PROGRESS: pass 4, dispatched chunk #38 = documents up to #3900/18846, outstanding queue size 39\n",
      "2022-07-28 13:46:26,716 - PROGRESS: pass 4, dispatched chunk #39 = documents up to #4000/18846, outstanding queue size 40\n",
      "2022-07-28 13:46:26,727 - PROGRESS: pass 4, dispatched chunk #40 = documents up to #4100/18846, outstanding queue size 41\n",
      "2022-07-28 13:46:26,747 - PROGRESS: pass 4, dispatched chunk #41 = documents up to #4200/18846, outstanding queue size 40\n",
      "2022-07-28 13:46:26,787 - PROGRESS: pass 4, dispatched chunk #42 = documents up to #4300/18846, outstanding queue size 37\n",
      "2022-07-28 13:46:26,788 - PROGRESS: pass 4, dispatched chunk #43 = documents up to #4400/18846, outstanding queue size 38\n",
      "2022-07-28 13:46:26,789 - PROGRESS: pass 4, dispatched chunk #44 = documents up to #4500/18846, outstanding queue size 39\n",
      "2022-07-28 13:46:26,790 - PROGRESS: pass 4, dispatched chunk #45 = documents up to #4600/18846, outstanding queue size 40\n",
      "2022-07-28 13:46:26,797 - PROGRESS: pass 4, dispatched chunk #46 = documents up to #4700/18846, outstanding queue size 41\n",
      "2022-07-28 13:46:26,821 - PROGRESS: pass 4, dispatched chunk #47 = documents up to #4800/18846, outstanding queue size 40\n",
      "2022-07-28 13:46:26,822 - PROGRESS: pass 4, dispatched chunk #48 = documents up to #4900/18846, outstanding queue size 41\n",
      "2022-07-28 13:46:26,856 - PROGRESS: pass 4, dispatched chunk #49 = documents up to #5000/18846, outstanding queue size 40\n",
      "2022-07-28 13:46:26,857 - PROGRESS: pass 4, dispatched chunk #50 = documents up to #5100/18846, outstanding queue size 41\n",
      "2022-07-28 13:46:26,893 - PROGRESS: pass 4, dispatched chunk #51 = documents up to #5200/18846, outstanding queue size 41\n",
      "2022-07-28 13:46:26,894 - PROGRESS: pass 4, dispatched chunk #52 = documents up to #5300/18846, outstanding queue size 42\n",
      "2022-07-28 13:46:26,933 - PROGRESS: pass 4, dispatched chunk #53 = documents up to #5400/18846, outstanding queue size 41\n",
      "2022-07-28 13:46:26,937 - PROGRESS: pass 4, dispatched chunk #54 = documents up to #5500/18846, outstanding queue size 42\n",
      "2022-07-28 13:46:26,954 - PROGRESS: pass 4, dispatched chunk #55 = documents up to #5600/18846, outstanding queue size 42\n",
      "2022-07-28 13:46:26,978 - PROGRESS: pass 4, dispatched chunk #56 = documents up to #5700/18846, outstanding queue size 43\n",
      "2022-07-28 13:46:26,980 - PROGRESS: pass 4, dispatched chunk #57 = documents up to #5800/18846, outstanding queue size 44\n",
      "2022-07-28 13:46:27,124 - merging changes from 1500 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:27,326 - topic #2 (0.100): 0.006*\"space\" + 0.006*\"time\" + 0.005*\"people\" + 0.004*\"government\" + 0.003*\"power\" + 0.003*\"key\" + 0.003*\"car\" + 0.002*\"encryption\" + 0.002*\"public\" + 0.002*\"data\"\n",
      "2022-07-28 13:46:27,349 - topic #7 (0.100): 0.028*\"ax\" + 0.012*\"jpeg\" + 0.008*\"car\" + 0.006*\"gif\" + 0.005*\"image\" + 0.004*\"file\" + 0.003*\"format\" + 0.003*\"images\" + 0.003*\"color\" + 0.003*\"files\"\n",
      "2022-07-28 13:46:27,361 - topic #4 (0.100): 0.011*\"god\" + 0.009*\"people\" + 0.005*\"jesus\" + 0.004*\"time\" + 0.004*\"db\" + 0.004*\"gun\" + 0.003*\"law\" + 0.003*\"christ\" + 0.003*\"key\" + 0.003*\"life\"\n",
      "2022-07-28 13:46:27,363 - topic #8 (0.100): 0.561*\"ax\" + 0.045*\"max\" + 0.004*\"di\" + 0.003*\"ei\" + 0.002*\"tm\" + 0.002*\"giz\" + 0.002*\"armenian\" + 0.002*\"bhj\" + 0.002*\"university\" + 0.002*\"turkish\"\n",
      "2022-07-28 13:46:27,364 - topic #1 (0.100): 0.007*\"file\" + 0.007*\"windows\" + 0.005*\"software\" + 0.005*\"mail\" + 0.005*\"program\" + 0.004*\"dos\" + 0.004*\"ftp\" + 0.004*\"list\" + 0.004*\"graphics\" + 0.004*\"image\"\n",
      "2022-07-28 13:46:27,366 - topic diff=0.051721, rho=0.071896\n",
      "2022-07-28 13:46:27,381 - PROGRESS: pass 4, dispatched chunk #58 = documents up to #5900/18846, outstanding queue size 44\n",
      "2022-07-28 13:46:27,399 - PROGRESS: pass 4, dispatched chunk #59 = documents up to #6000/18846, outstanding queue size 42\n",
      "2022-07-28 13:46:27,401 - PROGRESS: pass 4, dispatched chunk #60 = documents up to #6100/18846, outstanding queue size 43\n",
      "2022-07-28 13:46:27,403 - PROGRESS: pass 4, dispatched chunk #61 = documents up to #6200/18846, outstanding queue size 44\n",
      "2022-07-28 13:46:27,405 - PROGRESS: pass 4, dispatched chunk #62 = documents up to #6300/18846, outstanding queue size 45\n",
      "2022-07-28 13:46:27,406 - PROGRESS: pass 4, dispatched chunk #63 = documents up to #6400/18846, outstanding queue size 46\n",
      "2022-07-28 13:46:27,413 - PROGRESS: pass 4, dispatched chunk #64 = documents up to #6500/18846, outstanding queue size 46\n",
      "2022-07-28 13:46:27,415 - PROGRESS: pass 4, dispatched chunk #65 = documents up to #6600/18846, outstanding queue size 47\n",
      "2022-07-28 13:46:27,417 - PROGRESS: pass 4, dispatched chunk #66 = documents up to #6700/18846, outstanding queue size 48\n",
      "2022-07-28 13:46:27,420 - PROGRESS: pass 4, dispatched chunk #67 = documents up to #6800/18846, outstanding queue size 49\n",
      "2022-07-28 13:46:27,422 - PROGRESS: pass 4, dispatched chunk #68 = documents up to #6900/18846, outstanding queue size 50\n",
      "2022-07-28 13:46:27,431 - PROGRESS: pass 4, dispatched chunk #69 = documents up to #7000/18846, outstanding queue size 51\n",
      "2022-07-28 13:46:27,433 - PROGRESS: pass 4, dispatched chunk #70 = documents up to #7100/18846, outstanding queue size 52\n",
      "2022-07-28 13:46:27,440 - PROGRESS: pass 4, dispatched chunk #71 = documents up to #7200/18846, outstanding queue size 53\n",
      "2022-07-28 13:46:27,472 - PROGRESS: pass 4, dispatched chunk #72 = documents up to #7300/18846, outstanding queue size 54\n",
      "2022-07-28 13:46:27,521 - PROGRESS: pass 4, dispatched chunk #73 = documents up to #7400/18846, outstanding queue size 51\n",
      "2022-07-28 13:46:27,524 - PROGRESS: pass 4, dispatched chunk #74 = documents up to #7500/18846, outstanding queue size 52\n",
      "2022-07-28 13:46:27,572 - PROGRESS: pass 4, dispatched chunk #75 = documents up to #7600/18846, outstanding queue size 52\n",
      "2022-07-28 13:46:27,586 - PROGRESS: pass 4, dispatched chunk #76 = documents up to #7700/18846, outstanding queue size 53\n",
      "2022-07-28 13:46:27,679 - PROGRESS: pass 4, dispatched chunk #77 = documents up to #7800/18846, outstanding queue size 50\n",
      "2022-07-28 13:46:27,688 - PROGRESS: pass 4, dispatched chunk #78 = documents up to #7900/18846, outstanding queue size 50\n",
      "2022-07-28 13:46:27,693 - PROGRESS: pass 4, dispatched chunk #79 = documents up to #8000/18846, outstanding queue size 51\n",
      "2022-07-28 13:46:27,695 - PROGRESS: pass 4, dispatched chunk #80 = documents up to #8100/18846, outstanding queue size 52\n",
      "2022-07-28 13:46:27,696 - PROGRESS: pass 4, dispatched chunk #81 = documents up to #8200/18846, outstanding queue size 53\n",
      "2022-07-28 13:46:27,698 - PROGRESS: pass 4, dispatched chunk #82 = documents up to #8300/18846, outstanding queue size 54\n",
      "2022-07-28 13:46:27,702 - PROGRESS: pass 4, dispatched chunk #83 = documents up to #8400/18846, outstanding queue size 55\n",
      "2022-07-28 13:46:27,919 - merging changes from 1500 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:28,188 - topic #8 (0.100): 0.552*\"ax\" + 0.044*\"max\" + 0.004*\"di\" + 0.003*\"ei\" + 0.002*\"tm\" + 0.002*\"giz\" + 0.002*\"armenian\" + 0.002*\"bhj\" + 0.002*\"turkish\" + 0.002*\"university\"\n",
      "2022-07-28 13:46:28,204 - topic #0 (0.100): 0.010*\"drive\" + 0.006*\"scsi\" + 0.006*\"people\" + 0.005*\"card\" + 0.005*\"mb\" + 0.005*\"disk\" + 0.004*\"god\" + 0.004*\"hard\" + 0.004*\"bus\" + 0.004*\"mhz\"\n",
      "2022-07-28 13:46:28,210 - topic #9 (0.100): 0.011*\"people\" + 0.004*\"israel\" + 0.004*\"president\" + 0.004*\"jews\" + 0.003*\"time\" + 0.003*\"government\" + 0.003*\"war\" + 0.003*\"israeli\" + 0.002*\"question\" + 0.002*\"children\"\n",
      "2022-07-28 13:46:28,222 - topic #2 (0.100): 0.006*\"space\" + 0.006*\"time\" + 0.005*\"people\" + 0.004*\"government\" + 0.003*\"power\" + 0.003*\"key\" + 0.003*\"car\" + 0.002*\"encryption\" + 0.002*\"public\" + 0.002*\"data\"\n",
      "2022-07-28 13:46:28,226 - topic #6 (0.100): 0.012*\"ax\" + 0.006*\"hz\" + 0.005*\"dos\" + 0.005*\"ww\" + 0.004*\"st\" + 0.004*\"uw\" + 0.004*\"appears\" + 0.003*\"art\" + 0.003*\"battery\" + 0.003*\"tl\"\n",
      "2022-07-28 13:46:28,231 - topic diff=0.067480, rho=0.071896\n",
      "2022-07-28 13:46:28,235 - PROGRESS: pass 4, dispatched chunk #84 = documents up to #8500/18846, outstanding queue size 55\n",
      "2022-07-28 13:46:28,265 - PROGRESS: pass 4, dispatched chunk #85 = documents up to #8600/18846, outstanding queue size 51\n",
      "2022-07-28 13:46:28,271 - PROGRESS: pass 4, dispatched chunk #86 = documents up to #8700/18846, outstanding queue size 52\n",
      "2022-07-28 13:46:28,273 - PROGRESS: pass 4, dispatched chunk #87 = documents up to #8800/18846, outstanding queue size 53\n",
      "2022-07-28 13:46:28,274 - PROGRESS: pass 4, dispatched chunk #88 = documents up to #8900/18846, outstanding queue size 54\n",
      "2022-07-28 13:46:28,276 - PROGRESS: pass 4, dispatched chunk #89 = documents up to #9000/18846, outstanding queue size 55\n",
      "2022-07-28 13:46:28,278 - PROGRESS: pass 4, dispatched chunk #90 = documents up to #9100/18846, outstanding queue size 56\n",
      "2022-07-28 13:46:28,279 - PROGRESS: pass 4, dispatched chunk #91 = documents up to #9200/18846, outstanding queue size 57\n",
      "2022-07-28 13:46:28,281 - PROGRESS: pass 4, dispatched chunk #92 = documents up to #9300/18846, outstanding queue size 58\n",
      "2022-07-28 13:46:28,283 - PROGRESS: pass 4, dispatched chunk #93 = documents up to #9400/18846, outstanding queue size 59\n",
      "2022-07-28 13:46:28,284 - PROGRESS: pass 4, dispatched chunk #94 = documents up to #9500/18846, outstanding queue size 60\n",
      "2022-07-28 13:46:28,286 - PROGRESS: pass 4, dispatched chunk #95 = documents up to #9600/18846, outstanding queue size 61\n",
      "2022-07-28 13:46:28,326 - PROGRESS: pass 4, dispatched chunk #96 = documents up to #9700/18846, outstanding queue size 62\n",
      "2022-07-28 13:46:28,348 - PROGRESS: pass 4, dispatched chunk #97 = documents up to #9800/18846, outstanding queue size 63\n",
      "2022-07-28 13:46:28,416 - PROGRESS: pass 4, dispatched chunk #98 = documents up to #9900/18846, outstanding queue size 63\n",
      "2022-07-28 13:46:28,433 - PROGRESS: pass 4, dispatched chunk #99 = documents up to #10000/18846, outstanding queue size 63\n",
      "2022-07-28 13:46:28,437 - PROGRESS: pass 4, dispatched chunk #100 = documents up to #10100/18846, outstanding queue size 64\n",
      "2022-07-28 13:46:28,459 - PROGRESS: pass 4, dispatched chunk #101 = documents up to #10200/18846, outstanding queue size 65\n",
      "2022-07-28 13:46:28,470 - PROGRESS: pass 4, dispatched chunk #102 = documents up to #10300/18846, outstanding queue size 64\n",
      "2022-07-28 13:46:28,485 - PROGRESS: pass 4, dispatched chunk #103 = documents up to #10400/18846, outstanding queue size 65\n",
      "2022-07-28 13:46:28,529 - PROGRESS: pass 4, dispatched chunk #104 = documents up to #10500/18846, outstanding queue size 66\n",
      "2022-07-28 13:46:28,546 - PROGRESS: pass 4, dispatched chunk #105 = documents up to #10600/18846, outstanding queue size 66\n",
      "2022-07-28 13:46:28,546 - PROGRESS: pass 4, dispatched chunk #106 = documents up to #10700/18846, outstanding queue size 67\n",
      "2022-07-28 13:46:28,572 - PROGRESS: pass 4, dispatched chunk #107 = documents up to #10800/18846, outstanding queue size 66\n",
      "2022-07-28 13:46:28,590 - PROGRESS: pass 4, dispatched chunk #108 = documents up to #10900/18846, outstanding queue size 67\n",
      "2022-07-28 13:46:28,634 - PROGRESS: pass 4, dispatched chunk #109 = documents up to #11000/18846, outstanding queue size 66\n",
      "2022-07-28 13:46:28,639 - PROGRESS: pass 4, dispatched chunk #110 = documents up to #11100/18846, outstanding queue size 67\n",
      "2022-07-28 13:46:28,672 - PROGRESS: pass 4, dispatched chunk #111 = documents up to #11200/18846, outstanding queue size 68\n",
      "2022-07-28 13:46:28,673 - PROGRESS: pass 4, dispatched chunk #112 = documents up to #11300/18846, outstanding queue size 69\n",
      "2022-07-28 13:46:28,743 - merging changes from 1600 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:28,839 - topic #3 (0.100): 0.005*\"team\" + 0.004*\"play\" + 0.004*\"game\" + 0.004*\"time\" + 0.004*\"period\" + 0.003*\"hockey\" + 0.003*\"season\" + 0.003*\"goal\" + 0.002*\"win\" + 0.002*\"pit\"\n",
      "2022-07-28 13:46:28,846 - topic #0 (0.100): 0.010*\"drive\" + 0.007*\"scsi\" + 0.006*\"people\" + 0.006*\"mb\" + 0.006*\"card\" + 0.005*\"disk\" + 0.004*\"god\" + 0.004*\"hard\" + 0.004*\"bus\" + 0.004*\"mhz\"\n",
      "2022-07-28 13:46:28,848 - topic #9 (0.100): 0.011*\"people\" + 0.005*\"israel\" + 0.004*\"president\" + 0.004*\"jews\" + 0.003*\"time\" + 0.003*\"government\" + 0.003*\"war\" + 0.003*\"israeli\" + 0.003*\"children\" + 0.003*\"question\"\n",
      "2022-07-28 13:46:28,852 - topic #8 (0.100): 0.556*\"ax\" + 0.044*\"max\" + 0.004*\"di\" + 0.003*\"ei\" + 0.003*\"tm\" + 0.002*\"giz\" + 0.002*\"bhj\" + 0.002*\"armenian\" + 0.002*\"turkish\" + 0.002*\"university\"\n",
      "2022-07-28 13:46:28,854 - topic #4 (0.100): 0.012*\"god\" + 0.009*\"people\" + 0.006*\"jesus\" + 0.004*\"time\" + 0.003*\"gun\" + 0.003*\"db\" + 0.003*\"law\" + 0.003*\"christ\" + 0.003*\"key\" + 0.003*\"life\"\n",
      "2022-07-28 13:46:28,856 - topic diff=0.052903, rho=0.071896\n",
      "2022-07-28 13:46:28,868 - PROGRESS: pass 4, dispatched chunk #113 = documents up to #11400/18846, outstanding queue size 68\n",
      "2022-07-28 13:46:28,911 - PROGRESS: pass 4, dispatched chunk #114 = documents up to #11500/18846, outstanding queue size 68\n",
      "2022-07-28 13:46:28,914 - PROGRESS: pass 4, dispatched chunk #115 = documents up to #11600/18846, outstanding queue size 69\n",
      "2022-07-28 13:46:28,914 - PROGRESS: pass 4, dispatched chunk #116 = documents up to #11700/18846, outstanding queue size 70\n",
      "2022-07-28 13:46:28,916 - PROGRESS: pass 4, dispatched chunk #117 = documents up to #11800/18846, outstanding queue size 71\n",
      "2022-07-28 13:46:28,917 - PROGRESS: pass 4, dispatched chunk #118 = documents up to #11900/18846, outstanding queue size 72\n",
      "2022-07-28 13:46:28,918 - PROGRESS: pass 4, dispatched chunk #119 = documents up to #12000/18846, outstanding queue size 73\n",
      "2022-07-28 13:46:28,950 - PROGRESS: pass 4, dispatched chunk #120 = documents up to #12100/18846, outstanding queue size 72\n",
      "2022-07-28 13:46:29,028 - PROGRESS: pass 4, dispatched chunk #121 = documents up to #12200/18846, outstanding queue size 72\n",
      "2022-07-28 13:46:29,029 - PROGRESS: pass 4, dispatched chunk #122 = documents up to #12300/18846, outstanding queue size 73\n",
      "2022-07-28 13:46:29,030 - PROGRESS: pass 4, dispatched chunk #123 = documents up to #12400/18846, outstanding queue size 74\n",
      "2022-07-28 13:46:29,030 - PROGRESS: pass 4, dispatched chunk #124 = documents up to #12500/18846, outstanding queue size 75\n",
      "2022-07-28 13:46:29,031 - PROGRESS: pass 4, dispatched chunk #125 = documents up to #12600/18846, outstanding queue size 76\n",
      "2022-07-28 13:46:29,031 - PROGRESS: pass 4, dispatched chunk #126 = documents up to #12700/18846, outstanding queue size 77\n",
      "2022-07-28 13:46:29,032 - PROGRESS: pass 4, dispatched chunk #127 = documents up to #12800/18846, outstanding queue size 78\n",
      "2022-07-28 13:46:29,076 - PROGRESS: pass 4, dispatched chunk #128 = documents up to #12900/18846, outstanding queue size 77\n",
      "2022-07-28 13:46:29,086 - PROGRESS: pass 4, dispatched chunk #129 = documents up to #13000/18846, outstanding queue size 75\n",
      "2022-07-28 13:46:29,182 - merging changes from 1700 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:29,246 - topic #7 (0.100): 0.022*\"ax\" + 0.016*\"jpeg\" + 0.008*\"car\" + 0.008*\"gif\" + 0.007*\"image\" + 0.005*\"file\" + 0.004*\"color\" + 0.004*\"format\" + 0.004*\"images\" + 0.003*\"quality\"\n",
      "2022-07-28 13:46:29,263 - topic #6 (0.100): 0.010*\"ax\" + 0.007*\"hz\" + 0.005*\"ww\" + 0.005*\"scx\" + 0.004*\"dos\" + 0.004*\"st\" + 0.004*\"uw\" + 0.003*\"appears\" + 0.003*\"zd\" + 0.003*\"tl\"\n",
      "2022-07-28 13:46:29,272 - topic #1 (0.100): 0.008*\"file\" + 0.006*\"windows\" + 0.005*\"program\" + 0.005*\"software\" + 0.005*\"mail\" + 0.004*\"graphics\" + 0.004*\"ftp\" + 0.004*\"dos\" + 0.004*\"list\" + 0.004*\"data\"\n",
      "2022-07-28 13:46:29,274 - topic #2 (0.100): 0.006*\"space\" + 0.006*\"time\" + 0.005*\"people\" + 0.004*\"government\" + 0.003*\"car\" + 0.003*\"power\" + 0.003*\"key\" + 0.002*\"public\" + 0.002*\"encryption\" + 0.002*\"data\"\n",
      "2022-07-28 13:46:29,276 - topic #9 (0.100): 0.011*\"people\" + 0.004*\"israel\" + 0.004*\"president\" + 0.004*\"jews\" + 0.003*\"time\" + 0.003*\"government\" + 0.003*\"war\" + 0.003*\"children\" + 0.003*\"israeli\" + 0.003*\"question\"\n",
      "2022-07-28 13:46:29,277 - topic diff=0.055011, rho=0.071896\n",
      "2022-07-28 13:46:29,283 - PROGRESS: pass 4, dispatched chunk #130 = documents up to #13100/18846, outstanding queue size 68\n",
      "2022-07-28 13:46:29,319 - PROGRESS: pass 4, dispatched chunk #131 = documents up to #13200/18846, outstanding queue size 58\n",
      "2022-07-28 13:46:29,320 - PROGRESS: pass 4, dispatched chunk #132 = documents up to #13300/18846, outstanding queue size 59\n",
      "2022-07-28 13:46:29,320 - PROGRESS: pass 4, dispatched chunk #133 = documents up to #13400/18846, outstanding queue size 60\n",
      "2022-07-28 13:46:29,321 - PROGRESS: pass 4, dispatched chunk #134 = documents up to #13500/18846, outstanding queue size 61\n",
      "2022-07-28 13:46:29,321 - PROGRESS: pass 4, dispatched chunk #135 = documents up to #13600/18846, outstanding queue size 62\n",
      "2022-07-28 13:46:29,322 - PROGRESS: pass 4, dispatched chunk #136 = documents up to #13700/18846, outstanding queue size 63\n",
      "2022-07-28 13:46:29,322 - PROGRESS: pass 4, dispatched chunk #137 = documents up to #13800/18846, outstanding queue size 64\n",
      "2022-07-28 13:46:29,394 - PROGRESS: pass 4, dispatched chunk #138 = documents up to #13900/18846, outstanding queue size 64\n",
      "2022-07-28 13:46:29,396 - PROGRESS: pass 4, dispatched chunk #139 = documents up to #14000/18846, outstanding queue size 65\n",
      "2022-07-28 13:46:29,419 - PROGRESS: pass 4, dispatched chunk #140 = documents up to #14100/18846, outstanding queue size 66\n",
      "2022-07-28 13:46:29,552 - merging changes from 1600 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:29,615 - topic #7 (0.100): 0.021*\"ax\" + 0.016*\"jpeg\" + 0.008*\"car\" + 0.008*\"gif\" + 0.006*\"image\" + 0.005*\"file\" + 0.004*\"color\" + 0.004*\"format\" + 0.004*\"images\" + 0.003*\"files\"\n",
      "2022-07-28 13:46:29,616 - topic #4 (0.100): 0.012*\"god\" + 0.009*\"people\" + 0.005*\"jesus\" + 0.004*\"time\" + 0.003*\"gun\" + 0.003*\"christ\" + 0.003*\"law\" + 0.003*\"db\" + 0.003*\"life\" + 0.003*\"key\"\n",
      "2022-07-28 13:46:29,618 - topic #2 (0.100): 0.007*\"space\" + 0.006*\"time\" + 0.005*\"people\" + 0.004*\"government\" + 0.003*\"key\" + 0.003*\"power\" + 0.003*\"car\" + 0.002*\"public\" + 0.002*\"encryption\" + 0.002*\"data\"\n",
      "2022-07-28 13:46:29,620 - topic #6 (0.100): 0.010*\"ax\" + 0.007*\"hz\" + 0.004*\"st\" + 0.004*\"ww\" + 0.004*\"scx\" + 0.004*\"dos\" + 0.004*\"appears\" + 0.004*\"uw\" + 0.003*\"art\" + 0.003*\"zd\"\n",
      "2022-07-28 13:46:29,621 - topic #1 (0.100): 0.008*\"file\" + 0.007*\"windows\" + 0.005*\"program\" + 0.005*\"software\" + 0.005*\"mail\" + 0.004*\"ftp\" + 0.004*\"graphics\" + 0.004*\"dos\" + 0.004*\"list\" + 0.004*\"data\"\n",
      "2022-07-28 13:46:29,634 - topic diff=0.054147, rho=0.071896\n",
      "2022-07-28 13:46:29,635 - PROGRESS: pass 4, dispatched chunk #141 = documents up to #14200/18846, outstanding queue size 63\n",
      "2022-07-28 13:46:29,660 - PROGRESS: pass 4, dispatched chunk #142 = documents up to #14300/18846, outstanding queue size 57\n",
      "2022-07-28 13:46:29,662 - PROGRESS: pass 4, dispatched chunk #143 = documents up to #14400/18846, outstanding queue size 58\n",
      "2022-07-28 13:46:29,662 - PROGRESS: pass 4, dispatched chunk #144 = documents up to #14500/18846, outstanding queue size 59\n",
      "2022-07-28 13:46:29,663 - PROGRESS: pass 4, dispatched chunk #145 = documents up to #14600/18846, outstanding queue size 60\n",
      "2022-07-28 13:46:29,663 - PROGRESS: pass 4, dispatched chunk #146 = documents up to #14700/18846, outstanding queue size 61\n",
      "2022-07-28 13:46:29,664 - PROGRESS: pass 4, dispatched chunk #147 = documents up to #14800/18846, outstanding queue size 62\n",
      "2022-07-28 13:46:29,666 - PROGRESS: pass 4, dispatched chunk #148 = documents up to #14900/18846, outstanding queue size 63\n",
      "2022-07-28 13:46:29,666 - PROGRESS: pass 4, dispatched chunk #149 = documents up to #15000/18846, outstanding queue size 64\n",
      "2022-07-28 13:46:29,668 - PROGRESS: pass 4, dispatched chunk #150 = documents up to #15100/18846, outstanding queue size 65\n",
      "2022-07-28 13:46:29,673 - PROGRESS: pass 4, dispatched chunk #151 = documents up to #15200/18846, outstanding queue size 66\n",
      "2022-07-28 13:46:29,678 - PROGRESS: pass 4, dispatched chunk #152 = documents up to #15300/18846, outstanding queue size 67\n",
      "2022-07-28 13:46:29,692 - PROGRESS: pass 4, dispatched chunk #153 = documents up to #15400/18846, outstanding queue size 66\n",
      "2022-07-28 13:46:29,693 - PROGRESS: pass 4, dispatched chunk #154 = documents up to #15500/18846, outstanding queue size 67\n",
      "2022-07-28 13:46:29,695 - PROGRESS: pass 4, dispatched chunk #155 = documents up to #15600/18846, outstanding queue size 68\n",
      "2022-07-28 13:46:29,700 - PROGRESS: pass 4, dispatched chunk #156 = documents up to #15700/18846, outstanding queue size 69\n",
      "2022-07-28 13:46:29,712 - PROGRESS: pass 4, dispatched chunk #157 = documents up to #15800/18846, outstanding queue size 70\n",
      "2022-07-28 13:46:29,730 - PROGRESS: pass 4, dispatched chunk #158 = documents up to #15900/18846, outstanding queue size 70\n",
      "2022-07-28 13:46:29,742 - PROGRESS: pass 4, dispatched chunk #159 = documents up to #16000/18846, outstanding queue size 69\n",
      "2022-07-28 13:46:29,742 - PROGRESS: pass 4, dispatched chunk #160 = documents up to #16100/18846, outstanding queue size 70\n",
      "2022-07-28 13:46:29,751 - PROGRESS: pass 4, dispatched chunk #161 = documents up to #16200/18846, outstanding queue size 70\n",
      "2022-07-28 13:46:29,760 - PROGRESS: pass 4, dispatched chunk #162 = documents up to #16300/18846, outstanding queue size 71\n",
      "2022-07-28 13:46:29,861 - merging changes from 1700 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:29,935 - topic #8 (0.100): 0.603*\"ax\" + 0.048*\"max\" + 0.004*\"di\" + 0.003*\"ei\" + 0.003*\"tm\" + 0.002*\"giz\" + 0.002*\"bhj\" + 0.002*\"armenian\" + 0.002*\"wm\" + 0.002*\"ey\"\n",
      "2022-07-28 13:46:29,937 - topic #9 (0.100): 0.012*\"people\" + 0.004*\"israel\" + 0.004*\"president\" + 0.004*\"jews\" + 0.003*\"time\" + 0.003*\"government\" + 0.003*\"war\" + 0.003*\"children\" + 0.003*\"israeli\" + 0.003*\"question\"\n",
      "2022-07-28 13:46:29,939 - topic #6 (0.100): 0.009*\"ax\" + 0.007*\"hz\" + 0.006*\"ww\" + 0.005*\"uw\" + 0.004*\"scx\" + 0.004*\"st\" + 0.004*\"appears\" + 0.004*\"dos\" + 0.003*\"zd\" + 0.003*\"cj\"\n",
      "2022-07-28 13:46:29,940 - topic #3 (0.100): 0.006*\"team\" + 0.005*\"game\" + 0.005*\"play\" + 0.004*\"period\" + 0.004*\"time\" + 0.003*\"hockey\" + 0.003*\"win\" + 0.003*\"season\" + 0.003*\"pit\" + 0.003*\"goal\"\n",
      "2022-07-28 13:46:29,942 - topic #4 (0.100): 0.012*\"god\" + 0.009*\"people\" + 0.005*\"jesus\" + 0.004*\"time\" + 0.004*\"gun\" + 0.003*\"law\" + 0.003*\"christ\" + 0.003*\"life\" + 0.003*\"db\" + 0.002*\"key\"\n",
      "2022-07-28 13:46:29,944 - topic diff=0.046522, rho=0.071896\n",
      "2022-07-28 13:46:29,944 - PROGRESS: pass 4, dispatched chunk #163 = documents up to #16400/18846, outstanding queue size 68\n",
      "2022-07-28 13:46:29,957 - PROGRESS: pass 4, dispatched chunk #164 = documents up to #16500/18846, outstanding queue size 67\n",
      "2022-07-28 13:46:29,963 - PROGRESS: pass 4, dispatched chunk #165 = documents up to #16600/18846, outstanding queue size 68\n",
      "2022-07-28 13:46:29,964 - PROGRESS: pass 4, dispatched chunk #166 = documents up to #16700/18846, outstanding queue size 69\n",
      "2022-07-28 13:46:29,964 - PROGRESS: pass 4, dispatched chunk #167 = documents up to #16800/18846, outstanding queue size 70\n",
      "2022-07-28 13:46:29,965 - PROGRESS: pass 4, dispatched chunk #168 = documents up to #16900/18846, outstanding queue size 71\n",
      "2022-07-28 13:46:29,965 - PROGRESS: pass 4, dispatched chunk #169 = documents up to #17000/18846, outstanding queue size 72\n",
      "2022-07-28 13:46:30,041 - PROGRESS: pass 4, dispatched chunk #170 = documents up to #17100/18846, outstanding queue size 73\n",
      "2022-07-28 13:46:30,045 - PROGRESS: pass 4, dispatched chunk #171 = documents up to #17200/18846, outstanding queue size 74\n",
      "2022-07-28 13:46:30,062 - PROGRESS: pass 4, dispatched chunk #172 = documents up to #17300/18846, outstanding queue size 72\n",
      "2022-07-28 13:46:30,092 - PROGRESS: pass 4, dispatched chunk #173 = documents up to #17400/18846, outstanding queue size 73\n",
      "2022-07-28 13:46:30,133 - PROGRESS: pass 4, dispatched chunk #174 = documents up to #17500/18846, outstanding queue size 74\n",
      "2022-07-28 13:46:30,157 - PROGRESS: pass 4, dispatched chunk #175 = documents up to #17600/18846, outstanding queue size 74\n",
      "2022-07-28 13:46:30,243 - PROGRESS: pass 4, dispatched chunk #176 = documents up to #17700/18846, outstanding queue size 70\n",
      "2022-07-28 13:46:30,243 - PROGRESS: pass 4, dispatched chunk #177 = documents up to #17800/18846, outstanding queue size 71\n",
      "2022-07-28 13:46:30,244 - PROGRESS: pass 4, dispatched chunk #178 = documents up to #17900/18846, outstanding queue size 72\n",
      "2022-07-28 13:46:30,244 - PROGRESS: pass 4, dispatched chunk #179 = documents up to #18000/18846, outstanding queue size 73\n",
      "2022-07-28 13:46:30,247 - PROGRESS: pass 4, dispatched chunk #180 = documents up to #18100/18846, outstanding queue size 74\n",
      "2022-07-28 13:46:30,248 - PROGRESS: pass 4, dispatched chunk #181 = documents up to #18200/18846, outstanding queue size 75\n",
      "2022-07-28 13:46:30,250 - PROGRESS: pass 4, dispatched chunk #182 = documents up to #18300/18846, outstanding queue size 76\n",
      "2022-07-28 13:46:30,254 - PROGRESS: pass 4, dispatched chunk #183 = documents up to #18400/18846, outstanding queue size 77\n",
      "2022-07-28 13:46:30,277 - PROGRESS: pass 4, dispatched chunk #184 = documents up to #18500/18846, outstanding queue size 77\n",
      "2022-07-28 13:46:30,298 - PROGRESS: pass 4, dispatched chunk #185 = documents up to #18600/18846, outstanding queue size 78\n",
      "2022-07-28 13:46:30,519 - merging changes from 1500 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:30,584 - topic #4 (0.100): 0.012*\"god\" + 0.009*\"people\" + 0.005*\"jesus\" + 0.005*\"db\" + 0.004*\"time\" + 0.004*\"gun\" + 0.003*\"law\" + 0.003*\"christ\" + 0.003*\"life\" + 0.003*\"key\"\n",
      "2022-07-28 13:46:30,607 - topic #5 (0.100): 0.005*\"armenian\" + 0.003*\"azerbaijan\" + 0.003*\"time\" + 0.003*\"book\" + 0.003*\"source\" + 0.003*\"people\" + 0.002*\"players\" + 0.002*\"russian\" + 0.002*\"set\" + 0.002*\"sun\"\n",
      "2022-07-28 13:46:30,616 - topic #3 (0.100): 0.006*\"team\" + 0.005*\"game\" + 0.005*\"play\" + 0.005*\"period\" + 0.004*\"time\" + 0.003*\"hockey\" + 0.003*\"season\" + 0.003*\"win\" + 0.003*\"pts\" + 0.003*\"goal\"\n",
      "2022-07-28 13:46:30,617 - topic #7 (0.100): 0.019*\"ax\" + 0.015*\"jpeg\" + 0.009*\"car\" + 0.007*\"gif\" + 0.006*\"image\" + 0.005*\"file\" + 0.004*\"color\" + 0.004*\"images\" + 0.004*\"format\" + 0.003*\"clutch\"\n",
      "2022-07-28 13:46:30,619 - topic #8 (0.100): 0.611*\"ax\" + 0.049*\"max\" + 0.005*\"di\" + 0.004*\"ei\" + 0.003*\"tm\" + 0.003*\"giz\" + 0.003*\"bhj\" + 0.002*\"wm\" + 0.002*\"ey\" + 0.002*\"armenian\"\n",
      "2022-07-28 13:46:30,620 - topic diff=0.052048, rho=0.071896\n",
      "2022-07-28 13:46:30,621 - PROGRESS: pass 4, dispatched chunk #186 = documents up to #18700/18846, outstanding queue size 76\n",
      "2022-07-28 13:46:30,641 - PROGRESS: pass 4, dispatched chunk #187 = documents up to #18800/18846, outstanding queue size 76\n",
      "2022-07-28 13:46:30,642 - PROGRESS: pass 4, dispatched chunk #188 = documents up to #18846/18846, outstanding queue size 77\n",
      "2022-07-28 13:46:31,049 - merging changes from 1600 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:31,123 - topic #0 (0.100): 0.012*\"drive\" + 0.008*\"scsi\" + 0.006*\"mb\" + 0.006*\"card\" + 0.006*\"people\" + 0.005*\"disk\" + 0.005*\"hard\" + 0.004*\"bus\" + 0.004*\"bit\" + 0.004*\"mhz\"\n",
      "2022-07-28 13:46:31,142 - topic #5 (0.100): 0.005*\"armenian\" + 0.003*\"azerbaijan\" + 0.003*\"time\" + 0.003*\"book\" + 0.003*\"source\" + 0.002*\"people\" + 0.002*\"players\" + 0.002*\"russian\" + 0.002*\"set\" + 0.002*\"sun\"\n",
      "2022-07-28 13:46:31,143 - topic #7 (0.100): 0.018*\"ax\" + 0.017*\"jpeg\" + 0.008*\"gif\" + 0.008*\"car\" + 0.007*\"image\" + 0.006*\"file\" + 0.005*\"color\" + 0.004*\"images\" + 0.004*\"format\" + 0.004*\"quality\"\n",
      "2022-07-28 13:46:31,145 - topic #4 (0.100): 0.012*\"god\" + 0.009*\"people\" + 0.005*\"jesus\" + 0.004*\"time\" + 0.004*\"db\" + 0.004*\"gun\" + 0.003*\"law\" + 0.003*\"christ\" + 0.003*\"life\" + 0.002*\"key\"\n",
      "2022-07-28 13:46:31,146 - topic #8 (0.100): 0.628*\"ax\" + 0.050*\"max\" + 0.005*\"di\" + 0.004*\"ei\" + 0.003*\"giz\" + 0.003*\"tm\" + 0.003*\"bhj\" + 0.002*\"wm\" + 0.002*\"ey\" + 0.002*\"university\"\n",
      "2022-07-28 13:46:31,148 - topic diff=0.048857, rho=0.071896\n",
      "2022-07-28 13:46:31,416 - -10.514 per-word bound, 1462.1 perplexity estimate based on a held-out corpus of 46 documents with 2932 words\n",
      "2022-07-28 13:46:31,493 - merging changes from 1600 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:31,524 - topic #6 (0.100): 0.008*\"ax\" + 0.007*\"hz\" + 0.005*\"ww\" + 0.004*\"st\" + 0.004*\"uw\" + 0.004*\"scx\" + 0.003*\"appears\" + 0.003*\"battery\" + 0.003*\"dos\" + 0.003*\"art\"\n",
      "2022-07-28 13:46:31,526 - topic #5 (0.100): 0.005*\"armenian\" + 0.003*\"time\" + 0.003*\"azerbaijan\" + 0.003*\"book\" + 0.003*\"source\" + 0.002*\"people\" + 0.002*\"players\" + 0.002*\"russian\" + 0.002*\"set\" + 0.002*\"sun\"\n",
      "2022-07-28 13:46:31,527 - topic #0 (0.100): 0.012*\"drive\" + 0.008*\"scsi\" + 0.006*\"mb\" + 0.006*\"card\" + 0.006*\"people\" + 0.005*\"disk\" + 0.005*\"hard\" + 0.004*\"bus\" + 0.004*\"bit\" + 0.004*\"mhz\"\n",
      "2022-07-28 13:46:31,528 - topic #3 (0.100): 0.006*\"team\" + 0.006*\"game\" + 0.005*\"play\" + 0.004*\"period\" + 0.004*\"time\" + 0.003*\"hockey\" + 0.003*\"season\" + 0.003*\"pit\" + 0.003*\"games\" + 0.003*\"win\"\n",
      "2022-07-28 13:46:31,530 - topic #7 (0.100): 0.017*\"ax\" + 0.017*\"jpeg\" + 0.008*\"car\" + 0.008*\"gif\" + 0.007*\"image\" + 0.005*\"file\" + 0.004*\"color\" + 0.004*\"format\" + 0.004*\"images\" + 0.004*\"clutch\"\n",
      "2022-07-28 13:46:31,531 - topic diff=0.050766, rho=0.071896\n",
      "2022-07-28 13:46:31,604 - -10.508 per-word bound, 1456.1 perplexity estimate based on a held-out corpus of 46 documents with 2932 words\n",
      "2022-07-28 13:46:31,748 - merging changes from 4546 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:31,778 - topic #6 (0.100): 0.008*\"ax\" + 0.007*\"hz\" + 0.005*\"ww\" + 0.004*\"st\" + 0.004*\"uw\" + 0.004*\"scx\" + 0.003*\"appears\" + 0.003*\"battery\" + 0.003*\"dos\" + 0.003*\"water\"\n",
      "2022-07-28 13:46:31,780 - topic #7 (0.100): 0.016*\"ax\" + 0.016*\"jpeg\" + 0.009*\"car\" + 0.008*\"gif\" + 0.007*\"image\" + 0.005*\"file\" + 0.004*\"color\" + 0.004*\"images\" + 0.004*\"format\" + 0.004*\"clutch\"\n",
      "2022-07-28 13:46:31,781 - topic #5 (0.100): 0.005*\"armenian\" + 0.003*\"time\" + 0.003*\"book\" + 0.003*\"azerbaijan\" + 0.003*\"source\" + 0.002*\"people\" + 0.002*\"players\" + 0.002*\"russian\" + 0.002*\"set\" + 0.002*\"xfree\"\n",
      "2022-07-28 13:46:31,782 - topic #1 (0.100): 0.008*\"file\" + 0.007*\"windows\" + 0.006*\"software\" + 0.005*\"mail\" + 0.005*\"program\" + 0.005*\"dos\" + 0.005*\"ftp\" + 0.004*\"graphics\" + 0.004*\"list\" + 0.004*\"image\"\n",
      "2022-07-28 13:46:31,783 - topic #3 (0.100): 0.007*\"team\" + 0.006*\"game\" + 0.005*\"play\" + 0.004*\"period\" + 0.004*\"time\" + 0.004*\"hockey\" + 0.004*\"season\" + 0.003*\"games\" + 0.003*\"pit\" + 0.003*\"win\"\n",
      "2022-07-28 13:46:31,785 - topic diff=0.042705, rho=0.071896\n",
      "2022-07-28 13:46:31,857 - -10.471 per-word bound, 1419.1 perplexity estimate based on a held-out corpus of 46 documents with 2932 words\n",
      "2022-07-28 13:46:31,858 - PROGRESS: pass 5, dispatched chunk #0 = documents up to #100/18846, outstanding queue size 1\n",
      "2022-07-28 13:46:31,860 - PROGRESS: pass 5, dispatched chunk #1 = documents up to #200/18846, outstanding queue size 2\n",
      "2022-07-28 13:46:31,861 - PROGRESS: pass 5, dispatched chunk #2 = documents up to #300/18846, outstanding queue size 3\n",
      "2022-07-28 13:46:31,861 - PROGRESS: pass 5, dispatched chunk #3 = documents up to #400/18846, outstanding queue size 4\n",
      "2022-07-28 13:46:31,861 - PROGRESS: pass 5, dispatched chunk #4 = documents up to #500/18846, outstanding queue size 5\n",
      "2022-07-28 13:46:31,862 - PROGRESS: pass 5, dispatched chunk #5 = documents up to #600/18846, outstanding queue size 6\n",
      "2022-07-28 13:46:31,862 - PROGRESS: pass 5, dispatched chunk #6 = documents up to #700/18846, outstanding queue size 7\n",
      "2022-07-28 13:46:31,864 - PROGRESS: pass 5, dispatched chunk #7 = documents up to #800/18846, outstanding queue size 8\n",
      "2022-07-28 13:46:31,865 - PROGRESS: pass 5, dispatched chunk #8 = documents up to #900/18846, outstanding queue size 9\n",
      "2022-07-28 13:46:31,865 - PROGRESS: pass 5, dispatched chunk #9 = documents up to #1000/18846, outstanding queue size 10\n",
      "2022-07-28 13:46:31,865 - PROGRESS: pass 5, dispatched chunk #10 = documents up to #1100/18846, outstanding queue size 11\n",
      "2022-07-28 13:46:31,866 - PROGRESS: pass 5, dispatched chunk #11 = documents up to #1200/18846, outstanding queue size 12\n",
      "2022-07-28 13:46:31,868 - PROGRESS: pass 5, dispatched chunk #12 = documents up to #1300/18846, outstanding queue size 13\n",
      "2022-07-28 13:46:31,868 - PROGRESS: pass 5, dispatched chunk #13 = documents up to #1400/18846, outstanding queue size 14\n",
      "2022-07-28 13:46:31,869 - PROGRESS: pass 5, dispatched chunk #14 = documents up to #1500/18846, outstanding queue size 15\n",
      "2022-07-28 13:46:31,869 - PROGRESS: pass 5, dispatched chunk #15 = documents up to #1600/18846, outstanding queue size 16\n",
      "2022-07-28 13:46:31,870 - PROGRESS: pass 5, dispatched chunk #16 = documents up to #1700/18846, outstanding queue size 17\n",
      "2022-07-28 13:46:31,872 - PROGRESS: pass 5, dispatched chunk #17 = documents up to #1800/18846, outstanding queue size 18\n",
      "2022-07-28 13:46:31,872 - PROGRESS: pass 5, dispatched chunk #18 = documents up to #1900/18846, outstanding queue size 19\n",
      "2022-07-28 13:46:31,873 - PROGRESS: pass 5, dispatched chunk #19 = documents up to #2000/18846, outstanding queue size 20\n",
      "2022-07-28 13:46:31,873 - PROGRESS: pass 5, dispatched chunk #20 = documents up to #2100/18846, outstanding queue size 21\n",
      "2022-07-28 13:46:31,874 - PROGRESS: pass 5, dispatched chunk #21 = documents up to #2200/18846, outstanding queue size 22\n",
      "2022-07-28 13:46:31,874 - PROGRESS: pass 5, dispatched chunk #22 = documents up to #2300/18846, outstanding queue size 23\n",
      "2022-07-28 13:46:31,877 - PROGRESS: pass 5, dispatched chunk #23 = documents up to #2400/18846, outstanding queue size 24\n",
      "2022-07-28 13:46:31,877 - PROGRESS: pass 5, dispatched chunk #24 = documents up to #2500/18846, outstanding queue size 25\n",
      "2022-07-28 13:46:31,878 - PROGRESS: pass 5, dispatched chunk #25 = documents up to #2600/18846, outstanding queue size 26\n",
      "2022-07-28 13:46:31,878 - PROGRESS: pass 5, dispatched chunk #26 = documents up to #2700/18846, outstanding queue size 27\n",
      "2022-07-28 13:46:31,878 - PROGRESS: pass 5, dispatched chunk #27 = documents up to #2800/18846, outstanding queue size 28\n",
      "2022-07-28 13:46:31,881 - PROGRESS: pass 5, dispatched chunk #28 = documents up to #2900/18846, outstanding queue size 29\n",
      "2022-07-28 13:46:31,881 - PROGRESS: pass 5, dispatched chunk #29 = documents up to #3000/18846, outstanding queue size 30\n",
      "2022-07-28 13:46:31,881 - PROGRESS: pass 5, dispatched chunk #30 = documents up to #3100/18846, outstanding queue size 31\n",
      "2022-07-28 13:46:31,882 - PROGRESS: pass 5, dispatched chunk #31 = documents up to #3200/18846, outstanding queue size 32\n",
      "2022-07-28 13:46:31,882 - PROGRESS: pass 5, dispatched chunk #32 = documents up to #3300/18846, outstanding queue size 33\n",
      "2022-07-28 13:46:31,882 - PROGRESS: pass 5, dispatched chunk #33 = documents up to #3400/18846, outstanding queue size 34\n",
      "2022-07-28 13:46:31,883 - PROGRESS: pass 5, dispatched chunk #34 = documents up to #3500/18846, outstanding queue size 35\n",
      "2022-07-28 13:46:31,886 - PROGRESS: pass 5, dispatched chunk #35 = documents up to #3600/18846, outstanding queue size 36\n",
      "2022-07-28 13:46:31,888 - PROGRESS: pass 5, dispatched chunk #36 = documents up to #3700/18846, outstanding queue size 37\n",
      "2022-07-28 13:46:31,893 - PROGRESS: pass 5, dispatched chunk #37 = documents up to #3800/18846, outstanding queue size 38\n",
      "2022-07-28 13:46:31,898 - PROGRESS: pass 5, dispatched chunk #38 = documents up to #3900/18846, outstanding queue size 39\n",
      "2022-07-28 13:46:31,903 - PROGRESS: pass 5, dispatched chunk #39 = documents up to #4000/18846, outstanding queue size 40\n",
      "2022-07-28 13:46:31,917 - PROGRESS: pass 5, dispatched chunk #40 = documents up to #4100/18846, outstanding queue size 41\n",
      "2022-07-28 13:46:31,936 - PROGRESS: pass 5, dispatched chunk #41 = documents up to #4200/18846, outstanding queue size 41\n",
      "2022-07-28 13:46:31,938 - PROGRESS: pass 5, dispatched chunk #42 = documents up to #4300/18846, outstanding queue size 42\n",
      "2022-07-28 13:46:31,994 - PROGRESS: pass 5, dispatched chunk #43 = documents up to #4400/18846, outstanding queue size 37\n",
      "2022-07-28 13:46:31,996 - PROGRESS: pass 5, dispatched chunk #44 = documents up to #4500/18846, outstanding queue size 38\n",
      "2022-07-28 13:46:32,000 - PROGRESS: pass 5, dispatched chunk #45 = documents up to #4600/18846, outstanding queue size 39\n",
      "2022-07-28 13:46:32,010 - PROGRESS: pass 5, dispatched chunk #46 = documents up to #4700/18846, outstanding queue size 38\n",
      "2022-07-28 13:46:32,027 - PROGRESS: pass 5, dispatched chunk #47 = documents up to #4800/18846, outstanding queue size 38\n",
      "2022-07-28 13:46:32,031 - PROGRESS: pass 5, dispatched chunk #48 = documents up to #4900/18846, outstanding queue size 39\n",
      "2022-07-28 13:46:32,057 - PROGRESS: pass 5, dispatched chunk #49 = documents up to #5000/18846, outstanding queue size 39\n",
      "2022-07-28 13:46:32,081 - PROGRESS: pass 5, dispatched chunk #50 = documents up to #5100/18846, outstanding queue size 37\n",
      "2022-07-28 13:46:32,143 - merging changes from 1500 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:32,210 - topic #0 (0.100): 0.012*\"drive\" + 0.008*\"scsi\" + 0.007*\"card\" + 0.006*\"mb\" + 0.006*\"disk\" + 0.005*\"people\" + 0.005*\"hard\" + 0.004*\"bus\" + 0.004*\"bit\" + 0.004*\"drives\"\n",
      "2022-07-28 13:46:32,224 - topic #4 (0.100): 0.012*\"god\" + 0.009*\"people\" + 0.005*\"jesus\" + 0.004*\"time\" + 0.004*\"db\" + 0.004*\"gun\" + 0.003*\"law\" + 0.003*\"christ\" + 0.003*\"life\" + 0.003*\"bible\"\n",
      "2022-07-28 13:46:32,230 - topic #6 (0.100): 0.007*\"ax\" + 0.007*\"hz\" + 0.005*\"ww\" + 0.005*\"st\" + 0.004*\"uw\" + 0.004*\"dos\" + 0.003*\"scx\" + 0.003*\"battery\" + 0.003*\"water\" + 0.003*\"appears\"\n",
      "2022-07-28 13:46:32,236 - topic #7 (0.100): 0.015*\"ax\" + 0.015*\"jpeg\" + 0.008*\"car\" + 0.008*\"gif\" + 0.007*\"image\" + 0.005*\"file\" + 0.004*\"color\" + 0.004*\"images\" + 0.004*\"format\" + 0.003*\"clutch\"\n",
      "2022-07-28 13:46:32,239 - topic #3 (0.100): 0.007*\"team\" + 0.006*\"game\" + 0.005*\"play\" + 0.004*\"period\" + 0.004*\"time\" + 0.004*\"hockey\" + 0.003*\"season\" + 0.003*\"games\" + 0.003*\"pit\" + 0.003*\"win\"\n",
      "2022-07-28 13:46:32,244 - topic diff=0.048395, rho=0.071711\n",
      "2022-07-28 13:46:32,258 - PROGRESS: pass 5, dispatched chunk #51 = documents up to #5200/18846, outstanding queue size 37\n",
      "2022-07-28 13:46:32,280 - PROGRESS: pass 5, dispatched chunk #52 = documents up to #5300/18846, outstanding queue size 34\n",
      "2022-07-28 13:46:32,283 - PROGRESS: pass 5, dispatched chunk #53 = documents up to #5400/18846, outstanding queue size 35\n",
      "2022-07-28 13:46:32,285 - PROGRESS: pass 5, dispatched chunk #54 = documents up to #5500/18846, outstanding queue size 36\n",
      "2022-07-28 13:46:32,287 - PROGRESS: pass 5, dispatched chunk #55 = documents up to #5600/18846, outstanding queue size 37\n",
      "2022-07-28 13:46:32,288 - PROGRESS: pass 5, dispatched chunk #56 = documents up to #5700/18846, outstanding queue size 38\n",
      "2022-07-28 13:46:32,290 - PROGRESS: pass 5, dispatched chunk #57 = documents up to #5800/18846, outstanding queue size 39\n",
      "2022-07-28 13:46:32,291 - PROGRESS: pass 5, dispatched chunk #58 = documents up to #5900/18846, outstanding queue size 40\n",
      "2022-07-28 13:46:32,318 - PROGRESS: pass 5, dispatched chunk #59 = documents up to #6000/18846, outstanding queue size 40\n",
      "2022-07-28 13:46:32,363 - PROGRESS: pass 5, dispatched chunk #60 = documents up to #6100/18846, outstanding queue size 38\n",
      "2022-07-28 13:46:32,364 - PROGRESS: pass 5, dispatched chunk #61 = documents up to #6200/18846, outstanding queue size 39\n",
      "2022-07-28 13:46:32,365 - PROGRESS: pass 5, dispatched chunk #62 = documents up to #6300/18846, outstanding queue size 40\n",
      "2022-07-28 13:46:32,404 - PROGRESS: pass 5, dispatched chunk #63 = documents up to #6400/18846, outstanding queue size 40\n",
      "2022-07-28 13:46:32,405 - PROGRESS: pass 5, dispatched chunk #64 = documents up to #6500/18846, outstanding queue size 41\n",
      "2022-07-28 13:46:32,438 - PROGRESS: pass 5, dispatched chunk #65 = documents up to #6600/18846, outstanding queue size 41\n",
      "2022-07-28 13:46:32,468 - PROGRESS: pass 5, dispatched chunk #66 = documents up to #6700/18846, outstanding queue size 41\n",
      "2022-07-28 13:46:32,497 - PROGRESS: pass 5, dispatched chunk #67 = documents up to #6800/18846, outstanding queue size 40\n",
      "2022-07-28 13:46:32,536 - PROGRESS: pass 5, dispatched chunk #68 = documents up to #6900/18846, outstanding queue size 40\n",
      "2022-07-28 13:46:32,679 - merging changes from 1500 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:32,764 - topic #1 (0.100): 0.008*\"file\" + 0.007*\"windows\" + 0.006*\"software\" + 0.005*\"mail\" + 0.005*\"program\" + 0.005*\"dos\" + 0.005*\"ftp\" + 0.004*\"graphics\" + 0.004*\"list\" + 0.004*\"files\"\n",
      "2022-07-28 13:46:32,769 - topic #5 (0.100): 0.005*\"armenian\" + 0.004*\"azerbaijan\" + 0.003*\"time\" + 0.003*\"book\" + 0.002*\"source\" + 0.002*\"russian\" + 0.002*\"people\" + 0.002*\"players\" + 0.002*\"set\" + 0.002*\"azeri\"\n",
      "2022-07-28 13:46:32,773 - topic #0 (0.100): 0.012*\"drive\" + 0.008*\"scsi\" + 0.007*\"card\" + 0.006*\"mb\" + 0.005*\"disk\" + 0.005*\"people\" + 0.005*\"hard\" + 0.004*\"bus\" + 0.004*\"mhz\" + 0.004*\"bit\"\n",
      "2022-07-28 13:46:32,804 - topic #6 (0.100): 0.007*\"hz\" + 0.007*\"ax\" + 0.005*\"ww\" + 0.005*\"st\" + 0.004*\"dos\" + 0.004*\"uw\" + 0.004*\"appears\" + 0.003*\"art\" + 0.003*\"battery\" + 0.003*\"tl\"\n",
      "2022-07-28 13:46:32,806 - topic #4 (0.100): 0.012*\"god\" + 0.009*\"people\" + 0.006*\"jesus\" + 0.005*\"time\" + 0.003*\"gun\" + 0.003*\"db\" + 0.003*\"law\" + 0.003*\"christ\" + 0.003*\"life\" + 0.003*\"bible\"\n",
      "2022-07-28 13:46:32,809 - topic diff=0.058097, rho=0.071711\n",
      "2022-07-28 13:46:32,812 - PROGRESS: pass 5, dispatched chunk #69 = documents up to #7000/18846, outstanding queue size 40\n",
      "2022-07-28 13:46:32,823 - PROGRESS: pass 5, dispatched chunk #70 = documents up to #7100/18846, outstanding queue size 40\n",
      "2022-07-28 13:46:32,826 - PROGRESS: pass 5, dispatched chunk #71 = documents up to #7200/18846, outstanding queue size 41\n",
      "2022-07-28 13:46:32,827 - PROGRESS: pass 5, dispatched chunk #72 = documents up to #7300/18846, outstanding queue size 42\n",
      "2022-07-28 13:46:32,829 - PROGRESS: pass 5, dispatched chunk #73 = documents up to #7400/18846, outstanding queue size 43\n",
      "2022-07-28 13:46:32,830 - PROGRESS: pass 5, dispatched chunk #74 = documents up to #7500/18846, outstanding queue size 44\n",
      "2022-07-28 13:46:32,834 - PROGRESS: pass 5, dispatched chunk #75 = documents up to #7600/18846, outstanding queue size 45\n",
      "2022-07-28 13:46:32,835 - PROGRESS: pass 5, dispatched chunk #76 = documents up to #7700/18846, outstanding queue size 46\n",
      "2022-07-28 13:46:32,837 - PROGRESS: pass 5, dispatched chunk #77 = documents up to #7800/18846, outstanding queue size 47\n",
      "2022-07-28 13:46:32,840 - PROGRESS: pass 5, dispatched chunk #78 = documents up to #7900/18846, outstanding queue size 48\n",
      "2022-07-28 13:46:32,908 - PROGRESS: pass 5, dispatched chunk #79 = documents up to #8000/18846, outstanding queue size 48\n",
      "2022-07-28 13:46:32,985 - PROGRESS: pass 5, dispatched chunk #80 = documents up to #8100/18846, outstanding queue size 48\n",
      "2022-07-28 13:46:32,994 - PROGRESS: pass 5, dispatched chunk #81 = documents up to #8200/18846, outstanding queue size 49\n",
      "2022-07-28 13:46:32,996 - PROGRESS: pass 5, dispatched chunk #82 = documents up to #8300/18846, outstanding queue size 50\n",
      "2022-07-28 13:46:33,020 - PROGRESS: pass 5, dispatched chunk #83 = documents up to #8400/18846, outstanding queue size 51\n",
      "2022-07-28 13:46:33,038 - PROGRESS: pass 5, dispatched chunk #84 = documents up to #8500/18846, outstanding queue size 52\n",
      "2022-07-28 13:46:33,049 - PROGRESS: pass 5, dispatched chunk #85 = documents up to #8600/18846, outstanding queue size 53\n",
      "2022-07-28 13:46:33,124 - PROGRESS: pass 5, dispatched chunk #86 = documents up to #8700/18846, outstanding queue size 53\n",
      "2022-07-28 13:46:33,125 - PROGRESS: pass 5, dispatched chunk #87 = documents up to #8800/18846, outstanding queue size 54\n",
      "2022-07-28 13:46:33,126 - PROGRESS: pass 5, dispatched chunk #88 = documents up to #8900/18846, outstanding queue size 55\n",
      "2022-07-28 13:46:33,200 - PROGRESS: pass 5, dispatched chunk #89 = documents up to #9000/18846, outstanding queue size 52\n",
      "2022-07-28 13:46:33,243 - PROGRESS: pass 5, dispatched chunk #90 = documents up to #9100/18846, outstanding queue size 50\n",
      "2022-07-28 13:46:33,247 - PROGRESS: pass 5, dispatched chunk #91 = documents up to #9200/18846, outstanding queue size 51\n",
      "2022-07-28 13:46:33,248 - PROGRESS: pass 5, dispatched chunk #92 = documents up to #9300/18846, outstanding queue size 52\n",
      "2022-07-28 13:46:33,256 - PROGRESS: pass 5, dispatched chunk #93 = documents up to #9400/18846, outstanding queue size 52\n",
      "2022-07-28 13:46:33,305 - PROGRESS: pass 5, dispatched chunk #94 = documents up to #9500/18846, outstanding queue size 52\n",
      "2022-07-28 13:46:33,308 - PROGRESS: pass 5, dispatched chunk #95 = documents up to #9600/18846, outstanding queue size 53\n",
      "2022-07-28 13:46:33,527 - merging changes from 1500 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:33,659 - topic #6 (0.100): 0.007*\"hz\" + 0.006*\"ax\" + 0.005*\"scx\" + 0.005*\"ww\" + 0.004*\"st\" + 0.004*\"uw\" + 0.004*\"dos\" + 0.004*\"tl\" + 0.004*\"zd\" + 0.004*\"cj\"\n",
      "2022-07-28 13:46:33,662 - topic #9 (0.100): 0.012*\"people\" + 0.005*\"israel\" + 0.004*\"president\" + 0.004*\"jews\" + 0.003*\"government\" + 0.003*\"time\" + 0.003*\"war\" + 0.003*\"children\" + 0.003*\"israeli\" + 0.002*\"question\"\n",
      "2022-07-28 13:46:33,664 - topic #0 (0.100): 0.012*\"drive\" + 0.007*\"scsi\" + 0.007*\"card\" + 0.007*\"mb\" + 0.005*\"disk\" + 0.005*\"people\" + 0.005*\"hard\" + 0.004*\"mhz\" + 0.004*\"bus\" + 0.004*\"bit\"\n",
      "2022-07-28 13:46:33,666 - topic #5 (0.100): 0.005*\"armenian\" + 0.004*\"azerbaijan\" + 0.003*\"time\" + 0.003*\"book\" + 0.002*\"source\" + 0.002*\"russian\" + 0.002*\"people\" + 0.002*\"xfree\" + 0.002*\"players\" + 0.002*\"set\"\n",
      "2022-07-28 13:46:33,667 - topic #7 (0.100): 0.020*\"jpeg\" + 0.012*\"ax\" + 0.010*\"gif\" + 0.009*\"image\" + 0.008*\"car\" + 0.006*\"file\" + 0.005*\"color\" + 0.005*\"images\" + 0.005*\"format\" + 0.004*\"quality\"\n",
      "2022-07-28 13:46:33,669 - topic diff=0.052164, rho=0.071711\n",
      "2022-07-28 13:46:33,670 - PROGRESS: pass 5, dispatched chunk #96 = documents up to #9700/18846, outstanding queue size 52\n",
      "2022-07-28 13:46:33,672 - PROGRESS: pass 5, dispatched chunk #97 = documents up to #9800/18846, outstanding queue size 52\n",
      "2022-07-28 13:46:33,673 - PROGRESS: pass 5, dispatched chunk #98 = documents up to #9900/18846, outstanding queue size 53\n",
      "2022-07-28 13:46:33,674 - PROGRESS: pass 5, dispatched chunk #99 = documents up to #10000/18846, outstanding queue size 54\n",
      "2022-07-28 13:46:33,674 - PROGRESS: pass 5, dispatched chunk #100 = documents up to #10100/18846, outstanding queue size 55\n",
      "2022-07-28 13:46:33,675 - PROGRESS: pass 5, dispatched chunk #101 = documents up to #10200/18846, outstanding queue size 56\n",
      "2022-07-28 13:46:33,675 - PROGRESS: pass 5, dispatched chunk #102 = documents up to #10300/18846, outstanding queue size 57\n",
      "2022-07-28 13:46:33,697 - PROGRESS: pass 5, dispatched chunk #103 = documents up to #10400/18846, outstanding queue size 58\n",
      "2022-07-28 13:46:33,735 - PROGRESS: pass 5, dispatched chunk #104 = documents up to #10500/18846, outstanding queue size 59\n",
      "2022-07-28 13:46:33,740 - PROGRESS: pass 5, dispatched chunk #105 = documents up to #10600/18846, outstanding queue size 60\n",
      "2022-07-28 13:46:33,754 - PROGRESS: pass 5, dispatched chunk #106 = documents up to #10700/18846, outstanding queue size 59\n",
      "2022-07-28 13:46:33,754 - PROGRESS: pass 5, dispatched chunk #107 = documents up to #10800/18846, outstanding queue size 60\n",
      "2022-07-28 13:46:33,759 - PROGRESS: pass 5, dispatched chunk #108 = documents up to #10900/18846, outstanding queue size 61\n",
      "2022-07-28 13:46:33,760 - PROGRESS: pass 5, dispatched chunk #109 = documents up to #11000/18846, outstanding queue size 62\n",
      "2022-07-28 13:46:33,775 - PROGRESS: pass 5, dispatched chunk #110 = documents up to #11100/18846, outstanding queue size 63\n",
      "2022-07-28 13:46:33,779 - PROGRESS: pass 5, dispatched chunk #111 = documents up to #11200/18846, outstanding queue size 64\n",
      "2022-07-28 13:46:33,809 - PROGRESS: pass 5, dispatched chunk #112 = documents up to #11300/18846, outstanding queue size 61\n",
      "2022-07-28 13:46:33,810 - PROGRESS: pass 5, dispatched chunk #113 = documents up to #11400/18846, outstanding queue size 62\n",
      "2022-07-28 13:46:33,811 - PROGRESS: pass 5, dispatched chunk #114 = documents up to #11500/18846, outstanding queue size 63\n",
      "2022-07-28 13:46:33,811 - PROGRESS: pass 5, dispatched chunk #115 = documents up to #11600/18846, outstanding queue size 64\n",
      "2022-07-28 13:46:33,812 - PROGRESS: pass 5, dispatched chunk #116 = documents up to #11700/18846, outstanding queue size 65\n",
      "2022-07-28 13:46:33,836 - PROGRESS: pass 5, dispatched chunk #117 = documents up to #11800/18846, outstanding queue size 66\n",
      "2022-07-28 13:46:33,853 - PROGRESS: pass 5, dispatched chunk #118 = documents up to #11900/18846, outstanding queue size 67\n",
      "2022-07-28 13:46:33,855 - PROGRESS: pass 5, dispatched chunk #119 = documents up to #12000/18846, outstanding queue size 68\n",
      "2022-07-28 13:46:33,880 - PROGRESS: pass 5, dispatched chunk #120 = documents up to #12100/18846, outstanding queue size 67\n",
      "2022-07-28 13:46:33,882 - PROGRESS: pass 5, dispatched chunk #121 = documents up to #12200/18846, outstanding queue size 68\n",
      "2022-07-28 13:46:33,910 - PROGRESS: pass 5, dispatched chunk #122 = documents up to #12300/18846, outstanding queue size 68\n",
      "2022-07-28 13:46:33,924 - PROGRESS: pass 5, dispatched chunk #123 = documents up to #12400/18846, outstanding queue size 67\n",
      "2022-07-28 13:46:33,927 - PROGRESS: pass 5, dispatched chunk #124 = documents up to #12500/18846, outstanding queue size 68\n",
      "2022-07-28 13:46:33,979 - PROGRESS: pass 5, dispatched chunk #125 = documents up to #12600/18846, outstanding queue size 69\n",
      "2022-07-28 13:46:33,984 - PROGRESS: pass 5, dispatched chunk #126 = documents up to #12700/18846, outstanding queue size 70\n",
      "2022-07-28 13:46:34,019 - PROGRESS: pass 5, dispatched chunk #127 = documents up to #12800/18846, outstanding queue size 71\n",
      "2022-07-28 13:46:34,024 - PROGRESS: pass 5, dispatched chunk #128 = documents up to #12900/18846, outstanding queue size 72\n",
      "2022-07-28 13:46:34,033 - PROGRESS: pass 5, dispatched chunk #129 = documents up to #13000/18846, outstanding queue size 73\n",
      "2022-07-28 13:46:34,235 - merging changes from 1500 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:34,369 - topic #2 (0.100): 0.006*\"space\" + 0.006*\"time\" + 0.005*\"people\" + 0.004*\"government\" + 0.003*\"key\" + 0.003*\"car\" + 0.003*\"power\" + 0.003*\"encryption\" + 0.002*\"public\" + 0.002*\"clipper\"\n",
      "2022-07-28 13:46:34,371 - topic #3 (0.100): 0.007*\"team\" + 0.007*\"game\" + 0.005*\"play\" + 0.004*\"time\" + 0.004*\"period\" + 0.004*\"season\" + 0.004*\"hockey\" + 0.004*\"games\" + 0.003*\"win\" + 0.003*\"players\"\n",
      "2022-07-28 13:46:34,372 - topic #4 (0.100): 0.013*\"god\" + 0.009*\"people\" + 0.006*\"jesus\" + 0.005*\"time\" + 0.003*\"gun\" + 0.003*\"christ\" + 0.003*\"law\" + 0.003*\"life\" + 0.003*\"db\" + 0.003*\"bible\"\n",
      "2022-07-28 13:46:34,374 - topic #5 (0.100): 0.005*\"armenian\" + 0.004*\"azerbaijan\" + 0.003*\"time\" + 0.003*\"book\" + 0.003*\"source\" + 0.002*\"players\" + 0.002*\"russian\" + 0.002*\"people\" + 0.002*\"xfree\" + 0.002*\"set\"\n",
      "2022-07-28 13:46:34,375 - topic #6 (0.100): 0.007*\"hz\" + 0.006*\"ax\" + 0.005*\"scx\" + 0.005*\"ww\" + 0.005*\"st\" + 0.004*\"uw\" + 0.004*\"dos\" + 0.004*\"tl\" + 0.003*\"zd\" + 0.003*\"appears\"\n",
      "2022-07-28 13:46:34,377 - topic diff=0.047952, rho=0.071711\n",
      "2022-07-28 13:46:34,378 - PROGRESS: pass 5, dispatched chunk #130 = documents up to #13100/18846, outstanding queue size 71\n",
      "2022-07-28 13:46:34,388 - PROGRESS: pass 5, dispatched chunk #131 = documents up to #13200/18846, outstanding queue size 69\n",
      "2022-07-28 13:46:34,389 - PROGRESS: pass 5, dispatched chunk #132 = documents up to #13300/18846, outstanding queue size 70\n",
      "2022-07-28 13:46:34,389 - PROGRESS: pass 5, dispatched chunk #133 = documents up to #13400/18846, outstanding queue size 71\n",
      "2022-07-28 13:46:34,390 - PROGRESS: pass 5, dispatched chunk #134 = documents up to #13500/18846, outstanding queue size 72\n",
      "2022-07-28 13:46:34,391 - PROGRESS: pass 5, dispatched chunk #135 = documents up to #13600/18846, outstanding queue size 73\n",
      "2022-07-28 13:46:34,391 - PROGRESS: pass 5, dispatched chunk #136 = documents up to #13700/18846, outstanding queue size 74\n",
      "2022-07-28 13:46:34,392 - PROGRESS: pass 5, dispatched chunk #137 = documents up to #13800/18846, outstanding queue size 75\n",
      "2022-07-28 13:46:34,392 - PROGRESS: pass 5, dispatched chunk #138 = documents up to #13900/18846, outstanding queue size 76\n",
      "2022-07-28 13:46:34,393 - PROGRESS: pass 5, dispatched chunk #139 = documents up to #14000/18846, outstanding queue size 77\n",
      "2022-07-28 13:46:34,489 - PROGRESS: pass 5, dispatched chunk #140 = documents up to #14100/18846, outstanding queue size 75\n",
      "2022-07-28 13:46:34,492 - PROGRESS: pass 5, dispatched chunk #141 = documents up to #14200/18846, outstanding queue size 76\n",
      "2022-07-28 13:46:34,559 - PROGRESS: pass 5, dispatched chunk #142 = documents up to #14300/18846, outstanding queue size 77\n",
      "2022-07-28 13:46:34,578 - PROGRESS: pass 5, dispatched chunk #143 = documents up to #14400/18846, outstanding queue size 78\n",
      "2022-07-28 13:46:34,621 - PROGRESS: pass 5, dispatched chunk #144 = documents up to #14500/18846, outstanding queue size 79\n",
      "2022-07-28 13:46:34,649 - PROGRESS: pass 5, dispatched chunk #145 = documents up to #14600/18846, outstanding queue size 78\n",
      "2022-07-28 13:46:34,656 - PROGRESS: pass 5, dispatched chunk #146 = documents up to #14700/18846, outstanding queue size 79\n",
      "2022-07-28 13:46:34,689 - PROGRESS: pass 5, dispatched chunk #147 = documents up to #14800/18846, outstanding queue size 79\n",
      "2022-07-28 13:46:34,705 - PROGRESS: pass 5, dispatched chunk #148 = documents up to #14900/18846, outstanding queue size 80\n",
      "2022-07-28 13:46:34,739 - PROGRESS: pass 5, dispatched chunk #149 = documents up to #15000/18846, outstanding queue size 81\n",
      "2022-07-28 13:46:34,756 - PROGRESS: pass 5, dispatched chunk #150 = documents up to #15100/18846, outstanding queue size 81\n",
      "2022-07-28 13:46:34,762 - PROGRESS: pass 5, dispatched chunk #151 = documents up to #15200/18846, outstanding queue size 82\n",
      "2022-07-28 13:46:34,777 - PROGRESS: pass 5, dispatched chunk #152 = documents up to #15300/18846, outstanding queue size 83\n",
      "2022-07-28 13:46:34,780 - PROGRESS: pass 5, dispatched chunk #153 = documents up to #15400/18846, outstanding queue size 84\n",
      "2022-07-28 13:46:34,785 - PROGRESS: pass 5, dispatched chunk #154 = documents up to #15500/18846, outstanding queue size 85\n",
      "2022-07-28 13:46:34,813 - PROGRESS: pass 5, dispatched chunk #155 = documents up to #15600/18846, outstanding queue size 86\n",
      "2022-07-28 13:46:34,890 - merging changes from 1800 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:34,975 - topic #3 (0.100): 0.007*\"game\" + 0.007*\"team\" + 0.005*\"play\" + 0.004*\"period\" + 0.004*\"time\" + 0.004*\"season\" + 0.004*\"games\" + 0.004*\"hockey\" + 0.003*\"win\" + 0.003*\"players\"\n",
      "2022-07-28 13:46:34,977 - topic #6 (0.100): 0.008*\"hz\" + 0.006*\"ww\" + 0.005*\"uw\" + 0.005*\"scx\" + 0.005*\"ax\" + 0.004*\"st\" + 0.004*\"zd\" + 0.004*\"cj\" + 0.004*\"tl\" + 0.003*\"dos\"\n",
      "2022-07-28 13:46:34,979 - topic #0 (0.100): 0.013*\"drive\" + 0.008*\"scsi\" + 0.007*\"mb\" + 0.007*\"card\" + 0.006*\"disk\" + 0.005*\"hard\" + 0.005*\"people\" + 0.005*\"mhz\" + 0.005*\"bus\" + 0.005*\"bit\"\n",
      "2022-07-28 13:46:34,983 - topic #9 (0.100): 0.012*\"people\" + 0.005*\"israel\" + 0.004*\"president\" + 0.004*\"government\" + 0.004*\"jews\" + 0.003*\"time\" + 0.003*\"war\" + 0.003*\"children\" + 0.003*\"israeli\" + 0.003*\"question\"\n",
      "2022-07-28 13:46:34,985 - topic #8 (0.100): 0.612*\"ax\" + 0.049*\"max\" + 0.005*\"di\" + 0.004*\"ei\" + 0.003*\"tm\" + 0.003*\"giz\" + 0.002*\"bhj\" + 0.002*\"wm\" + 0.002*\"printf\" + 0.002*\"ey\"\n",
      "2022-07-28 13:46:34,988 - topic diff=0.045701, rho=0.071711\n",
      "2022-07-28 13:46:34,990 - PROGRESS: pass 5, dispatched chunk #156 = documents up to #15700/18846, outstanding queue size 79\n",
      "2022-07-28 13:46:35,008 - PROGRESS: pass 5, dispatched chunk #157 = documents up to #15800/18846, outstanding queue size 74\n",
      "2022-07-28 13:46:35,009 - PROGRESS: pass 5, dispatched chunk #158 = documents up to #15900/18846, outstanding queue size 75\n",
      "2022-07-28 13:46:35,009 - PROGRESS: pass 5, dispatched chunk #159 = documents up to #16000/18846, outstanding queue size 76\n",
      "2022-07-28 13:46:35,010 - PROGRESS: pass 5, dispatched chunk #160 = documents up to #16100/18846, outstanding queue size 77\n",
      "2022-07-28 13:46:35,010 - PROGRESS: pass 5, dispatched chunk #161 = documents up to #16200/18846, outstanding queue size 78\n",
      "2022-07-28 13:46:35,011 - PROGRESS: pass 5, dispatched chunk #162 = documents up to #16300/18846, outstanding queue size 79\n",
      "2022-07-28 13:46:35,053 - PROGRESS: pass 5, dispatched chunk #163 = documents up to #16400/18846, outstanding queue size 78\n",
      "2022-07-28 13:46:35,062 - PROGRESS: pass 5, dispatched chunk #164 = documents up to #16500/18846, outstanding queue size 79\n",
      "2022-07-28 13:46:35,062 - PROGRESS: pass 5, dispatched chunk #165 = documents up to #16600/18846, outstanding queue size 80\n",
      "2022-07-28 13:46:35,063 - PROGRESS: pass 5, dispatched chunk #166 = documents up to #16700/18846, outstanding queue size 81\n",
      "2022-07-28 13:46:35,063 - PROGRESS: pass 5, dispatched chunk #167 = documents up to #16800/18846, outstanding queue size 82\n",
      "2022-07-28 13:46:35,064 - PROGRESS: pass 5, dispatched chunk #168 = documents up to #16900/18846, outstanding queue size 83\n",
      "2022-07-28 13:46:35,124 - PROGRESS: pass 5, dispatched chunk #169 = documents up to #17000/18846, outstanding queue size 80\n",
      "2022-07-28 13:46:35,124 - PROGRESS: pass 5, dispatched chunk #170 = documents up to #17100/18846, outstanding queue size 81\n",
      "2022-07-28 13:46:35,223 - merging changes from 1900 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:35,320 - topic #2 (0.100): 0.006*\"space\" + 0.006*\"time\" + 0.004*\"people\" + 0.004*\"government\" + 0.003*\"key\" + 0.003*\"car\" + 0.003*\"power\" + 0.003*\"encryption\" + 0.002*\"public\" + 0.002*\"clipper\"\n",
      "2022-07-28 13:46:35,321 - topic #1 (0.100): 0.008*\"file\" + 0.007*\"windows\" + 0.006*\"program\" + 0.005*\"mail\" + 0.005*\"software\" + 0.005*\"ftp\" + 0.004*\"graphics\" + 0.004*\"dos\" + 0.004*\"list\" + 0.004*\"data\"\n",
      "2022-07-28 13:46:35,324 - topic #0 (0.100): 0.013*\"drive\" + 0.008*\"scsi\" + 0.007*\"card\" + 0.007*\"mb\" + 0.006*\"disk\" + 0.005*\"hard\" + 0.005*\"people\" + 0.005*\"mhz\" + 0.005*\"bit\" + 0.004*\"bus\"\n",
      "2022-07-28 13:46:35,326 - topic #3 (0.100): 0.008*\"game\" + 0.007*\"team\" + 0.005*\"play\" + 0.004*\"period\" + 0.004*\"time\" + 0.004*\"season\" + 0.004*\"games\" + 0.004*\"hockey\" + 0.003*\"win\" + 0.003*\"pts\"\n",
      "2022-07-28 13:46:35,330 - topic #5 (0.100): 0.005*\"armenian\" + 0.004*\"azerbaijan\" + 0.003*\"time\" + 0.003*\"book\" + 0.003*\"source\" + 0.003*\"russian\" + 0.002*\"people\" + 0.002*\"players\" + 0.002*\"xfree\" + 0.002*\"armenians\"\n",
      "2022-07-28 13:46:35,331 - topic diff=0.049209, rho=0.071711\n",
      "2022-07-28 13:46:35,336 - PROGRESS: pass 5, dispatched chunk #171 = documents up to #17200/18846, outstanding queue size 75\n",
      "2022-07-28 13:46:35,342 - PROGRESS: pass 5, dispatched chunk #172 = documents up to #17300/18846, outstanding queue size 75\n",
      "2022-07-28 13:46:35,343 - PROGRESS: pass 5, dispatched chunk #173 = documents up to #17400/18846, outstanding queue size 76\n",
      "2022-07-28 13:46:35,343 - PROGRESS: pass 5, dispatched chunk #174 = documents up to #17500/18846, outstanding queue size 77\n",
      "2022-07-28 13:46:35,343 - PROGRESS: pass 5, dispatched chunk #175 = documents up to #17600/18846, outstanding queue size 78\n",
      "2022-07-28 13:46:35,347 - PROGRESS: pass 5, dispatched chunk #176 = documents up to #17700/18846, outstanding queue size 79\n",
      "2022-07-28 13:46:35,347 - PROGRESS: pass 5, dispatched chunk #177 = documents up to #17800/18846, outstanding queue size 80\n",
      "2022-07-28 13:46:35,348 - PROGRESS: pass 5, dispatched chunk #178 = documents up to #17900/18846, outstanding queue size 81\n",
      "2022-07-28 13:46:35,349 - PROGRESS: pass 5, dispatched chunk #179 = documents up to #18000/18846, outstanding queue size 82\n",
      "2022-07-28 13:46:35,352 - PROGRESS: pass 5, dispatched chunk #180 = documents up to #18100/18846, outstanding queue size 83\n",
      "2022-07-28 13:46:35,352 - PROGRESS: pass 5, dispatched chunk #181 = documents up to #18200/18846, outstanding queue size 84\n",
      "2022-07-28 13:46:35,353 - PROGRESS: pass 5, dispatched chunk #182 = documents up to #18300/18846, outstanding queue size 85\n",
      "2022-07-28 13:46:35,353 - PROGRESS: pass 5, dispatched chunk #183 = documents up to #18400/18846, outstanding queue size 86\n",
      "2022-07-28 13:46:35,385 - PROGRESS: pass 5, dispatched chunk #184 = documents up to #18500/18846, outstanding queue size 83\n",
      "2022-07-28 13:46:35,433 - PROGRESS: pass 5, dispatched chunk #185 = documents up to #18600/18846, outstanding queue size 83\n",
      "2022-07-28 13:46:35,457 - PROGRESS: pass 5, dispatched chunk #186 = documents up to #18700/18846, outstanding queue size 83\n",
      "2022-07-28 13:46:35,530 - PROGRESS: pass 5, dispatched chunk #187 = documents up to #18800/18846, outstanding queue size 82\n",
      "2022-07-28 13:46:35,532 - PROGRESS: pass 5, dispatched chunk #188 = documents up to #18846/18846, outstanding queue size 83\n",
      "2022-07-28 13:46:35,809 - merging changes from 1700 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:35,945 - topic #2 (0.100): 0.006*\"space\" + 0.006*\"time\" + 0.004*\"government\" + 0.004*\"people\" + 0.003*\"key\" + 0.003*\"car\" + 0.003*\"power\" + 0.003*\"encryption\" + 0.002*\"public\" + 0.002*\"clipper\"\n",
      "2022-07-28 13:46:35,954 - topic #5 (0.100): 0.006*\"armenian\" + 0.004*\"azerbaijan\" + 0.003*\"book\" + 0.003*\"time\" + 0.003*\"source\" + 0.003*\"russian\" + 0.002*\"people\" + 0.002*\"armenians\" + 0.002*\"xfree\" + 0.002*\"players\"\n",
      "2022-07-28 13:46:35,958 - topic #7 (0.100): 0.020*\"jpeg\" + 0.010*\"gif\" + 0.010*\"ax\" + 0.009*\"image\" + 0.008*\"car\" + 0.007*\"file\" + 0.006*\"color\" + 0.005*\"images\" + 0.005*\"format\" + 0.004*\"quality\"\n",
      "2022-07-28 13:46:35,961 - topic #0 (0.100): 0.013*\"drive\" + 0.009*\"scsi\" + 0.007*\"mb\" + 0.007*\"card\" + 0.006*\"disk\" + 0.005*\"hard\" + 0.005*\"people\" + 0.005*\"bus\" + 0.005*\"bit\" + 0.005*\"mhz\"\n",
      "2022-07-28 13:46:35,964 - topic #1 (0.100): 0.008*\"file\" + 0.007*\"windows\" + 0.006*\"program\" + 0.006*\"software\" + 0.005*\"mail\" + 0.005*\"ftp\" + 0.005*\"graphics\" + 0.004*\"data\" + 0.004*\"dos\" + 0.004*\"list\"\n",
      "2022-07-28 13:46:35,967 - topic diff=0.040552, rho=0.071711\n",
      "2022-07-28 13:46:36,169 - -10.482 per-word bound, 1430.2 perplexity estimate based on a held-out corpus of 46 documents with 2932 words\n",
      "2022-07-28 13:46:36,396 - merging changes from 3100 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:36,478 - topic #0 (0.100): 0.013*\"drive\" + 0.009*\"scsi\" + 0.007*\"card\" + 0.007*\"mb\" + 0.006*\"disk\" + 0.005*\"hard\" + 0.005*\"bus\" + 0.005*\"people\" + 0.005*\"bit\" + 0.004*\"mhz\"\n",
      "2022-07-28 13:46:36,483 - topic #7 (0.100): 0.019*\"jpeg\" + 0.010*\"gif\" + 0.009*\"ax\" + 0.009*\"image\" + 0.008*\"car\" + 0.006*\"file\" + 0.006*\"color\" + 0.005*\"images\" + 0.005*\"format\" + 0.004*\"quality\"\n",
      "2022-07-28 13:46:36,487 - topic #3 (0.100): 0.008*\"game\" + 0.007*\"team\" + 0.005*\"play\" + 0.004*\"period\" + 0.004*\"games\" + 0.004*\"time\" + 0.004*\"season\" + 0.004*\"hockey\" + 0.003*\"win\" + 0.003*\"players\"\n",
      "2022-07-28 13:46:36,491 - topic #1 (0.100): 0.009*\"file\" + 0.007*\"windows\" + 0.006*\"program\" + 0.006*\"software\" + 0.005*\"mail\" + 0.005*\"ftp\" + 0.005*\"graphics\" + 0.004*\"data\" + 0.004*\"dos\" + 0.004*\"list\"\n",
      "2022-07-28 13:46:36,493 - topic #5 (0.100): 0.006*\"armenian\" + 0.004*\"azerbaijan\" + 0.003*\"book\" + 0.003*\"time\" + 0.003*\"source\" + 0.002*\"russian\" + 0.002*\"xfree\" + 0.002*\"armenians\" + 0.002*\"people\" + 0.002*\"players\"\n",
      "2022-07-28 13:46:36,496 - topic diff=0.037632, rho=0.071711\n",
      "2022-07-28 13:46:36,572 - -10.465 per-word bound, 1413.1 perplexity estimate based on a held-out corpus of 46 documents with 2932 words\n",
      "2022-07-28 13:46:36,700 - merging changes from 4346 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:36,730 - topic #3 (0.100): 0.008*\"game\" + 0.008*\"team\" + 0.005*\"play\" + 0.004*\"games\" + 0.004*\"period\" + 0.004*\"season\" + 0.004*\"time\" + 0.004*\"hockey\" + 0.003*\"win\" + 0.003*\"players\"\n",
      "2022-07-28 13:46:36,732 - topic #2 (0.100): 0.006*\"space\" + 0.006*\"time\" + 0.004*\"government\" + 0.004*\"people\" + 0.003*\"key\" + 0.003*\"car\" + 0.003*\"power\" + 0.003*\"encryption\" + 0.002*\"public\" + 0.002*\"chip\"\n",
      "2022-07-28 13:46:36,734 - topic #4 (0.100): 0.013*\"god\" + 0.009*\"people\" + 0.005*\"jesus\" + 0.005*\"time\" + 0.004*\"db\" + 0.004*\"gun\" + 0.003*\"christ\" + 0.003*\"law\" + 0.003*\"life\" + 0.003*\"bible\"\n",
      "2022-07-28 13:46:36,735 - topic #7 (0.100): 0.019*\"jpeg\" + 0.010*\"gif\" + 0.009*\"image\" + 0.009*\"ax\" + 0.009*\"car\" + 0.006*\"file\" + 0.006*\"color\" + 0.005*\"images\" + 0.005*\"format\" + 0.004*\"quality\"\n",
      "2022-07-28 13:46:36,737 - topic #9 (0.100): 0.012*\"people\" + 0.005*\"israel\" + 0.004*\"president\" + 0.004*\"government\" + 0.004*\"jews\" + 0.004*\"time\" + 0.003*\"war\" + 0.003*\"children\" + 0.003*\"israeli\" + 0.003*\"jewish\"\n",
      "2022-07-28 13:46:36,738 - topic diff=0.038036, rho=0.071711\n",
      "2022-07-28 13:46:36,810 - -10.436 per-word bound, 1385.5 perplexity estimate based on a held-out corpus of 46 documents with 2932 words\n",
      "2022-07-28 13:46:36,810 - PROGRESS: pass 6, dispatched chunk #0 = documents up to #100/18846, outstanding queue size 1\n",
      "2022-07-28 13:46:36,813 - PROGRESS: pass 6, dispatched chunk #1 = documents up to #200/18846, outstanding queue size 2\n",
      "2022-07-28 13:46:36,813 - PROGRESS: pass 6, dispatched chunk #2 = documents up to #300/18846, outstanding queue size 3\n",
      "2022-07-28 13:46:36,814 - PROGRESS: pass 6, dispatched chunk #3 = documents up to #400/18846, outstanding queue size 4\n",
      "2022-07-28 13:46:36,814 - PROGRESS: pass 6, dispatched chunk #4 = documents up to #500/18846, outstanding queue size 5\n",
      "2022-07-28 13:46:36,814 - PROGRESS: pass 6, dispatched chunk #5 = documents up to #600/18846, outstanding queue size 6\n",
      "2022-07-28 13:46:36,816 - PROGRESS: pass 6, dispatched chunk #6 = documents up to #700/18846, outstanding queue size 7\n",
      "2022-07-28 13:46:36,817 - PROGRESS: pass 6, dispatched chunk #7 = documents up to #800/18846, outstanding queue size 8\n",
      "2022-07-28 13:46:36,817 - PROGRESS: pass 6, dispatched chunk #8 = documents up to #900/18846, outstanding queue size 9\n",
      "2022-07-28 13:46:36,818 - PROGRESS: pass 6, dispatched chunk #9 = documents up to #1000/18846, outstanding queue size 10\n",
      "2022-07-28 13:46:36,818 - PROGRESS: pass 6, dispatched chunk #10 = documents up to #1100/18846, outstanding queue size 11\n",
      "2022-07-28 13:46:36,818 - PROGRESS: pass 6, dispatched chunk #11 = documents up to #1200/18846, outstanding queue size 12\n",
      "2022-07-28 13:46:36,819 - PROGRESS: pass 6, dispatched chunk #12 = documents up to #1300/18846, outstanding queue size 13\n",
      "2022-07-28 13:46:36,821 - PROGRESS: pass 6, dispatched chunk #13 = documents up to #1400/18846, outstanding queue size 14\n",
      "2022-07-28 13:46:36,821 - PROGRESS: pass 6, dispatched chunk #14 = documents up to #1500/18846, outstanding queue size 15\n",
      "2022-07-28 13:46:36,822 - PROGRESS: pass 6, dispatched chunk #15 = documents up to #1600/18846, outstanding queue size 16\n",
      "2022-07-28 13:46:36,822 - PROGRESS: pass 6, dispatched chunk #16 = documents up to #1700/18846, outstanding queue size 17\n",
      "2022-07-28 13:46:36,823 - PROGRESS: pass 6, dispatched chunk #17 = documents up to #1800/18846, outstanding queue size 18\n",
      "2022-07-28 13:46:36,823 - PROGRESS: pass 6, dispatched chunk #18 = documents up to #1900/18846, outstanding queue size 19\n",
      "2022-07-28 13:46:36,825 - PROGRESS: pass 6, dispatched chunk #19 = documents up to #2000/18846, outstanding queue size 20\n",
      "2022-07-28 13:46:36,826 - PROGRESS: pass 6, dispatched chunk #20 = documents up to #2100/18846, outstanding queue size 21\n",
      "2022-07-28 13:46:36,826 - PROGRESS: pass 6, dispatched chunk #21 = documents up to #2200/18846, outstanding queue size 22\n",
      "2022-07-28 13:46:36,826 - PROGRESS: pass 6, dispatched chunk #22 = documents up to #2300/18846, outstanding queue size 23\n",
      "2022-07-28 13:46:36,827 - PROGRESS: pass 6, dispatched chunk #23 = documents up to #2400/18846, outstanding queue size 24\n",
      "2022-07-28 13:46:36,827 - PROGRESS: pass 6, dispatched chunk #24 = documents up to #2500/18846, outstanding queue size 25\n",
      "2022-07-28 13:46:36,830 - PROGRESS: pass 6, dispatched chunk #25 = documents up to #2600/18846, outstanding queue size 26\n",
      "2022-07-28 13:46:36,830 - PROGRESS: pass 6, dispatched chunk #26 = documents up to #2700/18846, outstanding queue size 27\n",
      "2022-07-28 13:46:36,831 - PROGRESS: pass 6, dispatched chunk #27 = documents up to #2800/18846, outstanding queue size 28\n",
      "2022-07-28 13:46:36,831 - PROGRESS: pass 6, dispatched chunk #28 = documents up to #2900/18846, outstanding queue size 29\n",
      "2022-07-28 13:46:36,832 - PROGRESS: pass 6, dispatched chunk #29 = documents up to #3000/18846, outstanding queue size 30\n",
      "2022-07-28 13:46:36,836 - PROGRESS: pass 6, dispatched chunk #30 = documents up to #3100/18846, outstanding queue size 31\n",
      "2022-07-28 13:46:36,836 - PROGRESS: pass 6, dispatched chunk #31 = documents up to #3200/18846, outstanding queue size 32\n",
      "2022-07-28 13:46:36,837 - PROGRESS: pass 6, dispatched chunk #32 = documents up to #3300/18846, outstanding queue size 33\n",
      "2022-07-28 13:46:36,837 - PROGRESS: pass 6, dispatched chunk #33 = documents up to #3400/18846, outstanding queue size 34\n",
      "2022-07-28 13:46:36,840 - PROGRESS: pass 6, dispatched chunk #34 = documents up to #3500/18846, outstanding queue size 35\n",
      "2022-07-28 13:46:36,841 - PROGRESS: pass 6, dispatched chunk #35 = documents up to #3600/18846, outstanding queue size 36\n",
      "2022-07-28 13:46:36,845 - PROGRESS: pass 6, dispatched chunk #36 = documents up to #3700/18846, outstanding queue size 37\n",
      "2022-07-28 13:46:36,848 - PROGRESS: pass 6, dispatched chunk #37 = documents up to #3800/18846, outstanding queue size 38\n",
      "2022-07-28 13:46:36,852 - PROGRESS: pass 6, dispatched chunk #38 = documents up to #3900/18846, outstanding queue size 39\n",
      "2022-07-28 13:46:36,877 - PROGRESS: pass 6, dispatched chunk #39 = documents up to #4000/18846, outstanding queue size 39\n",
      "2022-07-28 13:46:36,880 - PROGRESS: pass 6, dispatched chunk #40 = documents up to #4100/18846, outstanding queue size 40\n",
      "2022-07-28 13:46:36,884 - PROGRESS: pass 6, dispatched chunk #41 = documents up to #4200/18846, outstanding queue size 41\n",
      "2022-07-28 13:46:36,940 - PROGRESS: pass 6, dispatched chunk #42 = documents up to #4300/18846, outstanding queue size 36\n",
      "2022-07-28 13:46:36,941 - PROGRESS: pass 6, dispatched chunk #43 = documents up to #4400/18846, outstanding queue size 37\n",
      "2022-07-28 13:46:36,941 - PROGRESS: pass 6, dispatched chunk #44 = documents up to #4500/18846, outstanding queue size 38\n",
      "2022-07-28 13:46:36,942 - PROGRESS: pass 6, dispatched chunk #45 = documents up to #4600/18846, outstanding queue size 39\n",
      "2022-07-28 13:46:36,958 - PROGRESS: pass 6, dispatched chunk #46 = documents up to #4700/18846, outstanding queue size 39\n",
      "2022-07-28 13:46:36,970 - PROGRESS: pass 6, dispatched chunk #47 = documents up to #4800/18846, outstanding queue size 40\n",
      "2022-07-28 13:46:37,012 - PROGRESS: pass 6, dispatched chunk #48 = documents up to #4900/18846, outstanding queue size 40\n",
      "2022-07-28 13:46:37,035 - PROGRESS: pass 6, dispatched chunk #49 = documents up to #5000/18846, outstanding queue size 40\n",
      "2022-07-28 13:46:37,037 - PROGRESS: pass 6, dispatched chunk #50 = documents up to #5100/18846, outstanding queue size 41\n",
      "2022-07-28 13:46:37,132 - PROGRESS: pass 6, dispatched chunk #51 = documents up to #5200/18846, outstanding queue size 39\n",
      "2022-07-28 13:46:37,135 - PROGRESS: pass 6, dispatched chunk #52 = documents up to #5300/18846, outstanding queue size 40\n",
      "2022-07-28 13:46:37,136 - PROGRESS: pass 6, dispatched chunk #53 = documents up to #5400/18846, outstanding queue size 41\n",
      "2022-07-28 13:46:37,377 - merging changes from 1500 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:37,518 - topic #6 (0.100): 0.007*\"hz\" + 0.005*\"ww\" + 0.005*\"st\" + 0.004*\"uw\" + 0.004*\"ax\" + 0.004*\"scx\" + 0.004*\"appears\" + 0.004*\"battery\" + 0.003*\"water\" + 0.003*\"art\"\n",
      "2022-07-28 13:46:37,522 - topic #0 (0.100): 0.013*\"drive\" + 0.008*\"scsi\" + 0.008*\"card\" + 0.007*\"mb\" + 0.006*\"disk\" + 0.005*\"hard\" + 0.005*\"bus\" + 0.005*\"bit\" + 0.004*\"people\" + 0.004*\"mhz\"\n",
      "2022-07-28 13:46:37,524 - topic #7 (0.100): 0.017*\"jpeg\" + 0.010*\"gif\" + 0.009*\"car\" + 0.008*\"image\" + 0.008*\"ax\" + 0.006*\"file\" + 0.005*\"color\" + 0.005*\"images\" + 0.005*\"format\" + 0.004*\"quality\"\n",
      "2022-07-28 13:46:37,529 - topic #2 (0.100): 0.006*\"space\" + 0.006*\"time\" + 0.004*\"government\" + 0.004*\"people\" + 0.003*\"key\" + 0.003*\"car\" + 0.003*\"power\" + 0.003*\"encryption\" + 0.002*\"public\" + 0.002*\"chip\"\n",
      "2022-07-28 13:46:37,539 - topic #9 (0.100): 0.012*\"people\" + 0.004*\"israel\" + 0.004*\"president\" + 0.004*\"government\" + 0.004*\"jews\" + 0.004*\"time\" + 0.003*\"war\" + 0.003*\"children\" + 0.003*\"fbi\" + 0.003*\"israeli\"\n",
      "2022-07-28 13:46:37,552 - topic diff=0.040714, rho=0.071527\n",
      "2022-07-28 13:46:37,556 - PROGRESS: pass 6, dispatched chunk #54 = documents up to #5500/18846, outstanding queue size 40\n",
      "2022-07-28 13:46:37,561 - PROGRESS: pass 6, dispatched chunk #55 = documents up to #5600/18846, outstanding queue size 40\n",
      "2022-07-28 13:46:37,564 - PROGRESS: pass 6, dispatched chunk #56 = documents up to #5700/18846, outstanding queue size 40\n",
      "2022-07-28 13:46:37,564 - PROGRESS: pass 6, dispatched chunk #57 = documents up to #5800/18846, outstanding queue size 41\n",
      "2022-07-28 13:46:37,565 - PROGRESS: pass 6, dispatched chunk #58 = documents up to #5900/18846, outstanding queue size 42\n",
      "2022-07-28 13:46:37,565 - PROGRESS: pass 6, dispatched chunk #59 = documents up to #6000/18846, outstanding queue size 43\n",
      "2022-07-28 13:46:37,565 - PROGRESS: pass 6, dispatched chunk #60 = documents up to #6100/18846, outstanding queue size 44\n",
      "2022-07-28 13:46:37,566 - PROGRESS: pass 6, dispatched chunk #61 = documents up to #6200/18846, outstanding queue size 45\n",
      "2022-07-28 13:46:37,566 - PROGRESS: pass 6, dispatched chunk #62 = documents up to #6300/18846, outstanding queue size 46\n",
      "2022-07-28 13:46:37,567 - PROGRESS: pass 6, dispatched chunk #63 = documents up to #6400/18846, outstanding queue size 47\n",
      "2022-07-28 13:46:37,567 - PROGRESS: pass 6, dispatched chunk #64 = documents up to #6500/18846, outstanding queue size 48\n",
      "2022-07-28 13:46:37,567 - PROGRESS: pass 6, dispatched chunk #65 = documents up to #6600/18846, outstanding queue size 49\n",
      "2022-07-28 13:46:37,568 - PROGRESS: pass 6, dispatched chunk #66 = documents up to #6700/18846, outstanding queue size 50\n",
      "2022-07-28 13:46:37,596 - PROGRESS: pass 6, dispatched chunk #67 = documents up to #6800/18846, outstanding queue size 51\n",
      "2022-07-28 13:46:37,600 - PROGRESS: pass 6, dispatched chunk #68 = documents up to #6900/18846, outstanding queue size 51\n",
      "2022-07-28 13:46:37,649 - PROGRESS: pass 6, dispatched chunk #69 = documents up to #7000/18846, outstanding queue size 51\n",
      "2022-07-28 13:46:37,673 - PROGRESS: pass 6, dispatched chunk #70 = documents up to #7100/18846, outstanding queue size 51\n",
      "2022-07-28 13:46:37,773 - PROGRESS: pass 6, dispatched chunk #71 = documents up to #7200/18846, outstanding queue size 50\n",
      "2022-07-28 13:46:37,775 - PROGRESS: pass 6, dispatched chunk #72 = documents up to #7300/18846, outstanding queue size 51\n",
      "2022-07-28 13:46:37,776 - PROGRESS: pass 6, dispatched chunk #73 = documents up to #7400/18846, outstanding queue size 52\n",
      "2022-07-28 13:46:37,777 - PROGRESS: pass 6, dispatched chunk #74 = documents up to #7500/18846, outstanding queue size 53\n",
      "2022-07-28 13:46:37,814 - PROGRESS: pass 6, dispatched chunk #75 = documents up to #7600/18846, outstanding queue size 53\n",
      "2022-07-28 13:46:37,853 - PROGRESS: pass 6, dispatched chunk #76 = documents up to #7700/18846, outstanding queue size 52\n",
      "2022-07-28 13:46:37,894 - PROGRESS: pass 6, dispatched chunk #77 = documents up to #7800/18846, outstanding queue size 52\n",
      "2022-07-28 13:46:37,931 - PROGRESS: pass 6, dispatched chunk #78 = documents up to #7900/18846, outstanding queue size 52\n",
      "2022-07-28 13:46:37,971 - PROGRESS: pass 6, dispatched chunk #79 = documents up to #8000/18846, outstanding queue size 52\n",
      "2022-07-28 13:46:38,010 - PROGRESS: pass 6, dispatched chunk #80 = documents up to #8100/18846, outstanding queue size 53\n",
      "2022-07-28 13:46:38,011 - PROGRESS: pass 6, dispatched chunk #81 = documents up to #8200/18846, outstanding queue size 54\n",
      "2022-07-28 13:46:38,303 - merging changes from 1500 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:38,537 - topic #6 (0.100): 0.007*\"hz\" + 0.006*\"ww\" + 0.005*\"st\" + 0.005*\"uw\" + 0.004*\"appears\" + 0.004*\"dos\" + 0.004*\"ax\" + 0.004*\"art\" + 0.004*\"tl\" + 0.004*\"scx\"\n",
      "2022-07-28 13:46:38,550 - topic #5 (0.100): 0.006*\"armenian\" + 0.004*\"azerbaijan\" + 0.003*\"russian\" + 0.003*\"time\" + 0.003*\"book\" + 0.002*\"source\" + 0.002*\"azeri\" + 0.002*\"armenians\" + 0.002*\"armenia\" + 0.002*\"people\"\n",
      "2022-07-28 13:46:38,554 - topic #3 (0.100): 0.008*\"game\" + 0.008*\"team\" + 0.005*\"play\" + 0.004*\"games\" + 0.004*\"period\" + 0.004*\"time\" + 0.004*\"season\" + 0.004*\"hockey\" + 0.003*\"win\" + 0.003*\"players\"\n",
      "2022-07-28 13:46:38,558 - topic #2 (0.100): 0.006*\"space\" + 0.006*\"time\" + 0.004*\"government\" + 0.004*\"people\" + 0.003*\"key\" + 0.003*\"car\" + 0.003*\"power\" + 0.003*\"encryption\" + 0.002*\"public\" + 0.002*\"chip\"\n",
      "2022-07-28 13:46:38,561 - topic #1 (0.100): 0.008*\"file\" + 0.007*\"windows\" + 0.006*\"program\" + 0.006*\"software\" + 0.006*\"mail\" + 0.005*\"ftp\" + 0.005*\"dos\" + 0.004*\"data\" + 0.004*\"graphics\" + 0.004*\"files\"\n",
      "2022-07-28 13:46:38,565 - topic diff=0.052826, rho=0.071527\n",
      "2022-07-28 13:46:38,569 - PROGRESS: pass 6, dispatched chunk #82 = documents up to #8300/18846, outstanding queue size 53\n",
      "2022-07-28 13:46:38,574 - PROGRESS: pass 6, dispatched chunk #83 = documents up to #8400/18846, outstanding queue size 53\n",
      "2022-07-28 13:46:38,600 - PROGRESS: pass 6, dispatched chunk #84 = documents up to #8500/18846, outstanding queue size 54\n",
      "2022-07-28 13:46:38,604 - PROGRESS: pass 6, dispatched chunk #85 = documents up to #8600/18846, outstanding queue size 55\n",
      "2022-07-28 13:46:38,605 - PROGRESS: pass 6, dispatched chunk #86 = documents up to #8700/18846, outstanding queue size 56\n",
      "2022-07-28 13:46:38,606 - PROGRESS: pass 6, dispatched chunk #87 = documents up to #8800/18846, outstanding queue size 57\n",
      "2022-07-28 13:46:38,607 - PROGRESS: pass 6, dispatched chunk #88 = documents up to #8900/18846, outstanding queue size 58\n",
      "2022-07-28 13:46:38,608 - PROGRESS: pass 6, dispatched chunk #89 = documents up to #9000/18846, outstanding queue size 59\n",
      "2022-07-28 13:46:38,609 - PROGRESS: pass 6, dispatched chunk #90 = documents up to #9100/18846, outstanding queue size 60\n",
      "2022-07-28 13:46:38,609 - PROGRESS: pass 6, dispatched chunk #91 = documents up to #9200/18846, outstanding queue size 61\n",
      "2022-07-28 13:46:38,610 - PROGRESS: pass 6, dispatched chunk #92 = documents up to #9300/18846, outstanding queue size 62\n",
      "2022-07-28 13:46:38,640 - PROGRESS: pass 6, dispatched chunk #93 = documents up to #9400/18846, outstanding queue size 63\n",
      "2022-07-28 13:46:38,653 - PROGRESS: pass 6, dispatched chunk #94 = documents up to #9500/18846, outstanding queue size 64\n",
      "2022-07-28 13:46:38,689 - PROGRESS: pass 6, dispatched chunk #95 = documents up to #9600/18846, outstanding queue size 62\n",
      "2022-07-28 13:46:38,697 - PROGRESS: pass 6, dispatched chunk #96 = documents up to #9700/18846, outstanding queue size 63\n",
      "2022-07-28 13:46:38,704 - PROGRESS: pass 6, dispatched chunk #97 = documents up to #9800/18846, outstanding queue size 64\n",
      "2022-07-28 13:46:38,741 - PROGRESS: pass 6, dispatched chunk #98 = documents up to #9900/18846, outstanding queue size 62\n",
      "2022-07-28 13:46:38,744 - PROGRESS: pass 6, dispatched chunk #99 = documents up to #10000/18846, outstanding queue size 63\n",
      "2022-07-28 13:46:38,772 - PROGRESS: pass 6, dispatched chunk #100 = documents up to #10100/18846, outstanding queue size 64\n",
      "2022-07-28 13:46:38,801 - PROGRESS: pass 6, dispatched chunk #101 = documents up to #10200/18846, outstanding queue size 65\n",
      "2022-07-28 13:46:38,871 - PROGRESS: pass 6, dispatched chunk #102 = documents up to #10300/18846, outstanding queue size 64\n",
      "2022-07-28 13:46:38,873 - PROGRESS: pass 6, dispatched chunk #103 = documents up to #10400/18846, outstanding queue size 65\n",
      "2022-07-28 13:46:38,875 - PROGRESS: pass 6, dispatched chunk #104 = documents up to #10500/18846, outstanding queue size 66\n",
      "2022-07-28 13:46:38,906 - PROGRESS: pass 6, dispatched chunk #105 = documents up to #10600/18846, outstanding queue size 67\n",
      "2022-07-28 13:46:38,934 - PROGRESS: pass 6, dispatched chunk #106 = documents up to #10700/18846, outstanding queue size 65\n",
      "2022-07-28 13:46:38,940 - PROGRESS: pass 6, dispatched chunk #107 = documents up to #10800/18846, outstanding queue size 65\n",
      "2022-07-28 13:46:38,955 - PROGRESS: pass 6, dispatched chunk #108 = documents up to #10900/18846, outstanding queue size 66\n",
      "2022-07-28 13:46:38,956 - PROGRESS: pass 6, dispatched chunk #109 = documents up to #11000/18846, outstanding queue size 67\n",
      "2022-07-28 13:46:39,032 - merging changes from 2000 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:39,125 - topic #1 (0.100): 0.009*\"file\" + 0.007*\"windows\" + 0.006*\"program\" + 0.006*\"software\" + 0.006*\"mail\" + 0.005*\"ftp\" + 0.005*\"dos\" + 0.005*\"graphics\" + 0.004*\"data\" + 0.004*\"files\"\n",
      "2022-07-28 13:46:39,127 - topic #7 (0.100): 0.021*\"jpeg\" + 0.011*\"gif\" + 0.010*\"image\" + 0.008*\"car\" + 0.007*\"file\" + 0.007*\"ax\" + 0.006*\"color\" + 0.006*\"images\" + 0.006*\"format\" + 0.005*\"quality\"\n",
      "2022-07-28 13:46:39,129 - topic #9 (0.100): 0.013*\"people\" + 0.005*\"israel\" + 0.005*\"president\" + 0.004*\"government\" + 0.004*\"time\" + 0.004*\"jews\" + 0.003*\"war\" + 0.003*\"children\" + 0.003*\"fbi\" + 0.003*\"jewish\"\n",
      "2022-07-28 13:46:39,131 - topic #8 (0.100): 0.622*\"ax\" + 0.050*\"max\" + 0.005*\"di\" + 0.004*\"ei\" + 0.003*\"tm\" + 0.003*\"giz\" + 0.003*\"bhj\" + 0.002*\"wm\" + 0.002*\"istanbul\" + 0.002*\"ey\"\n",
      "2022-07-28 13:46:39,132 - topic #2 (0.100): 0.006*\"space\" + 0.006*\"time\" + 0.004*\"people\" + 0.004*\"government\" + 0.003*\"key\" + 0.003*\"car\" + 0.003*\"power\" + 0.003*\"encryption\" + 0.002*\"public\" + 0.002*\"chip\"\n",
      "2022-07-28 13:46:39,134 - topic diff=0.050025, rho=0.071527\n",
      "2022-07-28 13:46:39,135 - PROGRESS: pass 6, dispatched chunk #110 = documents up to #11100/18846, outstanding queue size 61\n",
      "2022-07-28 13:46:39,148 - PROGRESS: pass 6, dispatched chunk #111 = documents up to #11200/18846, outstanding queue size 58\n",
      "2022-07-28 13:46:39,149 - PROGRESS: pass 6, dispatched chunk #112 = documents up to #11300/18846, outstanding queue size 59\n",
      "2022-07-28 13:46:39,150 - PROGRESS: pass 6, dispatched chunk #113 = documents up to #11400/18846, outstanding queue size 60\n",
      "2022-07-28 13:46:39,150 - PROGRESS: pass 6, dispatched chunk #114 = documents up to #11500/18846, outstanding queue size 61\n",
      "2022-07-28 13:46:39,153 - PROGRESS: pass 6, dispatched chunk #115 = documents up to #11600/18846, outstanding queue size 62\n",
      "2022-07-28 13:46:39,156 - PROGRESS: pass 6, dispatched chunk #116 = documents up to #11700/18846, outstanding queue size 63\n",
      "2022-07-28 13:46:39,161 - PROGRESS: pass 6, dispatched chunk #117 = documents up to #11800/18846, outstanding queue size 64\n",
      "2022-07-28 13:46:39,166 - PROGRESS: pass 6, dispatched chunk #118 = documents up to #11900/18846, outstanding queue size 65\n",
      "2022-07-28 13:46:39,171 - PROGRESS: pass 6, dispatched chunk #119 = documents up to #12000/18846, outstanding queue size 66\n",
      "2022-07-28 13:46:39,185 - PROGRESS: pass 6, dispatched chunk #120 = documents up to #12100/18846, outstanding queue size 65\n",
      "2022-07-28 13:46:39,186 - PROGRESS: pass 6, dispatched chunk #121 = documents up to #12200/18846, outstanding queue size 66\n",
      "2022-07-28 13:46:39,192 - PROGRESS: pass 6, dispatched chunk #122 = documents up to #12300/18846, outstanding queue size 66\n",
      "2022-07-28 13:46:39,193 - PROGRESS: pass 6, dispatched chunk #123 = documents up to #12400/18846, outstanding queue size 67\n",
      "2022-07-28 13:46:39,208 - PROGRESS: pass 6, dispatched chunk #124 = documents up to #12500/18846, outstanding queue size 67\n",
      "2022-07-28 13:46:39,282 - PROGRESS: pass 6, dispatched chunk #125 = documents up to #12600/18846, outstanding queue size 67\n",
      "2022-07-28 13:46:39,286 - PROGRESS: pass 6, dispatched chunk #126 = documents up to #12700/18846, outstanding queue size 68\n",
      "2022-07-28 13:46:39,322 - PROGRESS: pass 6, dispatched chunk #127 = documents up to #12800/18846, outstanding queue size 69\n",
      "2022-07-28 13:46:39,345 - PROGRESS: pass 6, dispatched chunk #128 = documents up to #12900/18846, outstanding queue size 66\n",
      "2022-07-28 13:46:39,533 - merging changes from 1600 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:39,674 - topic #8 (0.100): 0.613*\"ax\" + 0.050*\"max\" + 0.005*\"di\" + 0.004*\"ei\" + 0.003*\"tm\" + 0.003*\"giz\" + 0.003*\"bhj\" + 0.002*\"wm\" + 0.002*\"printf\" + 0.002*\"istanbul\"\n",
      "2022-07-28 13:46:39,682 - topic #9 (0.100): 0.013*\"people\" + 0.005*\"israel\" + 0.004*\"president\" + 0.004*\"government\" + 0.004*\"time\" + 0.004*\"jews\" + 0.003*\"war\" + 0.003*\"children\" + 0.003*\"fbi\" + 0.003*\"jewish\"\n",
      "2022-07-28 13:46:39,688 - topic #1 (0.100): 0.009*\"file\" + 0.007*\"windows\" + 0.006*\"program\" + 0.006*\"software\" + 0.005*\"mail\" + 0.005*\"ftp\" + 0.004*\"dos\" + 0.004*\"graphics\" + 0.004*\"data\" + 0.004*\"files\"\n",
      "2022-07-28 13:46:39,692 - topic #0 (0.100): 0.014*\"drive\" + 0.009*\"scsi\" + 0.008*\"card\" + 0.008*\"mb\" + 0.006*\"disk\" + 0.005*\"hard\" + 0.005*\"mhz\" + 0.005*\"bit\" + 0.005*\"bus\" + 0.004*\"people\"\n",
      "2022-07-28 13:46:39,697 - topic #5 (0.100): 0.006*\"armenian\" + 0.004*\"azerbaijan\" + 0.003*\"russian\" + 0.003*\"time\" + 0.003*\"book\" + 0.003*\"source\" + 0.002*\"xfree\" + 0.002*\"azeri\" + 0.002*\"armenians\" + 0.002*\"armenia\"\n",
      "2022-07-28 13:46:39,702 - topic diff=0.040062, rho=0.071527\n",
      "2022-07-28 13:46:39,706 - PROGRESS: pass 6, dispatched chunk #129 = documents up to #13000/18846, outstanding queue size 64\n",
      "2022-07-28 13:46:39,749 - PROGRESS: pass 6, dispatched chunk #130 = documents up to #13100/18846, outstanding queue size 60\n",
      "2022-07-28 13:46:39,754 - PROGRESS: pass 6, dispatched chunk #131 = documents up to #13200/18846, outstanding queue size 61\n",
      "2022-07-28 13:46:39,755 - PROGRESS: pass 6, dispatched chunk #132 = documents up to #13300/18846, outstanding queue size 62\n",
      "2022-07-28 13:46:39,757 - PROGRESS: pass 6, dispatched chunk #133 = documents up to #13400/18846, outstanding queue size 63\n",
      "2022-07-28 13:46:39,759 - PROGRESS: pass 6, dispatched chunk #134 = documents up to #13500/18846, outstanding queue size 64\n",
      "2022-07-28 13:46:39,760 - PROGRESS: pass 6, dispatched chunk #135 = documents up to #13600/18846, outstanding queue size 65\n",
      "2022-07-28 13:46:39,762 - PROGRESS: pass 6, dispatched chunk #136 = documents up to #13700/18846, outstanding queue size 66\n",
      "2022-07-28 13:46:39,764 - PROGRESS: pass 6, dispatched chunk #137 = documents up to #13800/18846, outstanding queue size 67\n",
      "2022-07-28 13:46:39,786 - PROGRESS: pass 6, dispatched chunk #138 = documents up to #13900/18846, outstanding queue size 60\n",
      "2022-07-28 13:46:39,788 - PROGRESS: pass 6, dispatched chunk #139 = documents up to #14000/18846, outstanding queue size 61\n",
      "2022-07-28 13:46:39,790 - PROGRESS: pass 6, dispatched chunk #140 = documents up to #14100/18846, outstanding queue size 62\n",
      "2022-07-28 13:46:39,792 - PROGRESS: pass 6, dispatched chunk #141 = documents up to #14200/18846, outstanding queue size 63\n",
      "2022-07-28 13:46:39,793 - PROGRESS: pass 6, dispatched chunk #142 = documents up to #14300/18846, outstanding queue size 64\n",
      "2022-07-28 13:46:39,795 - PROGRESS: pass 6, dispatched chunk #143 = documents up to #14400/18846, outstanding queue size 65\n",
      "2022-07-28 13:46:39,835 - PROGRESS: pass 6, dispatched chunk #144 = documents up to #14500/18846, outstanding queue size 66\n",
      "2022-07-28 13:46:39,949 - merging changes from 1700 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:40,041 - topic #0 (0.100): 0.014*\"drive\" + 0.009*\"scsi\" + 0.008*\"card\" + 0.008*\"mb\" + 0.006*\"disk\" + 0.005*\"hard\" + 0.005*\"bit\" + 0.005*\"mhz\" + 0.005*\"bus\" + 0.004*\"people\"\n",
      "2022-07-28 13:46:40,043 - topic #5 (0.100): 0.006*\"armenian\" + 0.004*\"azerbaijan\" + 0.003*\"russian\" + 0.003*\"book\" + 0.003*\"time\" + 0.003*\"source\" + 0.002*\"xfree\" + 0.002*\"armenians\" + 0.002*\"azeri\" + 0.002*\"armenia\"\n",
      "2022-07-28 13:46:40,047 - topic #6 (0.100): 0.008*\"hz\" + 0.007*\"ww\" + 0.006*\"uw\" + 0.005*\"scx\" + 0.005*\"st\" + 0.004*\"zd\" + 0.004*\"cj\" + 0.004*\"tl\" + 0.003*\"appears\" + 0.003*\"chz\"\n",
      "2022-07-28 13:46:40,051 - topic #4 (0.100): 0.013*\"god\" + 0.009*\"people\" + 0.006*\"jesus\" + 0.004*\"time\" + 0.003*\"gun\" + 0.003*\"christ\" + 0.003*\"law\" + 0.003*\"life\" + 0.003*\"bible\" + 0.003*\"christian\"\n",
      "2022-07-28 13:46:40,052 - topic #2 (0.100): 0.006*\"space\" + 0.006*\"time\" + 0.004*\"government\" + 0.004*\"people\" + 0.004*\"key\" + 0.003*\"car\" + 0.003*\"power\" + 0.003*\"encryption\" + 0.002*\"chip\" + 0.002*\"clipper\"\n",
      "2022-07-28 13:46:40,054 - topic diff=0.047792, rho=0.071527\n",
      "2022-07-28 13:46:40,057 - PROGRESS: pass 6, dispatched chunk #145 = documents up to #14600/18846, outstanding queue size 63\n",
      "2022-07-28 13:46:40,066 - PROGRESS: pass 6, dispatched chunk #146 = documents up to #14700/18846, outstanding queue size 62\n",
      "2022-07-28 13:46:40,067 - PROGRESS: pass 6, dispatched chunk #147 = documents up to #14800/18846, outstanding queue size 63\n",
      "2022-07-28 13:46:40,070 - PROGRESS: pass 6, dispatched chunk #148 = documents up to #14900/18846, outstanding queue size 64\n",
      "2022-07-28 13:46:40,071 - PROGRESS: pass 6, dispatched chunk #149 = documents up to #15000/18846, outstanding queue size 65\n",
      "2022-07-28 13:46:40,072 - PROGRESS: pass 6, dispatched chunk #150 = documents up to #15100/18846, outstanding queue size 66\n",
      "2022-07-28 13:46:40,072 - PROGRESS: pass 6, dispatched chunk #151 = documents up to #15200/18846, outstanding queue size 67\n",
      "2022-07-28 13:46:40,072 - PROGRESS: pass 6, dispatched chunk #152 = documents up to #15300/18846, outstanding queue size 68\n",
      "2022-07-28 13:46:40,073 - PROGRESS: pass 6, dispatched chunk #153 = documents up to #15400/18846, outstanding queue size 69\n",
      "2022-07-28 13:46:40,073 - PROGRESS: pass 6, dispatched chunk #154 = documents up to #15500/18846, outstanding queue size 70\n",
      "2022-07-28 13:46:40,076 - PROGRESS: pass 6, dispatched chunk #155 = documents up to #15600/18846, outstanding queue size 71\n",
      "2022-07-28 13:46:40,076 - PROGRESS: pass 6, dispatched chunk #156 = documents up to #15700/18846, outstanding queue size 72\n",
      "2022-07-28 13:46:40,078 - PROGRESS: pass 6, dispatched chunk #157 = documents up to #15800/18846, outstanding queue size 73\n",
      "2022-07-28 13:46:40,087 - PROGRESS: pass 6, dispatched chunk #158 = documents up to #15900/18846, outstanding queue size 74\n",
      "2022-07-28 13:46:40,100 - PROGRESS: pass 6, dispatched chunk #159 = documents up to #16000/18846, outstanding queue size 75\n",
      "2022-07-28 13:46:40,113 - PROGRESS: pass 6, dispatched chunk #160 = documents up to #16100/18846, outstanding queue size 75\n",
      "2022-07-28 13:46:40,118 - PROGRESS: pass 6, dispatched chunk #161 = documents up to #16200/18846, outstanding queue size 76\n",
      "2022-07-28 13:46:40,119 - PROGRESS: pass 6, dispatched chunk #162 = documents up to #16300/18846, outstanding queue size 77\n",
      "2022-07-28 13:46:40,146 - PROGRESS: pass 6, dispatched chunk #163 = documents up to #16400/18846, outstanding queue size 77\n",
      "2022-07-28 13:46:40,155 - PROGRESS: pass 6, dispatched chunk #164 = documents up to #16500/18846, outstanding queue size 78\n",
      "2022-07-28 13:46:40,187 - PROGRESS: pass 6, dispatched chunk #165 = documents up to #16600/18846, outstanding queue size 79\n",
      "2022-07-28 13:46:40,224 - PROGRESS: pass 6, dispatched chunk #166 = documents up to #16700/18846, outstanding queue size 80\n",
      "2022-07-28 13:46:40,226 - PROGRESS: pass 6, dispatched chunk #167 = documents up to #16800/18846, outstanding queue size 81\n",
      "2022-07-28 13:46:40,251 - PROGRESS: pass 6, dispatched chunk #168 = documents up to #16900/18846, outstanding queue size 81\n",
      "2022-07-28 13:46:40,252 - PROGRESS: pass 6, dispatched chunk #169 = documents up to #17000/18846, outstanding queue size 82\n",
      "2022-07-28 13:46:40,283 - PROGRESS: pass 6, dispatched chunk #170 = documents up to #17100/18846, outstanding queue size 79\n",
      "2022-07-28 13:46:40,296 - PROGRESS: pass 6, dispatched chunk #171 = documents up to #17200/18846, outstanding queue size 80\n",
      "2022-07-28 13:46:40,316 - PROGRESS: pass 6, dispatched chunk #172 = documents up to #17300/18846, outstanding queue size 81\n",
      "2022-07-28 13:46:40,350 - PROGRESS: pass 6, dispatched chunk #173 = documents up to #17400/18846, outstanding queue size 81\n",
      "2022-07-28 13:46:40,351 - PROGRESS: pass 6, dispatched chunk #174 = documents up to #17500/18846, outstanding queue size 82\n",
      "2022-07-28 13:46:40,352 - PROGRESS: pass 6, dispatched chunk #175 = documents up to #17600/18846, outstanding queue size 83\n",
      "2022-07-28 13:46:40,383 - PROGRESS: pass 6, dispatched chunk #176 = documents up to #17700/18846, outstanding queue size 84\n",
      "2022-07-28 13:46:40,412 - PROGRESS: pass 6, dispatched chunk #177 = documents up to #17800/18846, outstanding queue size 83\n",
      "2022-07-28 13:46:40,457 - PROGRESS: pass 6, dispatched chunk #178 = documents up to #17900/18846, outstanding queue size 83\n",
      "2022-07-28 13:46:40,497 - PROGRESS: pass 6, dispatched chunk #179 = documents up to #18000/18846, outstanding queue size 84\n",
      "2022-07-28 13:46:40,531 - PROGRESS: pass 6, dispatched chunk #180 = documents up to #18100/18846, outstanding queue size 85\n",
      "2022-07-28 13:46:40,620 - PROGRESS: pass 6, dispatched chunk #181 = documents up to #18200/18846, outstanding queue size 85\n",
      "2022-07-28 13:46:40,625 - PROGRESS: pass 6, dispatched chunk #182 = documents up to #18300/18846, outstanding queue size 86\n",
      "2022-07-28 13:46:40,627 - PROGRESS: pass 6, dispatched chunk #183 = documents up to #18400/18846, outstanding queue size 87\n",
      "2022-07-28 13:46:40,628 - PROGRESS: pass 6, dispatched chunk #184 = documents up to #18500/18846, outstanding queue size 88\n",
      "2022-07-28 13:46:40,630 - PROGRESS: pass 6, dispatched chunk #185 = documents up to #18600/18846, outstanding queue size 89\n",
      "2022-07-28 13:46:40,717 - merging changes from 1500 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:40,998 - topic #7 (0.100): 0.019*\"jpeg\" + 0.011*\"gif\" + 0.010*\"image\" + 0.009*\"car\" + 0.007*\"file\" + 0.006*\"images\" + 0.006*\"color\" + 0.006*\"ax\" + 0.005*\"format\" + 0.004*\"quality\"\n",
      "2022-07-28 13:46:41,014 - topic #0 (0.100): 0.014*\"drive\" + 0.009*\"scsi\" + 0.008*\"card\" + 0.008*\"mb\" + 0.006*\"disk\" + 0.005*\"hard\" + 0.005*\"mhz\" + 0.005*\"bit\" + 0.005*\"bus\" + 0.004*\"drives\"\n",
      "2022-07-28 13:46:41,018 - topic #8 (0.100): 0.687*\"ax\" + 0.054*\"max\" + 0.004*\"ei\" + 0.004*\"di\" + 0.003*\"giz\" + 0.002*\"tm\" + 0.002*\"bhj\" + 0.002*\"qq\" + 0.002*\"ey\" + 0.002*\"wm\"\n",
      "2022-07-28 13:46:41,022 - topic #4 (0.100): 0.013*\"god\" + 0.009*\"people\" + 0.006*\"jesus\" + 0.005*\"time\" + 0.003*\"gun\" + 0.003*\"christ\" + 0.003*\"life\" + 0.003*\"law\" + 0.003*\"bible\" + 0.003*\"christian\"\n",
      "2022-07-28 13:46:41,023 - topic #5 (0.100): 0.007*\"armenian\" + 0.004*\"azerbaijan\" + 0.003*\"russian\" + 0.003*\"book\" + 0.003*\"source\" + 0.003*\"time\" + 0.002*\"armenians\" + 0.002*\"armenia\" + 0.002*\"azeri\" + 0.002*\"xfree\"\n",
      "2022-07-28 13:46:41,025 - topic diff=0.051334, rho=0.071527\n",
      "2022-07-28 13:46:41,025 - PROGRESS: pass 6, dispatched chunk #186 = documents up to #18700/18846, outstanding queue size 89\n",
      "2022-07-28 13:46:41,028 - PROGRESS: pass 6, dispatched chunk #187 = documents up to #18800/18846, outstanding queue size 89\n",
      "2022-07-28 13:46:41,033 - PROGRESS: pass 6, dispatched chunk #188 = documents up to #18846/18846, outstanding queue size 90\n",
      "2022-07-28 13:46:41,613 - merging changes from 1700 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:41,755 - topic #2 (0.100): 0.006*\"space\" + 0.006*\"time\" + 0.004*\"government\" + 0.004*\"people\" + 0.004*\"key\" + 0.003*\"car\" + 0.003*\"power\" + 0.003*\"encryption\" + 0.002*\"public\" + 0.002*\"chip\"\n",
      "2022-07-28 13:46:41,758 - topic #8 (0.100): 0.679*\"ax\" + 0.053*\"max\" + 0.004*\"di\" + 0.004*\"ei\" + 0.003*\"tm\" + 0.003*\"giz\" + 0.002*\"bhj\" + 0.002*\"wm\" + 0.002*\"ey\" + 0.002*\"qq\"\n",
      "2022-07-28 13:46:41,760 - topic #6 (0.100): 0.008*\"hz\" + 0.006*\"ww\" + 0.005*\"uw\" + 0.005*\"st\" + 0.005*\"scx\" + 0.004*\"zd\" + 0.004*\"cj\" + 0.003*\"tl\" + 0.003*\"water\" + 0.003*\"appears\"\n",
      "2022-07-28 13:46:41,761 - topic #4 (0.100): 0.013*\"god\" + 0.009*\"people\" + 0.005*\"jesus\" + 0.005*\"time\" + 0.004*\"db\" + 0.004*\"gun\" + 0.003*\"life\" + 0.003*\"christ\" + 0.003*\"law\" + 0.003*\"bible\"\n",
      "2022-07-28 13:46:41,762 - topic #9 (0.100): 0.013*\"people\" + 0.004*\"israel\" + 0.004*\"president\" + 0.004*\"government\" + 0.004*\"jews\" + 0.004*\"time\" + 0.003*\"war\" + 0.003*\"children\" + 0.003*\"fbi\" + 0.003*\"rights\"\n",
      "2022-07-28 13:46:41,764 - topic diff=0.037338, rho=0.071527\n",
      "2022-07-28 13:46:41,868 - -10.452 per-word bound, 1401.0 perplexity estimate based on a held-out corpus of 46 documents with 2932 words\n",
      "2022-07-28 13:46:42,072 - merging changes from 7346 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:42,102 - topic #7 (0.100): 0.019*\"jpeg\" + 0.011*\"gif\" + 0.010*\"image\" + 0.009*\"car\" + 0.007*\"file\" + 0.006*\"images\" + 0.006*\"color\" + 0.005*\"ax\" + 0.005*\"format\" + 0.005*\"bit\"\n",
      "2022-07-28 13:46:42,104 - topic #6 (0.100): 0.008*\"hz\" + 0.006*\"ww\" + 0.005*\"uw\" + 0.005*\"st\" + 0.004*\"scx\" + 0.004*\"zd\" + 0.003*\"cj\" + 0.003*\"appears\" + 0.003*\"water\" + 0.003*\"tl\"\n",
      "2022-07-28 13:46:42,105 - topic #9 (0.100): 0.013*\"people\" + 0.004*\"israel\" + 0.004*\"president\" + 0.004*\"government\" + 0.004*\"jews\" + 0.004*\"time\" + 0.003*\"war\" + 0.003*\"children\" + 0.003*\"fbi\" + 0.003*\"rights\"\n",
      "2022-07-28 13:46:42,107 - topic #4 (0.100): 0.013*\"god\" + 0.009*\"people\" + 0.005*\"jesus\" + 0.005*\"time\" + 0.004*\"db\" + 0.004*\"gun\" + 0.003*\"life\" + 0.003*\"christ\" + 0.003*\"law\" + 0.003*\"bible\"\n",
      "2022-07-28 13:46:42,108 - topic #0 (0.100): 0.014*\"drive\" + 0.009*\"scsi\" + 0.008*\"card\" + 0.008*\"mb\" + 0.006*\"disk\" + 0.006*\"hard\" + 0.005*\"bit\" + 0.005*\"mhz\" + 0.005*\"bus\" + 0.004*\"drives\"\n",
      "2022-07-28 13:46:42,109 - topic diff=0.030729, rho=0.071527\n",
      "2022-07-28 13:46:42,181 - -10.429 per-word bound, 1378.3 perplexity estimate based on a held-out corpus of 46 documents with 2932 words\n",
      "2022-07-28 13:46:42,181 - PROGRESS: pass 7, dispatched chunk #0 = documents up to #100/18846, outstanding queue size 1\n",
      "2022-07-28 13:46:42,184 - PROGRESS: pass 7, dispatched chunk #1 = documents up to #200/18846, outstanding queue size 2\n",
      "2022-07-28 13:46:42,184 - PROGRESS: pass 7, dispatched chunk #2 = documents up to #300/18846, outstanding queue size 3\n",
      "2022-07-28 13:46:42,185 - PROGRESS: pass 7, dispatched chunk #3 = documents up to #400/18846, outstanding queue size 4\n",
      "2022-07-28 13:46:42,185 - PROGRESS: pass 7, dispatched chunk #4 = documents up to #500/18846, outstanding queue size 5\n",
      "2022-07-28 13:46:42,186 - PROGRESS: pass 7, dispatched chunk #5 = documents up to #600/18846, outstanding queue size 6\n",
      "2022-07-28 13:46:42,188 - PROGRESS: pass 7, dispatched chunk #6 = documents up to #700/18846, outstanding queue size 7\n",
      "2022-07-28 13:46:42,188 - PROGRESS: pass 7, dispatched chunk #7 = documents up to #800/18846, outstanding queue size 8\n",
      "2022-07-28 13:46:42,188 - PROGRESS: pass 7, dispatched chunk #8 = documents up to #900/18846, outstanding queue size 9\n",
      "2022-07-28 13:46:42,189 - PROGRESS: pass 7, dispatched chunk #9 = documents up to #1000/18846, outstanding queue size 10\n",
      "2022-07-28 13:46:42,189 - PROGRESS: pass 7, dispatched chunk #10 = documents up to #1100/18846, outstanding queue size 11\n",
      "2022-07-28 13:46:42,189 - PROGRESS: pass 7, dispatched chunk #11 = documents up to #1200/18846, outstanding queue size 12\n",
      "2022-07-28 13:46:42,191 - PROGRESS: pass 7, dispatched chunk #12 = documents up to #1300/18846, outstanding queue size 13\n",
      "2022-07-28 13:46:42,192 - PROGRESS: pass 7, dispatched chunk #13 = documents up to #1400/18846, outstanding queue size 14\n",
      "2022-07-28 13:46:42,192 - PROGRESS: pass 7, dispatched chunk #14 = documents up to #1500/18846, outstanding queue size 15\n",
      "2022-07-28 13:46:42,193 - PROGRESS: pass 7, dispatched chunk #15 = documents up to #1600/18846, outstanding queue size 16\n",
      "2022-07-28 13:46:42,193 - PROGRESS: pass 7, dispatched chunk #16 = documents up to #1700/18846, outstanding queue size 17\n",
      "2022-07-28 13:46:42,193 - PROGRESS: pass 7, dispatched chunk #17 = documents up to #1800/18846, outstanding queue size 18\n",
      "2022-07-28 13:46:42,194 - PROGRESS: pass 7, dispatched chunk #18 = documents up to #1900/18846, outstanding queue size 19\n",
      "2022-07-28 13:46:42,194 - PROGRESS: pass 7, dispatched chunk #19 = documents up to #2000/18846, outstanding queue size 20\n",
      "2022-07-28 13:46:42,196 - PROGRESS: pass 7, dispatched chunk #20 = documents up to #2100/18846, outstanding queue size 21\n",
      "2022-07-28 13:46:42,197 - PROGRESS: pass 7, dispatched chunk #21 = documents up to #2200/18846, outstanding queue size 22\n",
      "2022-07-28 13:46:42,197 - PROGRESS: pass 7, dispatched chunk #22 = documents up to #2300/18846, outstanding queue size 23\n",
      "2022-07-28 13:46:42,198 - PROGRESS: pass 7, dispatched chunk #23 = documents up to #2400/18846, outstanding queue size 24\n",
      "2022-07-28 13:46:42,198 - PROGRESS: pass 7, dispatched chunk #24 = documents up to #2500/18846, outstanding queue size 25\n",
      "2022-07-28 13:46:42,198 - PROGRESS: pass 7, dispatched chunk #25 = documents up to #2600/18846, outstanding queue size 26\n",
      "2022-07-28 13:46:42,199 - PROGRESS: pass 7, dispatched chunk #26 = documents up to #2700/18846, outstanding queue size 27\n",
      "2022-07-28 13:46:42,201 - PROGRESS: pass 7, dispatched chunk #27 = documents up to #2800/18846, outstanding queue size 28\n",
      "2022-07-28 13:46:42,202 - PROGRESS: pass 7, dispatched chunk #28 = documents up to #2900/18846, outstanding queue size 29\n",
      "2022-07-28 13:46:42,202 - PROGRESS: pass 7, dispatched chunk #29 = documents up to #3000/18846, outstanding queue size 30\n",
      "2022-07-28 13:46:42,203 - PROGRESS: pass 7, dispatched chunk #30 = documents up to #3100/18846, outstanding queue size 31\n",
      "2022-07-28 13:46:42,203 - PROGRESS: pass 7, dispatched chunk #31 = documents up to #3200/18846, outstanding queue size 32\n",
      "2022-07-28 13:46:42,205 - PROGRESS: pass 7, dispatched chunk #32 = documents up to #3300/18846, outstanding queue size 33\n",
      "2022-07-28 13:46:42,205 - PROGRESS: pass 7, dispatched chunk #33 = documents up to #3400/18846, outstanding queue size 34\n",
      "2022-07-28 13:46:42,206 - PROGRESS: pass 7, dispatched chunk #34 = documents up to #3500/18846, outstanding queue size 35\n",
      "2022-07-28 13:46:42,207 - PROGRESS: pass 7, dispatched chunk #35 = documents up to #3600/18846, outstanding queue size 36\n",
      "2022-07-28 13:46:42,216 - PROGRESS: pass 7, dispatched chunk #36 = documents up to #3700/18846, outstanding queue size 37\n",
      "2022-07-28 13:46:42,218 - PROGRESS: pass 7, dispatched chunk #37 = documents up to #3800/18846, outstanding queue size 38\n",
      "2022-07-28 13:46:42,224 - PROGRESS: pass 7, dispatched chunk #38 = documents up to #3900/18846, outstanding queue size 39\n",
      "2022-07-28 13:46:42,227 - PROGRESS: pass 7, dispatched chunk #39 = documents up to #4000/18846, outstanding queue size 40\n",
      "2022-07-28 13:46:42,262 - PROGRESS: pass 7, dispatched chunk #40 = documents up to #4100/18846, outstanding queue size 40\n",
      "2022-07-28 13:46:42,310 - PROGRESS: pass 7, dispatched chunk #41 = documents up to #4200/18846, outstanding queue size 33\n",
      "2022-07-28 13:46:42,311 - PROGRESS: pass 7, dispatched chunk #42 = documents up to #4300/18846, outstanding queue size 34\n",
      "2022-07-28 13:46:42,312 - PROGRESS: pass 7, dispatched chunk #43 = documents up to #4400/18846, outstanding queue size 35\n",
      "2022-07-28 13:46:42,347 - PROGRESS: pass 7, dispatched chunk #44 = documents up to #4500/18846, outstanding queue size 34\n",
      "2022-07-28 13:46:42,371 - PROGRESS: pass 7, dispatched chunk #45 = documents up to #4600/18846, outstanding queue size 35\n",
      "2022-07-28 13:46:42,372 - PROGRESS: pass 7, dispatched chunk #46 = documents up to #4700/18846, outstanding queue size 36\n",
      "2022-07-28 13:46:42,409 - PROGRESS: pass 7, dispatched chunk #47 = documents up to #4800/18846, outstanding queue size 37\n",
      "2022-07-28 13:46:42,453 - PROGRESS: pass 7, dispatched chunk #48 = documents up to #4900/18846, outstanding queue size 36\n",
      "2022-07-28 13:46:42,454 - PROGRESS: pass 7, dispatched chunk #49 = documents up to #5000/18846, outstanding queue size 37\n",
      "2022-07-28 13:46:42,455 - PROGRESS: pass 7, dispatched chunk #50 = documents up to #5100/18846, outstanding queue size 38\n",
      "2022-07-28 13:46:42,455 - PROGRESS: pass 7, dispatched chunk #51 = documents up to #5200/18846, outstanding queue size 39\n",
      "2022-07-28 13:46:42,456 - PROGRESS: pass 7, dispatched chunk #52 = documents up to #5300/18846, outstanding queue size 40\n",
      "2022-07-28 13:46:42,492 - PROGRESS: pass 7, dispatched chunk #53 = documents up to #5400/18846, outstanding queue size 41\n",
      "2022-07-28 13:46:42,496 - PROGRESS: pass 7, dispatched chunk #54 = documents up to #5500/18846, outstanding queue size 42\n",
      "2022-07-28 13:46:42,694 - merging changes from 1600 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:42,793 - topic #1 (0.100): 0.009*\"file\" + 0.007*\"windows\" + 0.006*\"program\" + 0.006*\"mail\" + 0.006*\"software\" + 0.005*\"ftp\" + 0.005*\"dos\" + 0.004*\"graphics\" + 0.004*\"data\" + 0.004*\"files\"\n",
      "2022-07-28 13:46:42,824 - topic #2 (0.100): 0.006*\"space\" + 0.006*\"time\" + 0.004*\"government\" + 0.004*\"people\" + 0.004*\"key\" + 0.003*\"car\" + 0.003*\"power\" + 0.003*\"encryption\" + 0.002*\"public\" + 0.002*\"chip\"\n",
      "2022-07-28 13:46:42,829 - topic #4 (0.100): 0.013*\"god\" + 0.009*\"people\" + 0.006*\"jesus\" + 0.005*\"time\" + 0.004*\"db\" + 0.003*\"gun\" + 0.003*\"law\" + 0.003*\"life\" + 0.003*\"christ\" + 0.003*\"bible\"\n",
      "2022-07-28 13:46:42,857 - topic #3 (0.100): 0.009*\"game\" + 0.008*\"team\" + 0.005*\"play\" + 0.005*\"games\" + 0.004*\"period\" + 0.004*\"time\" + 0.004*\"season\" + 0.004*\"hockey\" + 0.004*\"win\" + 0.003*\"players\"\n",
      "2022-07-28 13:46:42,861 - topic #9 (0.100): 0.013*\"people\" + 0.004*\"president\" + 0.004*\"israel\" + 0.004*\"government\" + 0.004*\"jews\" + 0.004*\"time\" + 0.003*\"war\" + 0.003*\"children\" + 0.003*\"fbi\" + 0.003*\"jewish\"\n",
      "2022-07-28 13:46:42,867 - topic diff=0.039453, rho=0.071345\n",
      "2022-07-28 13:46:42,874 - PROGRESS: pass 7, dispatched chunk #55 = documents up to #5600/18846, outstanding queue size 40\n",
      "2022-07-28 13:46:42,879 - PROGRESS: pass 7, dispatched chunk #56 = documents up to #5700/18846, outstanding queue size 40\n",
      "2022-07-28 13:46:42,892 - PROGRESS: pass 7, dispatched chunk #57 = documents up to #5800/18846, outstanding queue size 40\n",
      "2022-07-28 13:46:42,894 - PROGRESS: pass 7, dispatched chunk #58 = documents up to #5900/18846, outstanding queue size 41\n",
      "2022-07-28 13:46:42,896 - PROGRESS: pass 7, dispatched chunk #59 = documents up to #6000/18846, outstanding queue size 42\n",
      "2022-07-28 13:46:42,897 - PROGRESS: pass 7, dispatched chunk #60 = documents up to #6100/18846, outstanding queue size 43\n",
      "2022-07-28 13:46:42,899 - PROGRESS: pass 7, dispatched chunk #61 = documents up to #6200/18846, outstanding queue size 44\n",
      "2022-07-28 13:46:42,900 - PROGRESS: pass 7, dispatched chunk #62 = documents up to #6300/18846, outstanding queue size 45\n",
      "2022-07-28 13:46:42,902 - PROGRESS: pass 7, dispatched chunk #63 = documents up to #6400/18846, outstanding queue size 46\n",
      "2022-07-28 13:46:42,903 - PROGRESS: pass 7, dispatched chunk #64 = documents up to #6500/18846, outstanding queue size 47\n",
      "2022-07-28 13:46:42,905 - PROGRESS: pass 7, dispatched chunk #65 = documents up to #6600/18846, outstanding queue size 48\n",
      "2022-07-28 13:46:42,908 - PROGRESS: pass 7, dispatched chunk #66 = documents up to #6700/18846, outstanding queue size 49\n",
      "2022-07-28 13:46:42,929 - PROGRESS: pass 7, dispatched chunk #67 = documents up to #6800/18846, outstanding queue size 48\n",
      "2022-07-28 13:46:42,994 - PROGRESS: pass 7, dispatched chunk #68 = documents up to #6900/18846, outstanding queue size 48\n",
      "2022-07-28 13:46:43,041 - PROGRESS: pass 7, dispatched chunk #69 = documents up to #7000/18846, outstanding queue size 48\n",
      "2022-07-28 13:46:43,043 - PROGRESS: pass 7, dispatched chunk #70 = documents up to #7100/18846, outstanding queue size 49\n",
      "2022-07-28 13:46:43,045 - PROGRESS: pass 7, dispatched chunk #71 = documents up to #7200/18846, outstanding queue size 50\n",
      "2022-07-28 13:46:43,104 - PROGRESS: pass 7, dispatched chunk #72 = documents up to #7300/18846, outstanding queue size 50\n",
      "2022-07-28 13:46:43,107 - PROGRESS: pass 7, dispatched chunk #73 = documents up to #7400/18846, outstanding queue size 51\n",
      "2022-07-28 13:46:43,148 - PROGRESS: pass 7, dispatched chunk #74 = documents up to #7500/18846, outstanding queue size 52\n",
      "2022-07-28 13:46:43,151 - PROGRESS: pass 7, dispatched chunk #75 = documents up to #7600/18846, outstanding queue size 53\n",
      "2022-07-28 13:46:43,179 - PROGRESS: pass 7, dispatched chunk #76 = documents up to #7700/18846, outstanding queue size 54\n",
      "2022-07-28 13:46:43,221 - PROGRESS: pass 7, dispatched chunk #77 = documents up to #7800/18846, outstanding queue size 53\n",
      "2022-07-28 13:46:43,227 - PROGRESS: pass 7, dispatched chunk #78 = documents up to #7900/18846, outstanding queue size 53\n",
      "2022-07-28 13:46:43,282 - PROGRESS: pass 7, dispatched chunk #79 = documents up to #8000/18846, outstanding queue size 53\n",
      "2022-07-28 13:46:43,289 - PROGRESS: pass 7, dispatched chunk #80 = documents up to #8100/18846, outstanding queue size 53\n",
      "2022-07-28 13:46:43,372 - PROGRESS: pass 7, dispatched chunk #81 = documents up to #8200/18846, outstanding queue size 54\n",
      "2022-07-28 13:46:43,397 - PROGRESS: pass 7, dispatched chunk #82 = documents up to #8300/18846, outstanding queue size 54\n",
      "2022-07-28 13:46:43,602 - merging changes from 1600 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:43,804 - topic #8 (0.100): 0.651*\"ax\" + 0.052*\"max\" + 0.004*\"di\" + 0.004*\"ei\" + 0.003*\"tm\" + 0.003*\"giz\" + 0.002*\"bhj\" + 0.002*\"wm\" + 0.002*\"istanbul\" + 0.002*\"ey\"\n",
      "2022-07-28 13:46:43,829 - topic #5 (0.100): 0.007*\"armenian\" + 0.005*\"azerbaijan\" + 0.003*\"russian\" + 0.003*\"book\" + 0.003*\"source\" + 0.003*\"time\" + 0.002*\"armenia\" + 0.002*\"armenians\" + 0.002*\"azeri\" + 0.002*\"karabakh\"\n",
      "2022-07-28 13:46:43,832 - topic #6 (0.100): 0.008*\"hz\" + 0.006*\"ww\" + 0.005*\"uw\" + 0.005*\"st\" + 0.004*\"tl\" + 0.004*\"appears\" + 0.004*\"scx\" + 0.004*\"zd\" + 0.003*\"art\" + 0.003*\"cj\"\n",
      "2022-07-28 13:46:43,836 - topic #3 (0.100): 0.010*\"game\" + 0.008*\"team\" + 0.005*\"play\" + 0.005*\"games\" + 0.004*\"period\" + 0.004*\"time\" + 0.004*\"hockey\" + 0.004*\"season\" + 0.004*\"win\" + 0.003*\"players\"\n",
      "2022-07-28 13:46:43,840 - topic #1 (0.100): 0.009*\"file\" + 0.007*\"windows\" + 0.006*\"program\" + 0.006*\"mail\" + 0.005*\"software\" + 0.005*\"ftp\" + 0.005*\"graphics\" + 0.004*\"dos\" + 0.004*\"data\" + 0.004*\"files\"\n",
      "2022-07-28 13:46:43,843 - topic diff=0.052256, rho=0.071345\n",
      "2022-07-28 13:46:43,847 - PROGRESS: pass 7, dispatched chunk #83 = documents up to #8400/18846, outstanding queue size 52\n",
      "2022-07-28 13:46:43,851 - PROGRESS: pass 7, dispatched chunk #84 = documents up to #8500/18846, outstanding queue size 52\n",
      "2022-07-28 13:46:43,857 - PROGRESS: pass 7, dispatched chunk #85 = documents up to #8600/18846, outstanding queue size 53\n",
      "2022-07-28 13:46:43,858 - PROGRESS: pass 7, dispatched chunk #86 = documents up to #8700/18846, outstanding queue size 54\n",
      "2022-07-28 13:46:43,862 - PROGRESS: pass 7, dispatched chunk #87 = documents up to #8800/18846, outstanding queue size 55\n",
      "2022-07-28 13:46:43,862 - PROGRESS: pass 7, dispatched chunk #88 = documents up to #8900/18846, outstanding queue size 56\n",
      "2022-07-28 13:46:43,863 - PROGRESS: pass 7, dispatched chunk #89 = documents up to #9000/18846, outstanding queue size 57\n",
      "2022-07-28 13:46:43,863 - PROGRESS: pass 7, dispatched chunk #90 = documents up to #9100/18846, outstanding queue size 58\n",
      "2022-07-28 13:46:43,863 - PROGRESS: pass 7, dispatched chunk #91 = documents up to #9200/18846, outstanding queue size 59\n",
      "2022-07-28 13:46:43,864 - PROGRESS: pass 7, dispatched chunk #92 = documents up to #9300/18846, outstanding queue size 60\n",
      "2022-07-28 13:46:43,864 - PROGRESS: pass 7, dispatched chunk #93 = documents up to #9400/18846, outstanding queue size 61\n",
      "2022-07-28 13:46:43,865 - PROGRESS: pass 7, dispatched chunk #94 = documents up to #9500/18846, outstanding queue size 62\n",
      "2022-07-28 13:46:43,865 - PROGRESS: pass 7, dispatched chunk #95 = documents up to #9600/18846, outstanding queue size 63\n",
      "2022-07-28 13:46:43,866 - PROGRESS: pass 7, dispatched chunk #96 = documents up to #9700/18846, outstanding queue size 64\n",
      "2022-07-28 13:46:43,866 - PROGRESS: pass 7, dispatched chunk #97 = documents up to #9800/18846, outstanding queue size 65\n",
      "2022-07-28 13:46:43,869 - PROGRESS: pass 7, dispatched chunk #98 = documents up to #9900/18846, outstanding queue size 66\n",
      "2022-07-28 13:46:43,920 - PROGRESS: pass 7, dispatched chunk #99 = documents up to #10000/18846, outstanding queue size 67\n",
      "2022-07-28 13:46:43,983 - PROGRESS: pass 7, dispatched chunk #100 = documents up to #10100/18846, outstanding queue size 68\n",
      "2022-07-28 13:46:43,984 - PROGRESS: pass 7, dispatched chunk #101 = documents up to #10200/18846, outstanding queue size 69\n",
      "2022-07-28 13:46:43,984 - PROGRESS: pass 7, dispatched chunk #102 = documents up to #10300/18846, outstanding queue size 70\n",
      "2022-07-28 13:46:44,012 - PROGRESS: pass 7, dispatched chunk #103 = documents up to #10400/18846, outstanding queue size 70\n",
      "2022-07-28 13:46:44,054 - PROGRESS: pass 7, dispatched chunk #104 = documents up to #10500/18846, outstanding queue size 65\n",
      "2022-07-28 13:46:44,055 - PROGRESS: pass 7, dispatched chunk #105 = documents up to #10600/18846, outstanding queue size 66\n",
      "2022-07-28 13:46:44,057 - PROGRESS: pass 7, dispatched chunk #106 = documents up to #10700/18846, outstanding queue size 67\n",
      "2022-07-28 13:46:44,093 - PROGRESS: pass 7, dispatched chunk #107 = documents up to #10800/18846, outstanding queue size 64\n",
      "2022-07-28 13:46:44,105 - PROGRESS: pass 7, dispatched chunk #108 = documents up to #10900/18846, outstanding queue size 64\n",
      "2022-07-28 13:46:44,106 - PROGRESS: pass 7, dispatched chunk #109 = documents up to #11000/18846, outstanding queue size 65\n",
      "2022-07-28 13:46:44,183 - merging changes from 1500 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:44,253 - topic #8 (0.100): 0.664*\"ax\" + 0.053*\"max\" + 0.004*\"di\" + 0.004*\"ei\" + 0.003*\"tm\" + 0.003*\"giz\" + 0.002*\"bhj\" + 0.002*\"wm\" + 0.002*\"ey\" + 0.002*\"istanbul\"\n",
      "2022-07-28 13:46:44,257 - topic #0 (0.100): 0.014*\"drive\" + 0.009*\"scsi\" + 0.009*\"card\" + 0.008*\"mb\" + 0.006*\"disk\" + 0.006*\"hard\" + 0.005*\"mhz\" + 0.005*\"bit\" + 0.005*\"bus\" + 0.004*\"drives\"\n",
      "2022-07-28 13:46:44,259 - topic #9 (0.100): 0.013*\"people\" + 0.005*\"israel\" + 0.004*\"president\" + 0.004*\"government\" + 0.004*\"time\" + 0.004*\"jews\" + 0.003*\"war\" + 0.003*\"children\" + 0.003*\"fbi\" + 0.003*\"jewish\"\n",
      "2022-07-28 13:46:44,260 - topic #7 (0.100): 0.022*\"jpeg\" + 0.012*\"gif\" + 0.011*\"image\" + 0.008*\"car\" + 0.008*\"file\" + 0.007*\"images\" + 0.007*\"color\" + 0.006*\"format\" + 0.005*\"quality\" + 0.005*\"bit\"\n",
      "2022-07-28 13:46:44,261 - topic #6 (0.100): 0.008*\"hz\" + 0.006*\"ww\" + 0.006*\"scx\" + 0.005*\"st\" + 0.005*\"uw\" + 0.004*\"zd\" + 0.004*\"tl\" + 0.004*\"cj\" + 0.003*\"appears\" + 0.003*\"md\"\n",
      "2022-07-28 13:46:44,263 - topic diff=0.045586, rho=0.071345\n",
      "2022-07-28 13:46:44,264 - PROGRESS: pass 7, dispatched chunk #110 = documents up to #11100/18846, outstanding queue size 64\n",
      "2022-07-28 13:46:44,275 - PROGRESS: pass 7, dispatched chunk #111 = documents up to #11200/18846, outstanding queue size 62\n",
      "2022-07-28 13:46:44,276 - PROGRESS: pass 7, dispatched chunk #112 = documents up to #11300/18846, outstanding queue size 63\n",
      "2022-07-28 13:46:44,276 - PROGRESS: pass 7, dispatched chunk #113 = documents up to #11400/18846, outstanding queue size 64\n",
      "2022-07-28 13:46:44,277 - PROGRESS: pass 7, dispatched chunk #114 = documents up to #11500/18846, outstanding queue size 65\n",
      "2022-07-28 13:46:44,277 - PROGRESS: pass 7, dispatched chunk #115 = documents up to #11600/18846, outstanding queue size 66\n",
      "2022-07-28 13:46:44,278 - PROGRESS: pass 7, dispatched chunk #116 = documents up to #11700/18846, outstanding queue size 67\n",
      "2022-07-28 13:46:44,278 - PROGRESS: pass 7, dispatched chunk #117 = documents up to #11800/18846, outstanding queue size 68\n",
      "2022-07-28 13:46:44,279 - PROGRESS: pass 7, dispatched chunk #118 = documents up to #11900/18846, outstanding queue size 69\n",
      "2022-07-28 13:46:44,279 - PROGRESS: pass 7, dispatched chunk #119 = documents up to #12000/18846, outstanding queue size 70\n",
      "2022-07-28 13:46:44,308 - PROGRESS: pass 7, dispatched chunk #120 = documents up to #12100/18846, outstanding queue size 68\n",
      "2022-07-28 13:46:44,313 - PROGRESS: pass 7, dispatched chunk #121 = documents up to #12200/18846, outstanding queue size 68\n",
      "2022-07-28 13:46:44,333 - PROGRESS: pass 7, dispatched chunk #122 = documents up to #12300/18846, outstanding queue size 67\n",
      "2022-07-28 13:46:44,371 - PROGRESS: pass 7, dispatched chunk #123 = documents up to #12400/18846, outstanding queue size 68\n",
      "2022-07-28 13:46:44,432 - PROGRESS: pass 7, dispatched chunk #124 = documents up to #12500/18846, outstanding queue size 68\n",
      "2022-07-28 13:46:44,481 - PROGRESS: pass 7, dispatched chunk #125 = documents up to #12600/18846, outstanding queue size 67\n",
      "2022-07-28 13:46:44,486 - PROGRESS: pass 7, dispatched chunk #126 = documents up to #12700/18846, outstanding queue size 68\n",
      "2022-07-28 13:46:44,492 - PROGRESS: pass 7, dispatched chunk #127 = documents up to #12800/18846, outstanding queue size 68\n",
      "2022-07-28 13:46:44,576 - merging changes from 1500 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:44,662 - topic #5 (0.100): 0.007*\"armenian\" + 0.005*\"azerbaijan\" + 0.003*\"russian\" + 0.003*\"source\" + 0.003*\"book\" + 0.003*\"xfree\" + 0.002*\"armenians\" + 0.002*\"time\" + 0.002*\"armenia\" + 0.002*\"azeri\"\n",
      "2022-07-28 13:46:44,664 - topic #6 (0.100): 0.008*\"hz\" + 0.006*\"ww\" + 0.006*\"scx\" + 0.005*\"st\" + 0.005*\"uw\" + 0.004*\"zd\" + 0.004*\"tl\" + 0.004*\"cj\" + 0.003*\"appears\" + 0.003*\"md\"\n",
      "2022-07-28 13:46:44,665 - topic #7 (0.100): 0.021*\"jpeg\" + 0.012*\"gif\" + 0.011*\"image\" + 0.009*\"car\" + 0.007*\"file\" + 0.007*\"images\" + 0.006*\"color\" + 0.006*\"format\" + 0.005*\"bit\" + 0.005*\"quality\"\n",
      "2022-07-28 13:46:44,667 - topic #9 (0.100): 0.013*\"people\" + 0.005*\"president\" + 0.005*\"israel\" + 0.004*\"government\" + 0.004*\"time\" + 0.004*\"jews\" + 0.003*\"war\" + 0.003*\"children\" + 0.003*\"rights\" + 0.003*\"fbi\"\n",
      "2022-07-28 13:46:44,668 - topic #8 (0.100): 0.669*\"ax\" + 0.053*\"max\" + 0.005*\"di\" + 0.004*\"ei\" + 0.003*\"tm\" + 0.003*\"giz\" + 0.003*\"bhj\" + 0.002*\"wm\" + 0.002*\"ey\" + 0.002*\"qq\"\n",
      "2022-07-28 13:46:44,670 - topic diff=0.033578, rho=0.071345\n",
      "2022-07-28 13:46:44,670 - PROGRESS: pass 7, dispatched chunk #128 = documents up to #12900/18846, outstanding queue size 67\n",
      "2022-07-28 13:46:44,673 - PROGRESS: pass 7, dispatched chunk #129 = documents up to #13000/18846, outstanding queue size 67\n",
      "2022-07-28 13:46:44,673 - PROGRESS: pass 7, dispatched chunk #130 = documents up to #13100/18846, outstanding queue size 68\n",
      "2022-07-28 13:46:44,674 - PROGRESS: pass 7, dispatched chunk #131 = documents up to #13200/18846, outstanding queue size 69\n",
      "2022-07-28 13:46:44,674 - PROGRESS: pass 7, dispatched chunk #132 = documents up to #13300/18846, outstanding queue size 70\n",
      "2022-07-28 13:46:44,675 - PROGRESS: pass 7, dispatched chunk #133 = documents up to #13400/18846, outstanding queue size 71\n",
      "2022-07-28 13:46:44,675 - PROGRESS: pass 7, dispatched chunk #134 = documents up to #13500/18846, outstanding queue size 72\n",
      "2022-07-28 13:46:44,676 - PROGRESS: pass 7, dispatched chunk #135 = documents up to #13600/18846, outstanding queue size 73\n",
      "2022-07-28 13:46:44,709 - PROGRESS: pass 7, dispatched chunk #136 = documents up to #13700/18846, outstanding queue size 72\n",
      "2022-07-28 13:46:44,712 - PROGRESS: pass 7, dispatched chunk #137 = documents up to #13800/18846, outstanding queue size 73\n",
      "2022-07-28 13:46:44,746 - PROGRESS: pass 7, dispatched chunk #138 = documents up to #13900/18846, outstanding queue size 73\n",
      "2022-07-28 13:46:44,803 - PROGRESS: pass 7, dispatched chunk #139 = documents up to #14000/18846, outstanding queue size 70\n",
      "2022-07-28 13:46:44,809 - PROGRESS: pass 7, dispatched chunk #140 = documents up to #14100/18846, outstanding queue size 71\n",
      "2022-07-28 13:46:44,810 - PROGRESS: pass 7, dispatched chunk #141 = documents up to #14200/18846, outstanding queue size 72\n",
      "2022-07-28 13:46:44,890 - PROGRESS: pass 7, dispatched chunk #142 = documents up to #14300/18846, outstanding queue size 72\n",
      "2022-07-28 13:46:44,907 - PROGRESS: pass 7, dispatched chunk #143 = documents up to #14400/18846, outstanding queue size 73\n",
      "2022-07-28 13:46:44,913 - PROGRESS: pass 7, dispatched chunk #144 = documents up to #14500/18846, outstanding queue size 72\n",
      "2022-07-28 13:46:44,952 - PROGRESS: pass 7, dispatched chunk #145 = documents up to #14600/18846, outstanding queue size 70\n",
      "2022-07-28 13:46:44,957 - PROGRESS: pass 7, dispatched chunk #146 = documents up to #14700/18846, outstanding queue size 71\n",
      "2022-07-28 13:46:44,987 - PROGRESS: pass 7, dispatched chunk #147 = documents up to #14800/18846, outstanding queue size 72\n",
      "2022-07-28 13:46:45,015 - PROGRESS: pass 7, dispatched chunk #148 = documents up to #14900/18846, outstanding queue size 73\n",
      "2022-07-28 13:46:45,025 - PROGRESS: pass 7, dispatched chunk #149 = documents up to #15000/18846, outstanding queue size 74\n",
      "2022-07-28 13:46:45,058 - PROGRESS: pass 7, dispatched chunk #150 = documents up to #15100/18846, outstanding queue size 75\n",
      "2022-07-28 13:46:45,059 - PROGRESS: pass 7, dispatched chunk #151 = documents up to #15200/18846, outstanding queue size 76\n",
      "2022-07-28 13:46:45,150 - merging changes from 1500 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:45,270 - topic #5 (0.100): 0.007*\"armenian\" + 0.005*\"azerbaijan\" + 0.003*\"russian\" + 0.003*\"source\" + 0.003*\"book\" + 0.003*\"armenians\" + 0.002*\"xfree\" + 0.002*\"armenia\" + 0.002*\"time\" + 0.002*\"azeri\"\n",
      "2022-07-28 13:46:45,272 - topic #9 (0.100): 0.013*\"people\" + 0.005*\"israel\" + 0.005*\"president\" + 0.004*\"government\" + 0.004*\"time\" + 0.004*\"jews\" + 0.003*\"war\" + 0.003*\"children\" + 0.003*\"rights\" + 0.003*\"fbi\"\n",
      "2022-07-28 13:46:45,274 - topic #4 (0.100): 0.013*\"god\" + 0.009*\"people\" + 0.006*\"jesus\" + 0.005*\"time\" + 0.004*\"gun\" + 0.003*\"christ\" + 0.003*\"life\" + 0.003*\"law\" + 0.003*\"bible\" + 0.003*\"christian\"\n",
      "2022-07-28 13:46:45,276 - topic #2 (0.100): 0.006*\"space\" + 0.006*\"time\" + 0.004*\"government\" + 0.004*\"people\" + 0.004*\"key\" + 0.003*\"car\" + 0.003*\"encryption\" + 0.003*\"power\" + 0.003*\"chip\" + 0.002*\"public\"\n",
      "2022-07-28 13:46:45,277 - topic #7 (0.100): 0.021*\"jpeg\" + 0.011*\"gif\" + 0.011*\"image\" + 0.009*\"car\" + 0.007*\"file\" + 0.006*\"color\" + 0.006*\"images\" + 0.006*\"format\" + 0.005*\"bit\" + 0.005*\"quality\"\n",
      "2022-07-28 13:46:45,278 - topic diff=0.038644, rho=0.071345\n",
      "2022-07-28 13:46:45,279 - PROGRESS: pass 7, dispatched chunk #152 = documents up to #15300/18846, outstanding queue size 76\n",
      "2022-07-28 13:46:45,282 - PROGRESS: pass 7, dispatched chunk #153 = documents up to #15400/18846, outstanding queue size 76\n",
      "2022-07-28 13:46:45,282 - PROGRESS: pass 7, dispatched chunk #154 = documents up to #15500/18846, outstanding queue size 77\n",
      "2022-07-28 13:46:45,285 - PROGRESS: pass 7, dispatched chunk #155 = documents up to #15600/18846, outstanding queue size 78\n",
      "2022-07-28 13:46:45,285 - PROGRESS: pass 7, dispatched chunk #156 = documents up to #15700/18846, outstanding queue size 79\n",
      "2022-07-28 13:46:45,286 - PROGRESS: pass 7, dispatched chunk #157 = documents up to #15800/18846, outstanding queue size 80\n",
      "2022-07-28 13:46:45,286 - PROGRESS: pass 7, dispatched chunk #158 = documents up to #15900/18846, outstanding queue size 81\n",
      "2022-07-28 13:46:45,287 - PROGRESS: pass 7, dispatched chunk #159 = documents up to #16000/18846, outstanding queue size 82\n",
      "2022-07-28 13:46:45,287 - PROGRESS: pass 7, dispatched chunk #160 = documents up to #16100/18846, outstanding queue size 83\n",
      "2022-07-28 13:46:45,288 - PROGRESS: pass 7, dispatched chunk #161 = documents up to #16200/18846, outstanding queue size 84\n",
      "2022-07-28 13:46:45,336 - PROGRESS: pass 7, dispatched chunk #162 = documents up to #16300/18846, outstanding queue size 73\n",
      "2022-07-28 13:46:45,337 - PROGRESS: pass 7, dispatched chunk #163 = documents up to #16400/18846, outstanding queue size 74\n",
      "2022-07-28 13:46:45,355 - PROGRESS: pass 7, dispatched chunk #164 = documents up to #16500/18846, outstanding queue size 74\n",
      "2022-07-28 13:46:45,449 - merging changes from 1600 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:45,547 - topic #3 (0.100): 0.010*\"game\" + 0.008*\"team\" + 0.006*\"play\" + 0.005*\"games\" + 0.004*\"season\" + 0.004*\"period\" + 0.004*\"time\" + 0.004*\"win\" + 0.004*\"hockey\" + 0.003*\"players\"\n",
      "2022-07-28 13:46:45,558 - topic #7 (0.100): 0.020*\"jpeg\" + 0.011*\"gif\" + 0.011*\"image\" + 0.009*\"car\" + 0.007*\"file\" + 0.007*\"images\" + 0.006*\"color\" + 0.006*\"format\" + 0.005*\"bit\" + 0.005*\"quality\"\n",
      "2022-07-28 13:46:45,560 - topic #6 (0.100): 0.008*\"hz\" + 0.007*\"ww\" + 0.006*\"uw\" + 0.006*\"scx\" + 0.005*\"st\" + 0.004*\"zd\" + 0.004*\"cj\" + 0.004*\"tl\" + 0.004*\"chz\" + 0.004*\"md\"\n",
      "2022-07-28 13:46:45,562 - topic #5 (0.100): 0.007*\"armenian\" + 0.005*\"azerbaijan\" + 0.003*\"russian\" + 0.003*\"source\" + 0.003*\"armenians\" + 0.003*\"book\" + 0.002*\"armenia\" + 0.002*\"time\" + 0.002*\"xfree\" + 0.002*\"azeri\"\n",
      "2022-07-28 13:46:45,564 - topic #9 (0.100): 0.013*\"people\" + 0.004*\"government\" + 0.004*\"president\" + 0.004*\"israel\" + 0.004*\"jews\" + 0.004*\"time\" + 0.003*\"war\" + 0.003*\"children\" + 0.003*\"turkish\" + 0.003*\"rights\"\n",
      "2022-07-28 13:46:45,567 - topic diff=0.044385, rho=0.071345\n",
      "2022-07-28 13:46:45,568 - PROGRESS: pass 7, dispatched chunk #165 = documents up to #16600/18846, outstanding queue size 73\n",
      "2022-07-28 13:46:45,601 - PROGRESS: pass 7, dispatched chunk #166 = documents up to #16700/18846, outstanding queue size 70\n",
      "2022-07-28 13:46:45,601 - PROGRESS: pass 7, dispatched chunk #167 = documents up to #16800/18846, outstanding queue size 71\n",
      "2022-07-28 13:46:45,602 - PROGRESS: pass 7, dispatched chunk #168 = documents up to #16900/18846, outstanding queue size 72\n",
      "2022-07-28 13:46:45,603 - PROGRESS: pass 7, dispatched chunk #169 = documents up to #17000/18846, outstanding queue size 73\n",
      "2022-07-28 13:46:45,603 - PROGRESS: pass 7, dispatched chunk #170 = documents up to #17100/18846, outstanding queue size 74\n",
      "2022-07-28 13:46:45,604 - PROGRESS: pass 7, dispatched chunk #171 = documents up to #17200/18846, outstanding queue size 75\n",
      "2022-07-28 13:46:45,604 - PROGRESS: pass 7, dispatched chunk #172 = documents up to #17300/18846, outstanding queue size 76\n",
      "2022-07-28 13:46:45,605 - PROGRESS: pass 7, dispatched chunk #173 = documents up to #17400/18846, outstanding queue size 77\n",
      "2022-07-28 13:46:45,612 - PROGRESS: pass 7, dispatched chunk #174 = documents up to #17500/18846, outstanding queue size 78\n",
      "2022-07-28 13:46:45,705 - PROGRESS: pass 7, dispatched chunk #175 = documents up to #17600/18846, outstanding queue size 70\n",
      "2022-07-28 13:46:45,706 - PROGRESS: pass 7, dispatched chunk #176 = documents up to #17700/18846, outstanding queue size 71\n",
      "2022-07-28 13:46:45,707 - PROGRESS: pass 7, dispatched chunk #177 = documents up to #17800/18846, outstanding queue size 72\n",
      "2022-07-28 13:46:45,804 - merging changes from 1500 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:45,877 - topic #2 (0.100): 0.006*\"space\" + 0.006*\"time\" + 0.004*\"government\" + 0.004*\"people\" + 0.004*\"key\" + 0.003*\"car\" + 0.003*\"power\" + 0.003*\"encryption\" + 0.002*\"chip\" + 0.002*\"public\"\n",
      "2022-07-28 13:46:45,879 - topic #9 (0.100): 0.013*\"people\" + 0.005*\"government\" + 0.004*\"president\" + 0.004*\"israel\" + 0.004*\"jews\" + 0.004*\"time\" + 0.003*\"war\" + 0.003*\"children\" + 0.003*\"turkish\" + 0.003*\"rights\"\n",
      "2022-07-28 13:46:45,881 - topic #6 (0.100): 0.008*\"hz\" + 0.007*\"ww\" + 0.006*\"uw\" + 0.005*\"st\" + 0.005*\"scx\" + 0.004*\"appears\" + 0.004*\"zd\" + 0.004*\"cj\" + 0.004*\"art\" + 0.004*\"tl\"\n",
      "2022-07-28 13:46:45,884 - topic #5 (0.100): 0.008*\"armenian\" + 0.005*\"azerbaijan\" + 0.003*\"russian\" + 0.003*\"book\" + 0.003*\"source\" + 0.003*\"armenians\" + 0.003*\"armenia\" + 0.002*\"time\" + 0.002*\"azeri\" + 0.002*\"xfree\"\n",
      "2022-07-28 13:46:45,886 - topic #4 (0.100): 0.013*\"god\" + 0.009*\"people\" + 0.006*\"jesus\" + 0.005*\"time\" + 0.004*\"db\" + 0.004*\"gun\" + 0.003*\"life\" + 0.003*\"christ\" + 0.003*\"bible\" + 0.003*\"law\"\n",
      "2022-07-28 13:46:45,887 - topic diff=0.033267, rho=0.071345\n",
      "2022-07-28 13:46:45,888 - PROGRESS: pass 7, dispatched chunk #178 = documents up to #17900/18846, outstanding queue size 71\n",
      "2022-07-28 13:46:45,907 - PROGRESS: pass 7, dispatched chunk #179 = documents up to #18000/18846, outstanding queue size 69\n",
      "2022-07-28 13:46:45,910 - PROGRESS: pass 7, dispatched chunk #180 = documents up to #18100/18846, outstanding queue size 70\n",
      "2022-07-28 13:46:45,910 - PROGRESS: pass 7, dispatched chunk #181 = documents up to #18200/18846, outstanding queue size 71\n",
      "2022-07-28 13:46:45,911 - PROGRESS: pass 7, dispatched chunk #182 = documents up to #18300/18846, outstanding queue size 72\n",
      "2022-07-28 13:46:45,911 - PROGRESS: pass 7, dispatched chunk #183 = documents up to #18400/18846, outstanding queue size 73\n",
      "2022-07-28 13:46:45,912 - PROGRESS: pass 7, dispatched chunk #184 = documents up to #18500/18846, outstanding queue size 74\n",
      "2022-07-28 13:46:45,912 - PROGRESS: pass 7, dispatched chunk #185 = documents up to #18600/18846, outstanding queue size 75\n",
      "2022-07-28 13:46:45,913 - PROGRESS: pass 7, dispatched chunk #186 = documents up to #18700/18846, outstanding queue size 76\n",
      "2022-07-28 13:46:45,932 - PROGRESS: pass 7, dispatched chunk #187 = documents up to #18800/18846, outstanding queue size 77\n",
      "2022-07-28 13:46:45,988 - PROGRESS: pass 7, dispatched chunk #188 = documents up to #18846/18846, outstanding queue size 74\n",
      "2022-07-28 13:46:46,306 - merging changes from 2200 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:46,469 - topic #0 (0.100): 0.015*\"drive\" + 0.009*\"scsi\" + 0.009*\"card\" + 0.008*\"mb\" + 0.007*\"disk\" + 0.006*\"hard\" + 0.006*\"bit\" + 0.005*\"mhz\" + 0.005*\"bus\" + 0.005*\"drives\"\n",
      "2022-07-28 13:46:46,478 - topic #7 (0.100): 0.021*\"jpeg\" + 0.012*\"gif\" + 0.011*\"image\" + 0.009*\"car\" + 0.007*\"file\" + 0.007*\"images\" + 0.007*\"color\" + 0.006*\"format\" + 0.005*\"bit\" + 0.005*\"quality\"\n",
      "2022-07-28 13:46:46,484 - topic #1 (0.100): 0.010*\"file\" + 0.007*\"windows\" + 0.006*\"program\" + 0.006*\"mail\" + 0.006*\"software\" + 0.005*\"ftp\" + 0.005*\"graphics\" + 0.005*\"files\" + 0.004*\"data\" + 0.004*\"dos\"\n",
      "2022-07-28 13:46:46,486 - topic #6 (0.100): 0.008*\"hz\" + 0.006*\"ww\" + 0.006*\"uw\" + 0.005*\"st\" + 0.005*\"scx\" + 0.004*\"zd\" + 0.004*\"appears\" + 0.004*\"cj\" + 0.003*\"art\" + 0.003*\"tl\"\n",
      "2022-07-28 13:46:46,490 - topic #2 (0.100): 0.006*\"space\" + 0.006*\"time\" + 0.004*\"government\" + 0.004*\"people\" + 0.004*\"key\" + 0.003*\"car\" + 0.003*\"power\" + 0.003*\"encryption\" + 0.002*\"chip\" + 0.002*\"public\"\n",
      "2022-07-28 13:46:46,495 - topic diff=0.031744, rho=0.071345\n",
      "2022-07-28 13:46:46,805 - -10.437 per-word bound, 1386.2 perplexity estimate based on a held-out corpus of 46 documents with 2932 words\n",
      "2022-07-28 13:46:46,981 - merging changes from 5846 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:47,012 - topic #2 (0.100): 0.006*\"space\" + 0.006*\"time\" + 0.004*\"government\" + 0.004*\"key\" + 0.004*\"people\" + 0.003*\"car\" + 0.003*\"power\" + 0.003*\"encryption\" + 0.002*\"chip\" + 0.002*\"public\"\n",
      "2022-07-28 13:46:47,013 - topic #7 (0.100): 0.020*\"jpeg\" + 0.012*\"gif\" + 0.011*\"image\" + 0.009*\"car\" + 0.007*\"file\" + 0.007*\"images\" + 0.007*\"color\" + 0.006*\"format\" + 0.005*\"bit\" + 0.005*\"quality\"\n",
      "2022-07-28 13:46:47,014 - topic #0 (0.100): 0.015*\"drive\" + 0.009*\"scsi\" + 0.009*\"card\" + 0.008*\"mb\" + 0.007*\"disk\" + 0.006*\"hard\" + 0.006*\"bit\" + 0.005*\"mhz\" + 0.005*\"bus\" + 0.005*\"drives\"\n",
      "2022-07-28 13:46:47,016 - topic #3 (0.100): 0.011*\"game\" + 0.008*\"team\" + 0.006*\"play\" + 0.006*\"games\" + 0.005*\"season\" + 0.004*\"period\" + 0.004*\"time\" + 0.004*\"hockey\" + 0.004*\"win\" + 0.004*\"players\"\n",
      "2022-07-28 13:46:47,017 - topic #8 (0.100): 0.686*\"ax\" + 0.054*\"max\" + 0.004*\"di\" + 0.004*\"ei\" + 0.003*\"giz\" + 0.003*\"tm\" + 0.003*\"bhj\" + 0.002*\"wm\" + 0.002*\"ey\" + 0.002*\"qq\"\n",
      "2022-07-28 13:46:47,019 - topic diff=0.029941, rho=0.071345\n",
      "2022-07-28 13:46:47,090 - -10.411 per-word bound, 1361.5 perplexity estimate based on a held-out corpus of 46 documents with 2932 words\n",
      "2022-07-28 13:46:47,091 - PROGRESS: pass 8, dispatched chunk #0 = documents up to #100/18846, outstanding queue size 1\n",
      "2022-07-28 13:46:47,093 - PROGRESS: pass 8, dispatched chunk #1 = documents up to #200/18846, outstanding queue size 2\n",
      "2022-07-28 13:46:47,094 - PROGRESS: pass 8, dispatched chunk #2 = documents up to #300/18846, outstanding queue size 3\n",
      "2022-07-28 13:46:47,094 - PROGRESS: pass 8, dispatched chunk #3 = documents up to #400/18846, outstanding queue size 4\n",
      "2022-07-28 13:46:47,094 - PROGRESS: pass 8, dispatched chunk #4 = documents up to #500/18846, outstanding queue size 5\n",
      "2022-07-28 13:46:47,095 - PROGRESS: pass 8, dispatched chunk #5 = documents up to #600/18846, outstanding queue size 6\n",
      "2022-07-28 13:46:47,095 - PROGRESS: pass 8, dispatched chunk #6 = documents up to #700/18846, outstanding queue size 7\n",
      "2022-07-28 13:46:47,096 - PROGRESS: pass 8, dispatched chunk #7 = documents up to #800/18846, outstanding queue size 8\n",
      "2022-07-28 13:46:47,098 - PROGRESS: pass 8, dispatched chunk #8 = documents up to #900/18846, outstanding queue size 9\n",
      "2022-07-28 13:46:47,099 - PROGRESS: pass 8, dispatched chunk #9 = documents up to #1000/18846, outstanding queue size 10\n",
      "2022-07-28 13:46:47,099 - PROGRESS: pass 8, dispatched chunk #10 = documents up to #1100/18846, outstanding queue size 11\n",
      "2022-07-28 13:46:47,100 - PROGRESS: pass 8, dispatched chunk #11 = documents up to #1200/18846, outstanding queue size 12\n",
      "2022-07-28 13:46:47,102 - PROGRESS: pass 8, dispatched chunk #12 = documents up to #1300/18846, outstanding queue size 13\n",
      "2022-07-28 13:46:47,103 - PROGRESS: pass 8, dispatched chunk #13 = documents up to #1400/18846, outstanding queue size 14\n",
      "2022-07-28 13:46:47,103 - PROGRESS: pass 8, dispatched chunk #14 = documents up to #1500/18846, outstanding queue size 15\n",
      "2022-07-28 13:46:47,103 - PROGRESS: pass 8, dispatched chunk #15 = documents up to #1600/18846, outstanding queue size 16\n",
      "2022-07-28 13:46:47,104 - PROGRESS: pass 8, dispatched chunk #16 = documents up to #1700/18846, outstanding queue size 17\n",
      "2022-07-28 13:46:47,106 - PROGRESS: pass 8, dispatched chunk #17 = documents up to #1800/18846, outstanding queue size 18\n",
      "2022-07-28 13:46:47,107 - PROGRESS: pass 8, dispatched chunk #18 = documents up to #1900/18846, outstanding queue size 19\n",
      "2022-07-28 13:46:47,108 - PROGRESS: pass 8, dispatched chunk #19 = documents up to #2000/18846, outstanding queue size 20\n",
      "2022-07-28 13:46:47,108 - PROGRESS: pass 8, dispatched chunk #20 = documents up to #2100/18846, outstanding queue size 21\n",
      "2022-07-28 13:46:47,111 - PROGRESS: pass 8, dispatched chunk #21 = documents up to #2200/18846, outstanding queue size 22\n",
      "2022-07-28 13:46:47,111 - PROGRESS: pass 8, dispatched chunk #22 = documents up to #2300/18846, outstanding queue size 23\n",
      "2022-07-28 13:46:47,112 - PROGRESS: pass 8, dispatched chunk #23 = documents up to #2400/18846, outstanding queue size 24\n",
      "2022-07-28 13:46:47,112 - PROGRESS: pass 8, dispatched chunk #24 = documents up to #2500/18846, outstanding queue size 25\n",
      "2022-07-28 13:46:47,113 - PROGRESS: pass 8, dispatched chunk #25 = documents up to #2600/18846, outstanding queue size 26\n",
      "2022-07-28 13:46:47,113 - PROGRESS: pass 8, dispatched chunk #26 = documents up to #2700/18846, outstanding queue size 27\n",
      "2022-07-28 13:46:47,116 - PROGRESS: pass 8, dispatched chunk #27 = documents up to #2800/18846, outstanding queue size 28\n",
      "2022-07-28 13:46:47,116 - PROGRESS: pass 8, dispatched chunk #28 = documents up to #2900/18846, outstanding queue size 29\n",
      "2022-07-28 13:46:47,117 - PROGRESS: pass 8, dispatched chunk #29 = documents up to #3000/18846, outstanding queue size 30\n",
      "2022-07-28 13:46:47,117 - PROGRESS: pass 8, dispatched chunk #30 = documents up to #3100/18846, outstanding queue size 31\n",
      "2022-07-28 13:46:47,117 - PROGRESS: pass 8, dispatched chunk #31 = documents up to #3200/18846, outstanding queue size 32\n",
      "2022-07-28 13:46:47,118 - PROGRESS: pass 8, dispatched chunk #32 = documents up to #3300/18846, outstanding queue size 33\n",
      "2022-07-28 13:46:47,118 - PROGRESS: pass 8, dispatched chunk #33 = documents up to #3400/18846, outstanding queue size 34\n",
      "2022-07-28 13:46:47,122 - PROGRESS: pass 8, dispatched chunk #34 = documents up to #3500/18846, outstanding queue size 35\n",
      "2022-07-28 13:46:47,122 - PROGRESS: pass 8, dispatched chunk #35 = documents up to #3600/18846, outstanding queue size 36\n",
      "2022-07-28 13:46:47,127 - PROGRESS: pass 8, dispatched chunk #36 = documents up to #3700/18846, outstanding queue size 37\n",
      "2022-07-28 13:46:47,130 - PROGRESS: pass 8, dispatched chunk #37 = documents up to #3800/18846, outstanding queue size 38\n",
      "2022-07-28 13:46:47,134 - PROGRESS: pass 8, dispatched chunk #38 = documents up to #3900/18846, outstanding queue size 39\n",
      "2022-07-28 13:46:47,140 - PROGRESS: pass 8, dispatched chunk #39 = documents up to #4000/18846, outstanding queue size 40\n",
      "2022-07-28 13:46:47,158 - PROGRESS: pass 8, dispatched chunk #40 = documents up to #4100/18846, outstanding queue size 40\n",
      "2022-07-28 13:46:47,161 - PROGRESS: pass 8, dispatched chunk #41 = documents up to #4200/18846, outstanding queue size 41\n",
      "2022-07-28 13:46:47,168 - PROGRESS: pass 8, dispatched chunk #42 = documents up to #4300/18846, outstanding queue size 41\n",
      "2022-07-28 13:46:47,193 - PROGRESS: pass 8, dispatched chunk #43 = documents up to #4400/18846, outstanding queue size 39\n",
      "2022-07-28 13:46:47,218 - PROGRESS: pass 8, dispatched chunk #44 = documents up to #4500/18846, outstanding queue size 38\n",
      "2022-07-28 13:46:47,219 - PROGRESS: pass 8, dispatched chunk #45 = documents up to #4600/18846, outstanding queue size 39\n",
      "2022-07-28 13:46:47,219 - PROGRESS: pass 8, dispatched chunk #46 = documents up to #4700/18846, outstanding queue size 40\n",
      "2022-07-28 13:46:47,221 - PROGRESS: pass 8, dispatched chunk #47 = documents up to #4800/18846, outstanding queue size 41\n",
      "2022-07-28 13:46:47,247 - PROGRESS: pass 8, dispatched chunk #48 = documents up to #4900/18846, outstanding queue size 39\n",
      "2022-07-28 13:46:47,299 - PROGRESS: pass 8, dispatched chunk #49 = documents up to #5000/18846, outstanding queue size 38\n",
      "2022-07-28 13:46:47,338 - PROGRESS: pass 8, dispatched chunk #50 = documents up to #5100/18846, outstanding queue size 38\n",
      "2022-07-28 13:46:47,533 - merging changes from 1500 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:47,583 - topic #6 (0.100): 0.007*\"hz\" + 0.006*\"ww\" + 0.006*\"st\" + 0.005*\"uw\" + 0.005*\"scx\" + 0.004*\"appears\" + 0.004*\"zd\" + 0.003*\"cj\" + 0.003*\"art\" + 0.003*\"battery\"\n",
      "2022-07-28 13:46:47,587 - topic #8 (0.100): 0.675*\"ax\" + 0.053*\"max\" + 0.004*\"di\" + 0.004*\"ei\" + 0.003*\"giz\" + 0.003*\"tm\" + 0.003*\"bhj\" + 0.002*\"wm\" + 0.002*\"ey\" + 0.002*\"istanbul\"\n",
      "2022-07-28 13:46:47,591 - topic #0 (0.100): 0.014*\"drive\" + 0.009*\"card\" + 0.009*\"scsi\" + 0.008*\"mb\" + 0.007*\"disk\" + 0.006*\"hard\" + 0.006*\"bit\" + 0.005*\"mhz\" + 0.005*\"bus\" + 0.005*\"drives\"\n",
      "2022-07-28 13:46:47,596 - topic #4 (0.100): 0.014*\"god\" + 0.010*\"people\" + 0.006*\"jesus\" + 0.005*\"time\" + 0.003*\"db\" + 0.003*\"gun\" + 0.003*\"bible\" + 0.003*\"life\" + 0.003*\"christ\" + 0.003*\"law\"\n",
      "2022-07-28 13:46:47,598 - topic #1 (0.100): 0.009*\"file\" + 0.007*\"windows\" + 0.006*\"program\" + 0.006*\"mail\" + 0.006*\"software\" + 0.005*\"ftp\" + 0.005*\"dos\" + 0.005*\"files\" + 0.005*\"graphics\" + 0.005*\"data\"\n",
      "2022-07-28 13:46:47,602 - topic diff=0.034313, rho=0.071164\n",
      "2022-07-28 13:46:47,606 - PROGRESS: pass 8, dispatched chunk #51 = documents up to #5200/18846, outstanding queue size 37\n",
      "2022-07-28 13:46:47,625 - PROGRESS: pass 8, dispatched chunk #52 = documents up to #5300/18846, outstanding queue size 37\n",
      "2022-07-28 13:46:47,626 - PROGRESS: pass 8, dispatched chunk #53 = documents up to #5400/18846, outstanding queue size 38\n",
      "2022-07-28 13:46:47,627 - PROGRESS: pass 8, dispatched chunk #54 = documents up to #5500/18846, outstanding queue size 39\n",
      "2022-07-28 13:46:47,636 - PROGRESS: pass 8, dispatched chunk #55 = documents up to #5600/18846, outstanding queue size 40\n",
      "2022-07-28 13:46:47,637 - PROGRESS: pass 8, dispatched chunk #56 = documents up to #5700/18846, outstanding queue size 41\n",
      "2022-07-28 13:46:47,638 - PROGRESS: pass 8, dispatched chunk #57 = documents up to #5800/18846, outstanding queue size 42\n",
      "2022-07-28 13:46:47,638 - PROGRESS: pass 8, dispatched chunk #58 = documents up to #5900/18846, outstanding queue size 43\n",
      "2022-07-28 13:46:47,639 - PROGRESS: pass 8, dispatched chunk #59 = documents up to #6000/18846, outstanding queue size 44\n",
      "2022-07-28 13:46:47,639 - PROGRESS: pass 8, dispatched chunk #60 = documents up to #6100/18846, outstanding queue size 45\n",
      "2022-07-28 13:46:47,640 - PROGRESS: pass 8, dispatched chunk #61 = documents up to #6200/18846, outstanding queue size 46\n",
      "2022-07-28 13:46:47,640 - PROGRESS: pass 8, dispatched chunk #62 = documents up to #6300/18846, outstanding queue size 47\n",
      "2022-07-28 13:46:47,655 - PROGRESS: pass 8, dispatched chunk #63 = documents up to #6400/18846, outstanding queue size 48\n",
      "2022-07-28 13:46:47,693 - PROGRESS: pass 8, dispatched chunk #64 = documents up to #6500/18846, outstanding queue size 49\n",
      "2022-07-28 13:46:47,779 - PROGRESS: pass 8, dispatched chunk #65 = documents up to #6600/18846, outstanding queue size 46\n",
      "2022-07-28 13:46:47,780 - PROGRESS: pass 8, dispatched chunk #66 = documents up to #6700/18846, outstanding queue size 47\n",
      "2022-07-28 13:46:47,780 - PROGRESS: pass 8, dispatched chunk #67 = documents up to #6800/18846, outstanding queue size 48\n",
      "2022-07-28 13:46:47,796 - PROGRESS: pass 8, dispatched chunk #68 = documents up to #6900/18846, outstanding queue size 49\n",
      "2022-07-28 13:46:47,798 - PROGRESS: pass 8, dispatched chunk #69 = documents up to #7000/18846, outstanding queue size 50\n",
      "2022-07-28 13:46:47,917 - PROGRESS: pass 8, dispatched chunk #70 = documents up to #7100/18846, outstanding queue size 50\n",
      "2022-07-28 13:46:47,919 - PROGRESS: pass 8, dispatched chunk #71 = documents up to #7200/18846, outstanding queue size 51\n",
      "2022-07-28 13:46:47,919 - PROGRESS: pass 8, dispatched chunk #72 = documents up to #7300/18846, outstanding queue size 52\n",
      "2022-07-28 13:46:47,920 - PROGRESS: pass 8, dispatched chunk #73 = documents up to #7400/18846, outstanding queue size 53\n",
      "2022-07-28 13:46:47,921 - PROGRESS: pass 8, dispatched chunk #74 = documents up to #7500/18846, outstanding queue size 54\n",
      "2022-07-28 13:46:47,951 - PROGRESS: pass 8, dispatched chunk #75 = documents up to #7600/18846, outstanding queue size 55\n",
      "2022-07-28 13:46:47,991 - PROGRESS: pass 8, dispatched chunk #76 = documents up to #7700/18846, outstanding queue size 56\n",
      "2022-07-28 13:46:47,999 - PROGRESS: pass 8, dispatched chunk #77 = documents up to #7800/18846, outstanding queue size 57\n",
      "2022-07-28 13:46:48,006 - PROGRESS: pass 8, dispatched chunk #78 = documents up to #7900/18846, outstanding queue size 58\n",
      "2022-07-28 13:46:48,038 - PROGRESS: pass 8, dispatched chunk #79 = documents up to #8000/18846, outstanding queue size 59\n",
      "2022-07-28 13:46:48,039 - PROGRESS: pass 8, dispatched chunk #80 = documents up to #8100/18846, outstanding queue size 60\n",
      "2022-07-28 13:46:48,069 - PROGRESS: pass 8, dispatched chunk #81 = documents up to #8200/18846, outstanding queue size 60\n",
      "2022-07-28 13:46:48,090 - PROGRESS: pass 8, dispatched chunk #82 = documents up to #8300/18846, outstanding queue size 60\n",
      "2022-07-28 13:46:48,126 - PROGRESS: pass 8, dispatched chunk #83 = documents up to #8400/18846, outstanding queue size 60\n",
      "2022-07-28 13:46:48,146 - PROGRESS: pass 8, dispatched chunk #84 = documents up to #8500/18846, outstanding queue size 61\n",
      "2022-07-28 13:46:48,169 - PROGRESS: pass 8, dispatched chunk #85 = documents up to #8600/18846, outstanding queue size 62\n",
      "2022-07-28 13:46:48,187 - PROGRESS: pass 8, dispatched chunk #86 = documents up to #8700/18846, outstanding queue size 63\n",
      "2022-07-28 13:46:48,254 - PROGRESS: pass 8, dispatched chunk #87 = documents up to #8800/18846, outstanding queue size 64\n",
      "2022-07-28 13:46:48,327 - PROGRESS: pass 8, dispatched chunk #88 = documents up to #8900/18846, outstanding queue size 60\n",
      "2022-07-28 13:46:48,337 - PROGRESS: pass 8, dispatched chunk #89 = documents up to #9000/18846, outstanding queue size 61\n",
      "2022-07-28 13:46:48,340 - PROGRESS: pass 8, dispatched chunk #90 = documents up to #9100/18846, outstanding queue size 62\n",
      "2022-07-28 13:46:48,341 - PROGRESS: pass 8, dispatched chunk #91 = documents up to #9200/18846, outstanding queue size 63\n",
      "2022-07-28 13:46:48,369 - PROGRESS: pass 8, dispatched chunk #92 = documents up to #9300/18846, outstanding queue size 64\n",
      "2022-07-28 13:46:48,613 - merging changes from 1500 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:48,726 - topic #5 (0.100): 0.008*\"armenian\" + 0.004*\"azerbaijan\" + 0.003*\"russian\" + 0.003*\"xfree\" + 0.003*\"source\" + 0.003*\"armenians\" + 0.003*\"armenia\" + 0.003*\"book\" + 0.003*\"azeri\" + 0.002*\"time\"\n",
      "2022-07-28 13:46:48,729 - topic #0 (0.100): 0.014*\"drive\" + 0.009*\"card\" + 0.009*\"scsi\" + 0.008*\"mb\" + 0.007*\"disk\" + 0.006*\"hard\" + 0.006*\"bit\" + 0.005*\"mhz\" + 0.005*\"bus\" + 0.005*\"mac\"\n",
      "2022-07-28 13:46:48,732 - topic #6 (0.100): 0.008*\"hz\" + 0.006*\"ww\" + 0.006*\"st\" + 0.005*\"uw\" + 0.004*\"appears\" + 0.004*\"scx\" + 0.004*\"tl\" + 0.004*\"art\" + 0.004*\"zd\" + 0.003*\"cj\"\n",
      "2022-07-28 13:46:48,735 - topic #1 (0.100): 0.009*\"file\" + 0.008*\"windows\" + 0.006*\"program\" + 0.006*\"mail\" + 0.006*\"software\" + 0.005*\"dos\" + 0.005*\"ftp\" + 0.005*\"files\" + 0.005*\"graphics\" + 0.004*\"data\"\n",
      "2022-07-28 13:46:48,738 - topic #7 (0.100): 0.021*\"jpeg\" + 0.012*\"gif\" + 0.012*\"image\" + 0.009*\"car\" + 0.008*\"file\" + 0.007*\"images\" + 0.007*\"color\" + 0.006*\"format\" + 0.005*\"bit\" + 0.005*\"quality\"\n",
      "2022-07-28 13:46:48,741 - topic diff=0.044138, rho=0.071164\n",
      "2022-07-28 13:46:48,744 - PROGRESS: pass 8, dispatched chunk #93 = documents up to #9400/18846, outstanding queue size 64\n",
      "2022-07-28 13:46:48,750 - PROGRESS: pass 8, dispatched chunk #94 = documents up to #9500/18846, outstanding queue size 64\n",
      "2022-07-28 13:46:48,750 - PROGRESS: pass 8, dispatched chunk #95 = documents up to #9600/18846, outstanding queue size 65\n",
      "2022-07-28 13:46:48,751 - PROGRESS: pass 8, dispatched chunk #96 = documents up to #9700/18846, outstanding queue size 66\n",
      "2022-07-28 13:46:48,752 - PROGRESS: pass 8, dispatched chunk #97 = documents up to #9800/18846, outstanding queue size 67\n",
      "2022-07-28 13:46:48,753 - PROGRESS: pass 8, dispatched chunk #98 = documents up to #9900/18846, outstanding queue size 68\n",
      "2022-07-28 13:46:48,753 - PROGRESS: pass 8, dispatched chunk #99 = documents up to #10000/18846, outstanding queue size 69\n",
      "2022-07-28 13:46:48,754 - PROGRESS: pass 8, dispatched chunk #100 = documents up to #10100/18846, outstanding queue size 70\n",
      "2022-07-28 13:46:48,755 - PROGRESS: pass 8, dispatched chunk #101 = documents up to #10200/18846, outstanding queue size 71\n",
      "2022-07-28 13:46:48,776 - PROGRESS: pass 8, dispatched chunk #102 = documents up to #10300/18846, outstanding queue size 72\n",
      "2022-07-28 13:46:48,812 - PROGRESS: pass 8, dispatched chunk #103 = documents up to #10400/18846, outstanding queue size 73\n",
      "2022-07-28 13:46:48,859 - PROGRESS: pass 8, dispatched chunk #104 = documents up to #10500/18846, outstanding queue size 72\n",
      "2022-07-28 13:46:48,869 - PROGRESS: pass 8, dispatched chunk #105 = documents up to #10600/18846, outstanding queue size 70\n",
      "2022-07-28 13:46:48,893 - PROGRESS: pass 8, dispatched chunk #106 = documents up to #10700/18846, outstanding queue size 71\n",
      "2022-07-28 13:46:48,905 - PROGRESS: pass 8, dispatched chunk #107 = documents up to #10800/18846, outstanding queue size 68\n",
      "2022-07-28 13:46:48,915 - PROGRESS: pass 8, dispatched chunk #108 = documents up to #10900/18846, outstanding queue size 69\n",
      "2022-07-28 13:46:48,923 - PROGRESS: pass 8, dispatched chunk #109 = documents up to #11000/18846, outstanding queue size 70\n",
      "2022-07-28 13:46:48,926 - PROGRESS: pass 8, dispatched chunk #110 = documents up to #11100/18846, outstanding queue size 71\n",
      "2022-07-28 13:46:48,933 - PROGRESS: pass 8, dispatched chunk #111 = documents up to #11200/18846, outstanding queue size 72\n",
      "2022-07-28 13:46:48,942 - PROGRESS: pass 8, dispatched chunk #112 = documents up to #11300/18846, outstanding queue size 72\n",
      "2022-07-28 13:46:48,944 - PROGRESS: pass 8, dispatched chunk #113 = documents up to #11400/18846, outstanding queue size 73\n",
      "2022-07-28 13:46:48,953 - PROGRESS: pass 8, dispatched chunk #114 = documents up to #11500/18846, outstanding queue size 73\n",
      "2022-07-28 13:46:48,955 - PROGRESS: pass 8, dispatched chunk #115 = documents up to #11600/18846, outstanding queue size 74\n",
      "2022-07-28 13:46:48,968 - PROGRESS: pass 8, dispatched chunk #116 = documents up to #11700/18846, outstanding queue size 75\n",
      "2022-07-28 13:46:48,994 - PROGRESS: pass 8, dispatched chunk #117 = documents up to #11800/18846, outstanding queue size 76\n",
      "2022-07-28 13:46:48,997 - PROGRESS: pass 8, dispatched chunk #118 = documents up to #11900/18846, outstanding queue size 77\n",
      "2022-07-28 13:46:49,015 - PROGRESS: pass 8, dispatched chunk #119 = documents up to #12000/18846, outstanding queue size 77\n",
      "2022-07-28 13:46:49,095 - merging changes from 1500 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:49,231 - topic #4 (0.100): 0.014*\"god\" + 0.010*\"people\" + 0.006*\"jesus\" + 0.004*\"time\" + 0.003*\"christ\" + 0.003*\"bible\" + 0.003*\"life\" + 0.003*\"gun\" + 0.003*\"law\" + 0.003*\"christian\"\n",
      "2022-07-28 13:46:49,270 - topic #0 (0.100): 0.014*\"drive\" + 0.009*\"card\" + 0.009*\"scsi\" + 0.008*\"mb\" + 0.007*\"disk\" + 0.006*\"hard\" + 0.006*\"bit\" + 0.006*\"mhz\" + 0.005*\"bus\" + 0.005*\"mac\"\n",
      "2022-07-28 13:46:49,282 - topic #2 (0.100): 0.006*\"space\" + 0.005*\"time\" + 0.004*\"key\" + 0.004*\"government\" + 0.004*\"people\" + 0.003*\"car\" + 0.003*\"power\" + 0.003*\"encryption\" + 0.002*\"public\" + 0.002*\"chip\"\n",
      "2022-07-28 13:46:49,287 - topic #7 (0.100): 0.023*\"jpeg\" + 0.013*\"gif\" + 0.012*\"image\" + 0.008*\"file\" + 0.008*\"car\" + 0.007*\"color\" + 0.007*\"images\" + 0.006*\"format\" + 0.005*\"bit\" + 0.005*\"quality\"\n",
      "2022-07-28 13:46:49,294 - topic #6 (0.100): 0.008*\"hz\" + 0.006*\"ww\" + 0.006*\"scx\" + 0.005*\"st\" + 0.005*\"uw\" + 0.004*\"tl\" + 0.004*\"zd\" + 0.004*\"cj\" + 0.004*\"appears\" + 0.004*\"md\"\n",
      "2022-07-28 13:46:49,298 - topic diff=0.051842, rho=0.071164\n",
      "2022-07-28 13:46:49,303 - PROGRESS: pass 8, dispatched chunk #120 = documents up to #12100/18846, outstanding queue size 76\n",
      "2022-07-28 13:46:49,324 - PROGRESS: pass 8, dispatched chunk #121 = documents up to #12200/18846, outstanding queue size 76\n",
      "2022-07-28 13:46:49,327 - PROGRESS: pass 8, dispatched chunk #122 = documents up to #12300/18846, outstanding queue size 77\n",
      "2022-07-28 13:46:49,328 - PROGRESS: pass 8, dispatched chunk #123 = documents up to #12400/18846, outstanding queue size 78\n",
      "2022-07-28 13:46:49,329 - PROGRESS: pass 8, dispatched chunk #124 = documents up to #12500/18846, outstanding queue size 79\n",
      "2022-07-28 13:46:49,332 - PROGRESS: pass 8, dispatched chunk #125 = documents up to #12600/18846, outstanding queue size 80\n",
      "2022-07-28 13:46:49,332 - PROGRESS: pass 8, dispatched chunk #126 = documents up to #12700/18846, outstanding queue size 81\n",
      "2022-07-28 13:46:49,334 - PROGRESS: pass 8, dispatched chunk #127 = documents up to #12800/18846, outstanding queue size 82\n",
      "2022-07-28 13:46:49,345 - PROGRESS: pass 8, dispatched chunk #128 = documents up to #12900/18846, outstanding queue size 79\n",
      "2022-07-28 13:46:49,346 - PROGRESS: pass 8, dispatched chunk #129 = documents up to #13000/18846, outstanding queue size 80\n",
      "2022-07-28 13:46:49,346 - PROGRESS: pass 8, dispatched chunk #130 = documents up to #13100/18846, outstanding queue size 81\n",
      "2022-07-28 13:46:49,347 - PROGRESS: pass 8, dispatched chunk #131 = documents up to #13200/18846, outstanding queue size 82\n",
      "2022-07-28 13:46:49,386 - PROGRESS: pass 8, dispatched chunk #132 = documents up to #13300/18846, outstanding queue size 82\n",
      "2022-07-28 13:46:49,575 - merging changes from 1700 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:49,673 - topic #8 (0.100): 0.665*\"ax\" + 0.053*\"max\" + 0.004*\"di\" + 0.004*\"ei\" + 0.003*\"giz\" + 0.003*\"tm\" + 0.003*\"bhj\" + 0.002*\"istanbul\" + 0.002*\"wm\" + 0.002*\"ey\"\n",
      "2022-07-28 13:46:49,678 - topic #3 (0.100): 0.011*\"game\" + 0.008*\"team\" + 0.006*\"play\" + 0.006*\"games\" + 0.004*\"season\" + 0.004*\"period\" + 0.004*\"time\" + 0.004*\"win\" + 0.004*\"hockey\" + 0.004*\"players\"\n",
      "2022-07-28 13:46:49,696 - topic #0 (0.100): 0.014*\"drive\" + 0.009*\"card\" + 0.009*\"scsi\" + 0.008*\"mb\" + 0.007*\"disk\" + 0.006*\"mhz\" + 0.006*\"bit\" + 0.006*\"hard\" + 0.005*\"bus\" + 0.005*\"mac\"\n",
      "2022-07-28 13:46:49,697 - topic #1 (0.100): 0.009*\"file\" + 0.007*\"windows\" + 0.006*\"program\" + 0.006*\"mail\" + 0.006*\"software\" + 0.005*\"ftp\" + 0.005*\"graphics\" + 0.004*\"dos\" + 0.004*\"files\" + 0.004*\"data\"\n",
      "2022-07-28 13:46:49,700 - topic #4 (0.100): 0.014*\"god\" + 0.010*\"people\" + 0.006*\"jesus\" + 0.004*\"time\" + 0.003*\"bible\" + 0.003*\"christ\" + 0.003*\"life\" + 0.003*\"gun\" + 0.003*\"law\" + 0.003*\"christian\"\n",
      "2022-07-28 13:46:49,702 - topic diff=0.034448, rho=0.071164\n",
      "2022-07-28 13:46:49,747 - PROGRESS: pass 8, dispatched chunk #133 = documents up to #13400/18846, outstanding queue size 72\n",
      "2022-07-28 13:46:49,751 - PROGRESS: pass 8, dispatched chunk #134 = documents up to #13500/18846, outstanding queue size 72\n",
      "2022-07-28 13:46:49,753 - PROGRESS: pass 8, dispatched chunk #135 = documents up to #13600/18846, outstanding queue size 73\n",
      "2022-07-28 13:46:49,754 - PROGRESS: pass 8, dispatched chunk #136 = documents up to #13700/18846, outstanding queue size 74\n",
      "2022-07-28 13:46:49,756 - PROGRESS: pass 8, dispatched chunk #137 = documents up to #13800/18846, outstanding queue size 75\n",
      "2022-07-28 13:46:49,757 - PROGRESS: pass 8, dispatched chunk #138 = documents up to #13900/18846, outstanding queue size 76\n",
      "2022-07-28 13:46:49,759 - PROGRESS: pass 8, dispatched chunk #139 = documents up to #14000/18846, outstanding queue size 77\n",
      "2022-07-28 13:46:49,760 - PROGRESS: pass 8, dispatched chunk #140 = documents up to #14100/18846, outstanding queue size 78\n",
      "2022-07-28 13:46:49,762 - PROGRESS: pass 8, dispatched chunk #141 = documents up to #14200/18846, outstanding queue size 79\n",
      "2022-07-28 13:46:49,765 - PROGRESS: pass 8, dispatched chunk #142 = documents up to #14300/18846, outstanding queue size 80\n",
      "2022-07-28 13:46:49,766 - PROGRESS: pass 8, dispatched chunk #143 = documents up to #14400/18846, outstanding queue size 81\n",
      "2022-07-28 13:46:49,768 - PROGRESS: pass 8, dispatched chunk #144 = documents up to #14500/18846, outstanding queue size 82\n",
      "2022-07-28 13:46:49,769 - PROGRESS: pass 8, dispatched chunk #145 = documents up to #14600/18846, outstanding queue size 83\n",
      "2022-07-28 13:46:49,771 - PROGRESS: pass 8, dispatched chunk #146 = documents up to #14700/18846, outstanding queue size 84\n",
      "2022-07-28 13:46:49,772 - PROGRESS: pass 8, dispatched chunk #147 = documents up to #14800/18846, outstanding queue size 85\n",
      "2022-07-28 13:46:49,774 - PROGRESS: pass 8, dispatched chunk #148 = documents up to #14900/18846, outstanding queue size 86\n",
      "2022-07-28 13:46:49,776 - PROGRESS: pass 8, dispatched chunk #149 = documents up to #15000/18846, outstanding queue size 87\n",
      "2022-07-28 13:46:49,778 - PROGRESS: pass 8, dispatched chunk #150 = documents up to #15100/18846, outstanding queue size 88\n",
      "2022-07-28 13:46:49,840 - PROGRESS: pass 8, dispatched chunk #151 = documents up to #15200/18846, outstanding queue size 89\n",
      "2022-07-28 13:46:49,845 - PROGRESS: pass 8, dispatched chunk #152 = documents up to #15300/18846, outstanding queue size 90\n",
      "2022-07-28 13:46:49,905 - PROGRESS: pass 8, dispatched chunk #153 = documents up to #15400/18846, outstanding queue size 85\n",
      "2022-07-28 13:46:49,934 - PROGRESS: pass 8, dispatched chunk #154 = documents up to #15500/18846, outstanding queue size 81\n",
      "2022-07-28 13:46:49,935 - PROGRESS: pass 8, dispatched chunk #155 = documents up to #15600/18846, outstanding queue size 82\n",
      "2022-07-28 13:46:49,959 - PROGRESS: pass 8, dispatched chunk #156 = documents up to #15700/18846, outstanding queue size 83\n",
      "2022-07-28 13:46:49,980 - PROGRESS: pass 8, dispatched chunk #157 = documents up to #15800/18846, outstanding queue size 84\n",
      "2022-07-28 13:46:49,991 - PROGRESS: pass 8, dispatched chunk #158 = documents up to #15900/18846, outstanding queue size 85\n",
      "2022-07-28 13:46:50,021 - PROGRESS: pass 8, dispatched chunk #159 = documents up to #16000/18846, outstanding queue size 84\n",
      "2022-07-28 13:46:50,022 - PROGRESS: pass 8, dispatched chunk #160 = documents up to #16100/18846, outstanding queue size 85\n",
      "2022-07-28 13:46:50,095 - merging changes from 1500 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:50,164 - topic #7 (0.100): 0.021*\"jpeg\" + 0.012*\"gif\" + 0.012*\"image\" + 0.008*\"car\" + 0.008*\"file\" + 0.007*\"color\" + 0.007*\"images\" + 0.006*\"format\" + 0.005*\"bit\" + 0.005*\"quality\"\n",
      "2022-07-28 13:46:50,168 - topic #0 (0.100): 0.015*\"drive\" + 0.009*\"card\" + 0.009*\"scsi\" + 0.008*\"mb\" + 0.007*\"disk\" + 0.006*\"bit\" + 0.006*\"mhz\" + 0.006*\"hard\" + 0.005*\"bus\" + 0.005*\"mac\"\n",
      "2022-07-28 13:46:50,175 - topic #9 (0.100): 0.013*\"people\" + 0.005*\"government\" + 0.005*\"israel\" + 0.004*\"president\" + 0.004*\"time\" + 0.004*\"jews\" + 0.004*\"war\" + 0.003*\"children\" + 0.003*\"turkish\" + 0.003*\"armenians\"\n",
      "2022-07-28 13:46:50,185 - topic #6 (0.100): 0.008*\"hz\" + 0.007*\"ww\" + 0.006*\"uw\" + 0.006*\"scx\" + 0.006*\"st\" + 0.004*\"zd\" + 0.004*\"appears\" + 0.004*\"cj\" + 0.004*\"tl\" + 0.004*\"art\"\n",
      "2022-07-28 13:46:50,193 - topic #5 (0.100): 0.008*\"armenian\" + 0.005*\"azerbaijan\" + 0.004*\"russian\" + 0.003*\"source\" + 0.003*\"armenia\" + 0.003*\"armenians\" + 0.003*\"book\" + 0.003*\"azeri\" + 0.002*\"xfree\" + 0.002*\"time\"\n",
      "2022-07-28 13:46:50,195 - topic diff=0.041589, rho=0.071164\n",
      "2022-07-28 13:46:50,198 - PROGRESS: pass 8, dispatched chunk #161 = documents up to #16200/18846, outstanding queue size 85\n",
      "2022-07-28 13:46:50,202 - PROGRESS: pass 8, dispatched chunk #162 = documents up to #16300/18846, outstanding queue size 85\n",
      "2022-07-28 13:46:50,203 - PROGRESS: pass 8, dispatched chunk #163 = documents up to #16400/18846, outstanding queue size 86\n",
      "2022-07-28 13:46:50,203 - PROGRESS: pass 8, dispatched chunk #164 = documents up to #16500/18846, outstanding queue size 87\n",
      "2022-07-28 13:46:50,204 - PROGRESS: pass 8, dispatched chunk #165 = documents up to #16600/18846, outstanding queue size 88\n",
      "2022-07-28 13:46:50,207 - PROGRESS: pass 8, dispatched chunk #166 = documents up to #16700/18846, outstanding queue size 89\n",
      "2022-07-28 13:46:50,211 - PROGRESS: pass 8, dispatched chunk #167 = documents up to #16800/18846, outstanding queue size 90\n",
      "2022-07-28 13:46:50,237 - PROGRESS: pass 8, dispatched chunk #168 = documents up to #16900/18846, outstanding queue size 91\n",
      "2022-07-28 13:46:50,271 - PROGRESS: pass 8, dispatched chunk #169 = documents up to #17000/18846, outstanding queue size 80\n",
      "2022-07-28 13:46:50,273 - PROGRESS: pass 8, dispatched chunk #170 = documents up to #17100/18846, outstanding queue size 81\n",
      "2022-07-28 13:46:50,418 - merging changes from 2400 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:50,503 - topic #0 (0.100): 0.015*\"drive\" + 0.010*\"scsi\" + 0.009*\"card\" + 0.008*\"mb\" + 0.007*\"disk\" + 0.006*\"bit\" + 0.006*\"hard\" + 0.006*\"mhz\" + 0.005*\"bus\" + 0.005*\"mac\"\n",
      "2022-07-28 13:46:50,505 - topic #1 (0.100): 0.010*\"file\" + 0.007*\"windows\" + 0.006*\"program\" + 0.006*\"mail\" + 0.006*\"software\" + 0.005*\"ftp\" + 0.005*\"graphics\" + 0.004*\"dos\" + 0.004*\"files\" + 0.004*\"data\"\n",
      "2022-07-28 13:46:50,506 - topic #3 (0.100): 0.011*\"game\" + 0.008*\"team\" + 0.006*\"play\" + 0.006*\"games\" + 0.004*\"period\" + 0.004*\"season\" + 0.004*\"time\" + 0.004*\"win\" + 0.004*\"hockey\" + 0.004*\"players\"\n",
      "2022-07-28 13:46:50,508 - topic #6 (0.100): 0.008*\"hz\" + 0.007*\"ww\" + 0.006*\"uw\" + 0.006*\"scx\" + 0.006*\"st\" + 0.004*\"zd\" + 0.004*\"appears\" + 0.004*\"cj\" + 0.004*\"tl\" + 0.004*\"art\"\n",
      "2022-07-28 13:46:50,510 - topic #7 (0.100): 0.021*\"jpeg\" + 0.012*\"image\" + 0.012*\"gif\" + 0.009*\"car\" + 0.008*\"file\" + 0.007*\"images\" + 0.007*\"color\" + 0.006*\"format\" + 0.006*\"bit\" + 0.005*\"quality\"\n",
      "2022-07-28 13:46:50,512 - topic diff=0.031085, rho=0.071164\n",
      "2022-07-28 13:46:50,512 - PROGRESS: pass 8, dispatched chunk #171 = documents up to #17200/18846, outstanding queue size 71\n",
      "2022-07-28 13:46:50,530 - PROGRESS: pass 8, dispatched chunk #172 = documents up to #17300/18846, outstanding queue size 66\n",
      "2022-07-28 13:46:50,531 - PROGRESS: pass 8, dispatched chunk #173 = documents up to #17400/18846, outstanding queue size 67\n",
      "2022-07-28 13:46:50,531 - PROGRESS: pass 8, dispatched chunk #174 = documents up to #17500/18846, outstanding queue size 68\n",
      "2022-07-28 13:46:50,532 - PROGRESS: pass 8, dispatched chunk #175 = documents up to #17600/18846, outstanding queue size 69\n",
      "2022-07-28 13:46:50,532 - PROGRESS: pass 8, dispatched chunk #176 = documents up to #17700/18846, outstanding queue size 70\n",
      "2022-07-28 13:46:50,533 - PROGRESS: pass 8, dispatched chunk #177 = documents up to #17800/18846, outstanding queue size 71\n",
      "2022-07-28 13:46:50,534 - PROGRESS: pass 8, dispatched chunk #178 = documents up to #17900/18846, outstanding queue size 72\n",
      "2022-07-28 13:46:50,536 - PROGRESS: pass 8, dispatched chunk #179 = documents up to #18000/18846, outstanding queue size 73\n",
      "2022-07-28 13:46:50,568 - PROGRESS: pass 8, dispatched chunk #180 = documents up to #18100/18846, outstanding queue size 69\n",
      "2022-07-28 13:46:50,569 - PROGRESS: pass 8, dispatched chunk #181 = documents up to #18200/18846, outstanding queue size 70\n",
      "2022-07-28 13:46:50,570 - PROGRESS: pass 8, dispatched chunk #182 = documents up to #18300/18846, outstanding queue size 71\n",
      "2022-07-28 13:46:50,585 - PROGRESS: pass 8, dispatched chunk #183 = documents up to #18400/18846, outstanding queue size 69\n",
      "2022-07-28 13:46:50,586 - PROGRESS: pass 8, dispatched chunk #184 = documents up to #18500/18846, outstanding queue size 70\n",
      "2022-07-28 13:46:50,586 - PROGRESS: pass 8, dispatched chunk #185 = documents up to #18600/18846, outstanding queue size 71\n",
      "2022-07-28 13:46:50,587 - PROGRESS: pass 8, dispatched chunk #186 = documents up to #18700/18846, outstanding queue size 72\n",
      "2022-07-28 13:46:50,592 - PROGRESS: pass 8, dispatched chunk #187 = documents up to #18800/18846, outstanding queue size 73\n",
      "2022-07-28 13:46:50,603 - PROGRESS: pass 8, dispatched chunk #188 = documents up to #18846/18846, outstanding queue size 74\n",
      "2022-07-28 13:46:50,760 - merging changes from 1500 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:50,841 - topic #5 (0.100): 0.008*\"armenian\" + 0.005*\"azerbaijan\" + 0.004*\"russian\" + 0.003*\"armenia\" + 0.003*\"source\" + 0.003*\"armenians\" + 0.003*\"book\" + 0.002*\"azeri\" + 0.002*\"xfree\" + 0.002*\"time\"\n",
      "2022-07-28 13:46:50,846 - topic #3 (0.100): 0.011*\"game\" + 0.008*\"team\" + 0.006*\"play\" + 0.006*\"games\" + 0.005*\"period\" + 0.004*\"time\" + 0.004*\"season\" + 0.004*\"win\" + 0.004*\"hockey\" + 0.004*\"players\"\n",
      "2022-07-28 13:46:50,848 - topic #9 (0.100): 0.013*\"people\" + 0.005*\"government\" + 0.004*\"president\" + 0.004*\"israel\" + 0.004*\"war\" + 0.004*\"time\" + 0.004*\"jews\" + 0.003*\"children\" + 0.003*\"turkish\" + 0.003*\"armenians\"\n",
      "2022-07-28 13:46:50,850 - topic #2 (0.100): 0.006*\"space\" + 0.006*\"time\" + 0.004*\"key\" + 0.004*\"government\" + 0.004*\"people\" + 0.003*\"car\" + 0.003*\"power\" + 0.003*\"encryption\" + 0.003*\"chip\" + 0.002*\"public\"\n",
      "2022-07-28 13:46:50,853 - topic #1 (0.100): 0.010*\"file\" + 0.007*\"windows\" + 0.006*\"program\" + 0.006*\"mail\" + 0.006*\"software\" + 0.005*\"ftp\" + 0.005*\"graphics\" + 0.004*\"data\" + 0.004*\"dos\" + 0.004*\"files\"\n",
      "2022-07-28 13:46:50,855 - topic diff=0.037052, rho=0.071164\n",
      "2022-07-28 13:46:51,013 - -10.424 per-word bound, 1373.9 perplexity estimate based on a held-out corpus of 46 documents with 2932 words\n",
      "2022-07-28 13:46:51,477 - merging changes from 1600 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:51,647 - topic #6 (0.100): 0.008*\"hz\" + 0.006*\"ww\" + 0.006*\"st\" + 0.005*\"uw\" + 0.005*\"scx\" + 0.004*\"appears\" + 0.004*\"zd\" + 0.004*\"cj\" + 0.004*\"art\" + 0.003*\"tl\"\n",
      "2022-07-28 13:46:51,650 - topic #7 (0.100): 0.022*\"jpeg\" + 0.013*\"image\" + 0.012*\"gif\" + 0.008*\"file\" + 0.008*\"car\" + 0.008*\"images\" + 0.007*\"color\" + 0.007*\"format\" + 0.006*\"bit\" + 0.005*\"quality\"\n",
      "2022-07-28 13:46:51,654 - topic #8 (0.100): 0.704*\"ax\" + 0.055*\"max\" + 0.004*\"di\" + 0.004*\"ei\" + 0.003*\"tm\" + 0.003*\"giz\" + 0.002*\"bhj\" + 0.002*\"wm\" + 0.002*\"ey\" + 0.002*\"qq\"\n",
      "2022-07-28 13:46:51,677 - topic #5 (0.100): 0.008*\"armenian\" + 0.005*\"azerbaijan\" + 0.004*\"russian\" + 0.003*\"armenia\" + 0.003*\"source\" + 0.003*\"book\" + 0.003*\"armenians\" + 0.002*\"azeri\" + 0.002*\"time\" + 0.002*\"xfree\"\n",
      "2022-07-28 13:46:51,684 - topic #4 (0.100): 0.014*\"god\" + 0.010*\"people\" + 0.006*\"jesus\" + 0.005*\"time\" + 0.004*\"gun\" + 0.003*\"life\" + 0.003*\"bible\" + 0.003*\"db\" + 0.003*\"christ\" + 0.003*\"christian\"\n",
      "2022-07-28 13:46:51,690 - topic diff=0.035606, rho=0.071164\n",
      "2022-07-28 13:46:51,799 - -10.421 per-word bound, 1371.1 perplexity estimate based on a held-out corpus of 46 documents with 2932 words\n",
      "2022-07-28 13:46:51,958 - merging changes from 5646 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:51,989 - topic #6 (0.100): 0.008*\"hz\" + 0.006*\"ww\" + 0.006*\"st\" + 0.005*\"uw\" + 0.005*\"scx\" + 0.004*\"appears\" + 0.004*\"zd\" + 0.004*\"cj\" + 0.004*\"art\" + 0.003*\"md\"\n",
      "2022-07-28 13:46:51,991 - topic #2 (0.100): 0.006*\"space\" + 0.005*\"time\" + 0.004*\"key\" + 0.004*\"government\" + 0.004*\"people\" + 0.003*\"car\" + 0.003*\"encryption\" + 0.003*\"power\" + 0.003*\"chip\" + 0.002*\"public\"\n",
      "2022-07-28 13:46:51,992 - topic #9 (0.100): 0.013*\"people\" + 0.005*\"government\" + 0.004*\"israel\" + 0.004*\"president\" + 0.004*\"time\" + 0.004*\"war\" + 0.004*\"jews\" + 0.003*\"children\" + 0.003*\"turkish\" + 0.003*\"armenians\"\n",
      "2022-07-28 13:46:51,994 - topic #5 (0.100): 0.008*\"armenian\" + 0.005*\"azerbaijan\" + 0.003*\"russian\" + 0.003*\"armenia\" + 0.003*\"source\" + 0.003*\"book\" + 0.003*\"armenians\" + 0.002*\"azeri\" + 0.002*\"xfree\" + 0.002*\"time\"\n",
      "2022-07-28 13:46:51,995 - topic #3 (0.100): 0.011*\"game\" + 0.008*\"team\" + 0.006*\"games\" + 0.006*\"play\" + 0.005*\"season\" + 0.005*\"period\" + 0.004*\"time\" + 0.004*\"hockey\" + 0.004*\"win\" + 0.004*\"players\"\n",
      "2022-07-28 13:46:51,997 - topic diff=0.027645, rho=0.071164\n",
      "2022-07-28 13:46:52,067 - -10.394 per-word bound, 1346.0 perplexity estimate based on a held-out corpus of 46 documents with 2932 words\n",
      "2022-07-28 13:46:52,068 - PROGRESS: pass 9, dispatched chunk #0 = documents up to #100/18846, outstanding queue size 1\n",
      "2022-07-28 13:46:52,071 - PROGRESS: pass 9, dispatched chunk #1 = documents up to #200/18846, outstanding queue size 2\n",
      "2022-07-28 13:46:52,072 - PROGRESS: pass 9, dispatched chunk #2 = documents up to #300/18846, outstanding queue size 3\n",
      "2022-07-28 13:46:52,072 - PROGRESS: pass 9, dispatched chunk #3 = documents up to #400/18846, outstanding queue size 4\n",
      "2022-07-28 13:46:52,072 - PROGRESS: pass 9, dispatched chunk #4 = documents up to #500/18846, outstanding queue size 5\n",
      "2022-07-28 13:46:52,073 - PROGRESS: pass 9, dispatched chunk #5 = documents up to #600/18846, outstanding queue size 6\n",
      "2022-07-28 13:46:52,073 - PROGRESS: pass 9, dispatched chunk #6 = documents up to #700/18846, outstanding queue size 7\n",
      "2022-07-28 13:46:52,076 - PROGRESS: pass 9, dispatched chunk #7 = documents up to #800/18846, outstanding queue size 8\n",
      "2022-07-28 13:46:52,076 - PROGRESS: pass 9, dispatched chunk #8 = documents up to #900/18846, outstanding queue size 9\n",
      "2022-07-28 13:46:52,077 - PROGRESS: pass 9, dispatched chunk #9 = documents up to #1000/18846, outstanding queue size 10\n",
      "2022-07-28 13:46:52,077 - PROGRESS: pass 9, dispatched chunk #10 = documents up to #1100/18846, outstanding queue size 11\n",
      "2022-07-28 13:46:52,077 - PROGRESS: pass 9, dispatched chunk #11 = documents up to #1200/18846, outstanding queue size 12\n",
      "2022-07-28 13:46:52,078 - PROGRESS: pass 9, dispatched chunk #12 = documents up to #1300/18846, outstanding queue size 13\n",
      "2022-07-28 13:46:52,078 - PROGRESS: pass 9, dispatched chunk #13 = documents up to #1400/18846, outstanding queue size 14\n",
      "2022-07-28 13:46:52,081 - PROGRESS: pass 9, dispatched chunk #14 = documents up to #1500/18846, outstanding queue size 15\n",
      "2022-07-28 13:46:52,081 - PROGRESS: pass 9, dispatched chunk #15 = documents up to #1600/18846, outstanding queue size 16\n",
      "2022-07-28 13:46:52,082 - PROGRESS: pass 9, dispatched chunk #16 = documents up to #1700/18846, outstanding queue size 17\n",
      "2022-07-28 13:46:52,082 - PROGRESS: pass 9, dispatched chunk #17 = documents up to #1800/18846, outstanding queue size 18\n",
      "2022-07-28 13:46:52,083 - PROGRESS: pass 9, dispatched chunk #18 = documents up to #1900/18846, outstanding queue size 19\n",
      "2022-07-28 13:46:52,083 - PROGRESS: pass 9, dispatched chunk #19 = documents up to #2000/18846, outstanding queue size 20\n",
      "2022-07-28 13:46:52,085 - PROGRESS: pass 9, dispatched chunk #20 = documents up to #2100/18846, outstanding queue size 21\n",
      "2022-07-28 13:46:52,086 - PROGRESS: pass 9, dispatched chunk #21 = documents up to #2200/18846, outstanding queue size 22\n",
      "2022-07-28 13:46:52,086 - PROGRESS: pass 9, dispatched chunk #22 = documents up to #2300/18846, outstanding queue size 23\n",
      "2022-07-28 13:46:52,087 - PROGRESS: pass 9, dispatched chunk #23 = documents up to #2400/18846, outstanding queue size 24\n",
      "2022-07-28 13:46:52,087 - PROGRESS: pass 9, dispatched chunk #24 = documents up to #2500/18846, outstanding queue size 25\n",
      "2022-07-28 13:46:52,087 - PROGRESS: pass 9, dispatched chunk #25 = documents up to #2600/18846, outstanding queue size 26\n",
      "2022-07-28 13:46:52,088 - PROGRESS: pass 9, dispatched chunk #26 = documents up to #2700/18846, outstanding queue size 27\n",
      "2022-07-28 13:46:52,091 - PROGRESS: pass 9, dispatched chunk #27 = documents up to #2800/18846, outstanding queue size 28\n",
      "2022-07-28 13:46:52,091 - PROGRESS: pass 9, dispatched chunk #28 = documents up to #2900/18846, outstanding queue size 29\n",
      "2022-07-28 13:46:52,091 - PROGRESS: pass 9, dispatched chunk #29 = documents up to #3000/18846, outstanding queue size 30\n",
      "2022-07-28 13:46:52,092 - PROGRESS: pass 9, dispatched chunk #30 = documents up to #3100/18846, outstanding queue size 31\n",
      "2022-07-28 13:46:52,094 - PROGRESS: pass 9, dispatched chunk #31 = documents up to #3200/18846, outstanding queue size 32\n",
      "2022-07-28 13:46:52,095 - PROGRESS: pass 9, dispatched chunk #32 = documents up to #3300/18846, outstanding queue size 33\n",
      "2022-07-28 13:46:52,095 - PROGRESS: pass 9, dispatched chunk #33 = documents up to #3400/18846, outstanding queue size 34\n",
      "2022-07-28 13:46:52,096 - PROGRESS: pass 9, dispatched chunk #34 = documents up to #3500/18846, outstanding queue size 35\n",
      "2022-07-28 13:46:52,096 - PROGRESS: pass 9, dispatched chunk #35 = documents up to #3600/18846, outstanding queue size 36\n",
      "2022-07-28 13:46:52,102 - PROGRESS: pass 9, dispatched chunk #36 = documents up to #3700/18846, outstanding queue size 37\n",
      "2022-07-28 13:46:52,111 - PROGRESS: pass 9, dispatched chunk #37 = documents up to #3800/18846, outstanding queue size 38\n",
      "2022-07-28 13:46:52,114 - PROGRESS: pass 9, dispatched chunk #38 = documents up to #3900/18846, outstanding queue size 39\n",
      "2022-07-28 13:46:52,118 - PROGRESS: pass 9, dispatched chunk #39 = documents up to #4000/18846, outstanding queue size 40\n",
      "2022-07-28 13:46:52,123 - PROGRESS: pass 9, dispatched chunk #40 = documents up to #4100/18846, outstanding queue size 41\n",
      "2022-07-28 13:46:52,138 - PROGRESS: pass 9, dispatched chunk #41 = documents up to #4200/18846, outstanding queue size 41\n",
      "2022-07-28 13:46:52,152 - PROGRESS: pass 9, dispatched chunk #42 = documents up to #4300/18846, outstanding queue size 41\n",
      "2022-07-28 13:46:52,167 - PROGRESS: pass 9, dispatched chunk #43 = documents up to #4400/18846, outstanding queue size 39\n",
      "2022-07-28 13:46:52,171 - PROGRESS: pass 9, dispatched chunk #44 = documents up to #4500/18846, outstanding queue size 40\n",
      "2022-07-28 13:46:52,172 - PROGRESS: pass 9, dispatched chunk #45 = documents up to #4600/18846, outstanding queue size 41\n",
      "2022-07-28 13:46:52,178 - PROGRESS: pass 9, dispatched chunk #46 = documents up to #4700/18846, outstanding queue size 41\n",
      "2022-07-28 13:46:52,206 - PROGRESS: pass 9, dispatched chunk #47 = documents up to #4800/18846, outstanding queue size 39\n",
      "2022-07-28 13:46:52,221 - PROGRESS: pass 9, dispatched chunk #48 = documents up to #4900/18846, outstanding queue size 39\n",
      "2022-07-28 13:46:52,226 - PROGRESS: pass 9, dispatched chunk #49 = documents up to #5000/18846, outstanding queue size 40\n",
      "2022-07-28 13:46:52,230 - PROGRESS: pass 9, dispatched chunk #50 = documents up to #5100/18846, outstanding queue size 41\n",
      "2022-07-28 13:46:52,263 - PROGRESS: pass 9, dispatched chunk #51 = documents up to #5200/18846, outstanding queue size 40\n",
      "2022-07-28 13:46:52,277 - PROGRESS: pass 9, dispatched chunk #52 = documents up to #5300/18846, outstanding queue size 40\n",
      "2022-07-28 13:46:52,309 - PROGRESS: pass 9, dispatched chunk #53 = documents up to #5400/18846, outstanding queue size 40\n",
      "2022-07-28 13:46:52,314 - PROGRESS: pass 9, dispatched chunk #54 = documents up to #5500/18846, outstanding queue size 41\n",
      "2022-07-28 13:46:52,462 - merging changes from 1600 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:52,526 - topic #9 (0.100): 0.013*\"people\" + 0.005*\"government\" + 0.004*\"president\" + 0.004*\"israel\" + 0.004*\"time\" + 0.004*\"war\" + 0.004*\"jews\" + 0.003*\"children\" + 0.003*\"turkish\" + 0.003*\"armenians\"\n",
      "2022-07-28 13:46:52,528 - topic #2 (0.100): 0.006*\"space\" + 0.005*\"time\" + 0.004*\"key\" + 0.004*\"government\" + 0.004*\"people\" + 0.003*\"car\" + 0.003*\"encryption\" + 0.003*\"power\" + 0.003*\"chip\" + 0.002*\"public\"\n",
      "2022-07-28 13:46:52,529 - topic #5 (0.100): 0.008*\"armenian\" + 0.005*\"azerbaijan\" + 0.003*\"russian\" + 0.003*\"armenia\" + 0.003*\"source\" + 0.003*\"book\" + 0.003*\"armenians\" + 0.003*\"azeri\" + 0.002*\"karabakh\" + 0.002*\"xfree\"\n",
      "2022-07-28 13:46:52,531 - topic #3 (0.100): 0.011*\"game\" + 0.008*\"team\" + 0.006*\"games\" + 0.006*\"play\" + 0.005*\"season\" + 0.005*\"period\" + 0.004*\"time\" + 0.004*\"hockey\" + 0.004*\"win\" + 0.004*\"players\"\n",
      "2022-07-28 13:46:52,532 - topic #8 (0.100): 0.687*\"ax\" + 0.054*\"max\" + 0.004*\"di\" + 0.004*\"ei\" + 0.003*\"tm\" + 0.003*\"giz\" + 0.002*\"bhj\" + 0.002*\"wm\" + 0.002*\"ey\" + 0.002*\"qq\"\n",
      "2022-07-28 13:46:52,534 - topic diff=0.033647, rho=0.070984\n",
      "2022-07-28 13:46:52,535 - PROGRESS: pass 9, dispatched chunk #55 = documents up to #5600/18846, outstanding queue size 40\n",
      "2022-07-28 13:46:52,610 - PROGRESS: pass 9, dispatched chunk #56 = documents up to #5700/18846, outstanding queue size 29\n",
      "2022-07-28 13:46:52,616 - PROGRESS: pass 9, dispatched chunk #57 = documents up to #5800/18846, outstanding queue size 30\n",
      "2022-07-28 13:46:52,617 - PROGRESS: pass 9, dispatched chunk #58 = documents up to #5900/18846, outstanding queue size 31\n",
      "2022-07-28 13:46:52,617 - PROGRESS: pass 9, dispatched chunk #59 = documents up to #6000/18846, outstanding queue size 32\n",
      "2022-07-28 13:46:52,618 - PROGRESS: pass 9, dispatched chunk #60 = documents up to #6100/18846, outstanding queue size 33\n",
      "2022-07-28 13:46:52,618 - PROGRESS: pass 9, dispatched chunk #61 = documents up to #6200/18846, outstanding queue size 34\n",
      "2022-07-28 13:46:52,619 - PROGRESS: pass 9, dispatched chunk #62 = documents up to #6300/18846, outstanding queue size 35\n",
      "2022-07-28 13:46:52,619 - PROGRESS: pass 9, dispatched chunk #63 = documents up to #6400/18846, outstanding queue size 36\n",
      "2022-07-28 13:46:52,620 - PROGRESS: pass 9, dispatched chunk #64 = documents up to #6500/18846, outstanding queue size 37\n",
      "2022-07-28 13:46:52,703 - PROGRESS: pass 9, dispatched chunk #65 = documents up to #6600/18846, outstanding queue size 38\n",
      "2022-07-28 13:46:52,721 - PROGRESS: pass 9, dispatched chunk #66 = documents up to #6700/18846, outstanding queue size 38\n",
      "2022-07-28 13:46:52,737 - PROGRESS: pass 9, dispatched chunk #67 = documents up to #6800/18846, outstanding queue size 39\n",
      "2022-07-28 13:46:52,893 - merging changes from 1700 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:53,122 - topic #1 (0.100): 0.009*\"file\" + 0.007*\"windows\" + 0.006*\"program\" + 0.006*\"mail\" + 0.006*\"software\" + 0.005*\"ftp\" + 0.005*\"dos\" + 0.005*\"files\" + 0.005*\"graphics\" + 0.005*\"data\"\n",
      "2022-07-28 13:46:53,127 - topic #2 (0.100): 0.006*\"space\" + 0.005*\"time\" + 0.004*\"key\" + 0.004*\"government\" + 0.004*\"people\" + 0.003*\"car\" + 0.003*\"encryption\" + 0.003*\"power\" + 0.003*\"chip\" + 0.002*\"clipper\"\n",
      "2022-07-28 13:46:53,130 - topic #8 (0.100): 0.682*\"ax\" + 0.054*\"max\" + 0.005*\"di\" + 0.004*\"ei\" + 0.003*\"tm\" + 0.003*\"giz\" + 0.003*\"bhj\" + 0.002*\"wm\" + 0.002*\"ey\" + 0.002*\"um\"\n",
      "2022-07-28 13:46:53,134 - topic #4 (0.100): 0.014*\"god\" + 0.010*\"people\" + 0.006*\"jesus\" + 0.005*\"time\" + 0.003*\"bible\" + 0.003*\"life\" + 0.003*\"gun\" + 0.003*\"christ\" + 0.003*\"christian\" + 0.003*\"law\"\n",
      "2022-07-28 13:46:53,136 - topic #6 (0.100): 0.008*\"hz\" + 0.006*\"ww\" + 0.006*\"st\" + 0.005*\"uw\" + 0.004*\"appears\" + 0.004*\"scx\" + 0.004*\"tl\" + 0.004*\"art\" + 0.004*\"zd\" + 0.003*\"wolverine\"\n",
      "2022-07-28 13:46:53,139 - topic diff=0.041500, rho=0.070984\n",
      "2022-07-28 13:46:53,141 - PROGRESS: pass 9, dispatched chunk #68 = documents up to #6900/18846, outstanding queue size 36\n",
      "2022-07-28 13:46:53,148 - PROGRESS: pass 9, dispatched chunk #69 = documents up to #7000/18846, outstanding queue size 36\n",
      "2022-07-28 13:46:53,150 - PROGRESS: pass 9, dispatched chunk #70 = documents up to #7100/18846, outstanding queue size 37\n",
      "2022-07-28 13:46:53,152 - PROGRESS: pass 9, dispatched chunk #71 = documents up to #7200/18846, outstanding queue size 38\n",
      "2022-07-28 13:46:53,153 - PROGRESS: pass 9, dispatched chunk #72 = documents up to #7300/18846, outstanding queue size 39\n",
      "2022-07-28 13:46:53,154 - PROGRESS: pass 9, dispatched chunk #73 = documents up to #7400/18846, outstanding queue size 40\n",
      "2022-07-28 13:46:53,156 - PROGRESS: pass 9, dispatched chunk #74 = documents up to #7500/18846, outstanding queue size 41\n",
      "2022-07-28 13:46:53,157 - PROGRESS: pass 9, dispatched chunk #75 = documents up to #7600/18846, outstanding queue size 42\n",
      "2022-07-28 13:46:53,159 - PROGRESS: pass 9, dispatched chunk #76 = documents up to #7700/18846, outstanding queue size 43\n",
      "2022-07-28 13:46:53,160 - PROGRESS: pass 9, dispatched chunk #77 = documents up to #7800/18846, outstanding queue size 44\n",
      "2022-07-28 13:46:53,162 - PROGRESS: pass 9, dispatched chunk #78 = documents up to #7900/18846, outstanding queue size 45\n",
      "2022-07-28 13:46:53,165 - PROGRESS: pass 9, dispatched chunk #79 = documents up to #8000/18846, outstanding queue size 46\n",
      "2022-07-28 13:46:53,166 - PROGRESS: pass 9, dispatched chunk #80 = documents up to #8100/18846, outstanding queue size 47\n",
      "2022-07-28 13:46:53,177 - PROGRESS: pass 9, dispatched chunk #81 = documents up to #8200/18846, outstanding queue size 47\n",
      "2022-07-28 13:46:53,183 - PROGRESS: pass 9, dispatched chunk #82 = documents up to #8300/18846, outstanding queue size 48\n",
      "2022-07-28 13:46:53,237 - PROGRESS: pass 9, dispatched chunk #83 = documents up to #8400/18846, outstanding queue size 48\n",
      "2022-07-28 13:46:53,242 - PROGRESS: pass 9, dispatched chunk #84 = documents up to #8500/18846, outstanding queue size 49\n",
      "2022-07-28 13:46:53,317 - PROGRESS: pass 9, dispatched chunk #85 = documents up to #8600/18846, outstanding queue size 49\n",
      "2022-07-28 13:46:53,317 - PROGRESS: pass 9, dispatched chunk #86 = documents up to #8700/18846, outstanding queue size 50\n",
      "2022-07-28 13:46:53,318 - PROGRESS: pass 9, dispatched chunk #87 = documents up to #8800/18846, outstanding queue size 51\n",
      "2022-07-28 13:46:53,339 - PROGRESS: pass 9, dispatched chunk #88 = documents up to #8900/18846, outstanding queue size 51\n",
      "2022-07-28 13:46:53,343 - PROGRESS: pass 9, dispatched chunk #89 = documents up to #9000/18846, outstanding queue size 52\n",
      "2022-07-28 13:46:53,364 - PROGRESS: pass 9, dispatched chunk #90 = documents up to #9100/18846, outstanding queue size 52\n",
      "2022-07-28 13:46:53,378 - PROGRESS: pass 9, dispatched chunk #91 = documents up to #9200/18846, outstanding queue size 53\n",
      "2022-07-28 13:46:53,387 - PROGRESS: pass 9, dispatched chunk #92 = documents up to #9300/18846, outstanding queue size 54\n",
      "2022-07-28 13:46:53,423 - PROGRESS: pass 9, dispatched chunk #93 = documents up to #9400/18846, outstanding queue size 53\n",
      "2022-07-28 13:46:53,435 - PROGRESS: pass 9, dispatched chunk #94 = documents up to #9500/18846, outstanding queue size 53\n",
      "2022-07-28 13:46:53,554 - PROGRESS: pass 9, dispatched chunk #95 = documents up to #9600/18846, outstanding queue size 53\n",
      "2022-07-28 13:46:53,645 - PROGRESS: pass 9, dispatched chunk #96 = documents up to #9700/18846, outstanding queue size 53\n",
      "2022-07-28 13:46:53,661 - PROGRESS: pass 9, dispatched chunk #97 = documents up to #9800/18846, outstanding queue size 54\n",
      "2022-07-28 13:46:53,662 - PROGRESS: pass 9, dispatched chunk #98 = documents up to #9900/18846, outstanding queue size 55\n",
      "2022-07-28 13:46:53,740 - PROGRESS: pass 9, dispatched chunk #99 = documents up to #10000/18846, outstanding queue size 56\n",
      "2022-07-28 13:46:53,757 - PROGRESS: pass 9, dispatched chunk #100 = documents up to #10100/18846, outstanding queue size 54\n",
      "2022-07-28 13:46:53,764 - PROGRESS: pass 9, dispatched chunk #101 = documents up to #10200/18846, outstanding queue size 55\n",
      "2022-07-28 13:46:53,769 - PROGRESS: pass 9, dispatched chunk #102 = documents up to #10300/18846, outstanding queue size 56\n",
      "2022-07-28 13:46:53,771 - PROGRESS: pass 9, dispatched chunk #103 = documents up to #10400/18846, outstanding queue size 57\n",
      "2022-07-28 13:46:53,784 - PROGRESS: pass 9, dispatched chunk #104 = documents up to #10500/18846, outstanding queue size 58\n",
      "2022-07-28 13:46:53,786 - PROGRESS: pass 9, dispatched chunk #105 = documents up to #10600/18846, outstanding queue size 59\n",
      "2022-07-28 13:46:53,799 - PROGRESS: pass 9, dispatched chunk #106 = documents up to #10700/18846, outstanding queue size 60\n",
      "2022-07-28 13:46:53,996 - merging changes from 1600 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:54,061 - topic #2 (0.100): 0.006*\"space\" + 0.005*\"time\" + 0.004*\"key\" + 0.004*\"government\" + 0.004*\"people\" + 0.003*\"car\" + 0.003*\"encryption\" + 0.003*\"power\" + 0.003*\"chip\" + 0.002*\"public\"\n",
      "2022-07-28 13:46:54,066 - topic #4 (0.100): 0.014*\"god\" + 0.010*\"people\" + 0.006*\"jesus\" + 0.005*\"time\" + 0.004*\"bible\" + 0.004*\"christ\" + 0.003*\"life\" + 0.003*\"gun\" + 0.003*\"christian\" + 0.003*\"law\"\n",
      "2022-07-28 13:46:54,067 - topic #1 (0.100): 0.010*\"file\" + 0.007*\"windows\" + 0.006*\"program\" + 0.006*\"mail\" + 0.006*\"software\" + 0.005*\"ftp\" + 0.005*\"graphics\" + 0.005*\"dos\" + 0.005*\"files\" + 0.004*\"data\"\n",
      "2022-07-28 13:46:54,069 - topic #3 (0.100): 0.011*\"game\" + 0.008*\"team\" + 0.006*\"games\" + 0.006*\"play\" + 0.004*\"time\" + 0.004*\"season\" + 0.004*\"period\" + 0.004*\"hockey\" + 0.004*\"win\" + 0.004*\"players\"\n",
      "2022-07-28 13:46:54,070 - topic #0 (0.100): 0.015*\"drive\" + 0.010*\"card\" + 0.009*\"scsi\" + 0.009*\"mb\" + 0.007*\"disk\" + 0.006*\"hard\" + 0.006*\"bit\" + 0.006*\"mhz\" + 0.005*\"bus\" + 0.005*\"mac\"\n",
      "2022-07-28 13:46:54,072 - topic diff=0.042008, rho=0.070984\n",
      "2022-07-28 13:46:54,073 - PROGRESS: pass 9, dispatched chunk #107 = documents up to #10800/18846, outstanding queue size 59\n",
      "2022-07-28 13:46:54,097 - PROGRESS: pass 9, dispatched chunk #108 = documents up to #10900/18846, outstanding queue size 54\n",
      "2022-07-28 13:46:54,101 - PROGRESS: pass 9, dispatched chunk #109 = documents up to #11000/18846, outstanding queue size 55\n",
      "2022-07-28 13:46:54,102 - PROGRESS: pass 9, dispatched chunk #110 = documents up to #11100/18846, outstanding queue size 56\n",
      "2022-07-28 13:46:54,104 - PROGRESS: pass 9, dispatched chunk #111 = documents up to #11200/18846, outstanding queue size 57\n",
      "2022-07-28 13:46:54,105 - PROGRESS: pass 9, dispatched chunk #112 = documents up to #11300/18846, outstanding queue size 58\n",
      "2022-07-28 13:46:54,107 - PROGRESS: pass 9, dispatched chunk #113 = documents up to #11400/18846, outstanding queue size 59\n",
      "2022-07-28 13:46:54,108 - PROGRESS: pass 9, dispatched chunk #114 = documents up to #11500/18846, outstanding queue size 60\n",
      "2022-07-28 13:46:54,110 - PROGRESS: pass 9, dispatched chunk #115 = documents up to #11600/18846, outstanding queue size 61\n",
      "2022-07-28 13:46:54,113 - PROGRESS: pass 9, dispatched chunk #116 = documents up to #11700/18846, outstanding queue size 62\n",
      "2022-07-28 13:46:54,135 - PROGRESS: pass 9, dispatched chunk #117 = documents up to #11800/18846, outstanding queue size 63\n",
      "2022-07-28 13:46:54,140 - PROGRESS: pass 9, dispatched chunk #118 = documents up to #11900/18846, outstanding queue size 64\n",
      "2022-07-28 13:46:54,184 - PROGRESS: pass 9, dispatched chunk #119 = documents up to #12000/18846, outstanding queue size 64\n",
      "2022-07-28 13:46:54,204 - PROGRESS: pass 9, dispatched chunk #120 = documents up to #12100/18846, outstanding queue size 62\n",
      "2022-07-28 13:46:54,210 - PROGRESS: pass 9, dispatched chunk #121 = documents up to #12200/18846, outstanding queue size 63\n",
      "2022-07-28 13:46:54,212 - PROGRESS: pass 9, dispatched chunk #122 = documents up to #12300/18846, outstanding queue size 64\n",
      "2022-07-28 13:46:54,501 - merging changes from 1600 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:54,603 - topic #5 (0.100): 0.008*\"armenian\" + 0.006*\"azerbaijan\" + 0.004*\"russian\" + 0.003*\"armenia\" + 0.003*\"source\" + 0.003*\"azeri\" + 0.003*\"armenians\" + 0.003*\"xfree\" + 0.003*\"book\" + 0.002*\"dead\"\n",
      "2022-07-28 13:46:54,608 - topic #2 (0.100): 0.006*\"space\" + 0.005*\"time\" + 0.004*\"key\" + 0.004*\"government\" + 0.004*\"people\" + 0.003*\"car\" + 0.003*\"encryption\" + 0.003*\"power\" + 0.003*\"chip\" + 0.003*\"clipper\"\n",
      "2022-07-28 13:46:54,611 - topic #6 (0.100): 0.008*\"hz\" + 0.006*\"ww\" + 0.006*\"scx\" + 0.005*\"st\" + 0.005*\"uw\" + 0.004*\"zd\" + 0.004*\"tl\" + 0.004*\"cj\" + 0.004*\"appears\" + 0.004*\"md\"\n",
      "2022-07-28 13:46:54,614 - topic #9 (0.100): 0.014*\"people\" + 0.005*\"government\" + 0.005*\"israel\" + 0.004*\"president\" + 0.004*\"time\" + 0.004*\"war\" + 0.004*\"jews\" + 0.003*\"children\" + 0.003*\"turkish\" + 0.003*\"armenians\"\n",
      "2022-07-28 13:46:54,616 - topic #0 (0.100): 0.015*\"drive\" + 0.010*\"card\" + 0.009*\"scsi\" + 0.009*\"mb\" + 0.007*\"disk\" + 0.006*\"bit\" + 0.006*\"hard\" + 0.006*\"mhz\" + 0.005*\"bus\" + 0.005*\"mac\"\n",
      "2022-07-28 13:46:54,620 - topic diff=0.033151, rho=0.070984\n",
      "2022-07-28 13:46:54,623 - PROGRESS: pass 9, dispatched chunk #123 = documents up to #12400/18846, outstanding queue size 59\n",
      "2022-07-28 13:46:54,634 - PROGRESS: pass 9, dispatched chunk #124 = documents up to #12500/18846, outstanding queue size 58\n",
      "2022-07-28 13:46:54,638 - PROGRESS: pass 9, dispatched chunk #125 = documents up to #12600/18846, outstanding queue size 59\n",
      "2022-07-28 13:46:54,640 - PROGRESS: pass 9, dispatched chunk #126 = documents up to #12700/18846, outstanding queue size 60\n",
      "2022-07-28 13:46:54,646 - PROGRESS: pass 9, dispatched chunk #127 = documents up to #12800/18846, outstanding queue size 61\n",
      "2022-07-28 13:46:54,647 - PROGRESS: pass 9, dispatched chunk #128 = documents up to #12900/18846, outstanding queue size 62\n",
      "2022-07-28 13:46:54,651 - PROGRESS: pass 9, dispatched chunk #129 = documents up to #13000/18846, outstanding queue size 63\n",
      "2022-07-28 13:46:54,653 - PROGRESS: pass 9, dispatched chunk #130 = documents up to #13100/18846, outstanding queue size 64\n",
      "2022-07-28 13:46:54,654 - PROGRESS: pass 9, dispatched chunk #131 = documents up to #13200/18846, outstanding queue size 65\n",
      "2022-07-28 13:46:54,656 - PROGRESS: pass 9, dispatched chunk #132 = documents up to #13300/18846, outstanding queue size 66\n",
      "2022-07-28 13:46:54,657 - PROGRESS: pass 9, dispatched chunk #133 = documents up to #13400/18846, outstanding queue size 67\n",
      "2022-07-28 13:46:54,659 - PROGRESS: pass 9, dispatched chunk #134 = documents up to #13500/18846, outstanding queue size 68\n",
      "2022-07-28 13:46:54,661 - PROGRESS: pass 9, dispatched chunk #135 = documents up to #13600/18846, outstanding queue size 69\n",
      "2022-07-28 13:46:54,665 - PROGRESS: pass 9, dispatched chunk #136 = documents up to #13700/18846, outstanding queue size 70\n",
      "2022-07-28 13:46:54,665 - PROGRESS: pass 9, dispatched chunk #137 = documents up to #13800/18846, outstanding queue size 71\n",
      "2022-07-28 13:46:54,666 - PROGRESS: pass 9, dispatched chunk #138 = documents up to #13900/18846, outstanding queue size 72\n",
      "2022-07-28 13:46:54,667 - PROGRESS: pass 9, dispatched chunk #139 = documents up to #14000/18846, outstanding queue size 73\n",
      "2022-07-28 13:46:54,686 - PROGRESS: pass 9, dispatched chunk #140 = documents up to #14100/18846, outstanding queue size 73\n",
      "2022-07-28 13:46:54,761 - PROGRESS: pass 9, dispatched chunk #141 = documents up to #14200/18846, outstanding queue size 70\n",
      "2022-07-28 13:46:54,800 - PROGRESS: pass 9, dispatched chunk #142 = documents up to #14300/18846, outstanding queue size 71\n",
      "2022-07-28 13:46:54,839 - PROGRESS: pass 9, dispatched chunk #143 = documents up to #14400/18846, outstanding queue size 72\n",
      "2022-07-28 13:46:54,844 - PROGRESS: pass 9, dispatched chunk #144 = documents up to #14500/18846, outstanding queue size 73\n",
      "2022-07-28 13:46:54,874 - PROGRESS: pass 9, dispatched chunk #145 = documents up to #14600/18846, outstanding queue size 74\n",
      "2022-07-28 13:46:54,884 - PROGRESS: pass 9, dispatched chunk #146 = documents up to #14700/18846, outstanding queue size 75\n",
      "2022-07-28 13:46:54,912 - PROGRESS: pass 9, dispatched chunk #147 = documents up to #14800/18846, outstanding queue size 74\n",
      "2022-07-28 13:46:54,925 - PROGRESS: pass 9, dispatched chunk #148 = documents up to #14900/18846, outstanding queue size 73\n",
      "2022-07-28 13:46:54,932 - PROGRESS: pass 9, dispatched chunk #149 = documents up to #15000/18846, outstanding queue size 72\n",
      "2022-07-28 13:46:54,933 - PROGRESS: pass 9, dispatched chunk #150 = documents up to #15100/18846, outstanding queue size 73\n",
      "2022-07-28 13:46:54,964 - PROGRESS: pass 9, dispatched chunk #151 = documents up to #15200/18846, outstanding queue size 74\n",
      "2022-07-28 13:46:54,997 - PROGRESS: pass 9, dispatched chunk #152 = documents up to #15300/18846, outstanding queue size 75\n",
      "2022-07-28 13:46:55,000 - PROGRESS: pass 9, dispatched chunk #153 = documents up to #15400/18846, outstanding queue size 76\n",
      "2022-07-28 13:46:55,004 - PROGRESS: pass 9, dispatched chunk #154 = documents up to #15500/18846, outstanding queue size 77\n",
      "2022-07-28 13:46:55,012 - PROGRESS: pass 9, dispatched chunk #155 = documents up to #15600/18846, outstanding queue size 77\n",
      "2022-07-28 13:46:55,013 - PROGRESS: pass 9, dispatched chunk #156 = documents up to #15700/18846, outstanding queue size 78\n",
      "2022-07-28 13:46:55,036 - PROGRESS: pass 9, dispatched chunk #157 = documents up to #15800/18846, outstanding queue size 79\n",
      "2022-07-28 13:46:55,041 - PROGRESS: pass 9, dispatched chunk #158 = documents up to #15900/18846, outstanding queue size 80\n",
      "2022-07-28 13:46:55,045 - PROGRESS: pass 9, dispatched chunk #159 = documents up to #16000/18846, outstanding queue size 81\n",
      "2022-07-28 13:46:55,136 - merging changes from 1500 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:55,264 - topic #0 (0.100): 0.015*\"drive\" + 0.010*\"card\" + 0.009*\"scsi\" + 0.008*\"mb\" + 0.007*\"disk\" + 0.006*\"bit\" + 0.006*\"hard\" + 0.006*\"mhz\" + 0.005*\"mac\" + 0.005*\"bus\"\n",
      "2022-07-28 13:46:55,278 - topic #6 (0.100): 0.008*\"hz\" + 0.007*\"ww\" + 0.006*\"uw\" + 0.006*\"scx\" + 0.005*\"st\" + 0.004*\"zd\" + 0.004*\"appears\" + 0.004*\"cj\" + 0.004*\"tl\" + 0.004*\"art\"\n",
      "2022-07-28 13:46:55,279 - topic #2 (0.100): 0.006*\"space\" + 0.005*\"time\" + 0.004*\"key\" + 0.004*\"government\" + 0.004*\"people\" + 0.003*\"car\" + 0.003*\"encryption\" + 0.003*\"power\" + 0.003*\"chip\" + 0.003*\"clipper\"\n",
      "2022-07-28 13:46:55,281 - topic #1 (0.100): 0.009*\"file\" + 0.007*\"windows\" + 0.006*\"program\" + 0.006*\"mail\" + 0.006*\"software\" + 0.005*\"ftp\" + 0.005*\"graphics\" + 0.004*\"files\" + 0.004*\"dos\" + 0.004*\"data\"\n",
      "2022-07-28 13:46:55,282 - topic #4 (0.100): 0.014*\"god\" + 0.010*\"people\" + 0.006*\"jesus\" + 0.005*\"time\" + 0.004*\"bible\" + 0.003*\"life\" + 0.003*\"christ\" + 0.003*\"gun\" + 0.003*\"christian\" + 0.003*\"law\"\n",
      "2022-07-28 13:46:55,285 - topic diff=0.036993, rho=0.070984\n",
      "2022-07-28 13:46:55,293 - PROGRESS: pass 9, dispatched chunk #160 = documents up to #16100/18846, outstanding queue size 81\n",
      "2022-07-28 13:46:55,297 - PROGRESS: pass 9, dispatched chunk #161 = documents up to #16200/18846, outstanding queue size 81\n",
      "2022-07-28 13:46:55,299 - PROGRESS: pass 9, dispatched chunk #162 = documents up to #16300/18846, outstanding queue size 82\n",
      "2022-07-28 13:46:55,300 - PROGRESS: pass 9, dispatched chunk #163 = documents up to #16400/18846, outstanding queue size 83\n",
      "2022-07-28 13:46:55,302 - PROGRESS: pass 9, dispatched chunk #164 = documents up to #16500/18846, outstanding queue size 84\n",
      "2022-07-28 13:46:55,306 - PROGRESS: pass 9, dispatched chunk #165 = documents up to #16600/18846, outstanding queue size 85\n",
      "2022-07-28 13:46:55,308 - PROGRESS: pass 9, dispatched chunk #166 = documents up to #16700/18846, outstanding queue size 86\n",
      "2022-07-28 13:46:55,309 - PROGRESS: pass 9, dispatched chunk #167 = documents up to #16800/18846, outstanding queue size 87\n",
      "2022-07-28 13:46:55,311 - PROGRESS: pass 9, dispatched chunk #168 = documents up to #16900/18846, outstanding queue size 88\n",
      "2022-07-28 13:46:55,312 - PROGRESS: pass 9, dispatched chunk #169 = documents up to #17000/18846, outstanding queue size 89\n",
      "2022-07-28 13:46:55,313 - PROGRESS: pass 9, dispatched chunk #170 = documents up to #17100/18846, outstanding queue size 90\n",
      "2022-07-28 13:46:55,328 - PROGRESS: pass 9, dispatched chunk #171 = documents up to #17200/18846, outstanding queue size 91\n",
      "2022-07-28 13:46:55,329 - PROGRESS: pass 9, dispatched chunk #172 = documents up to #17300/18846, outstanding queue size 92\n",
      "2022-07-28 13:46:55,330 - PROGRESS: pass 9, dispatched chunk #173 = documents up to #17400/18846, outstanding queue size 93\n",
      "2022-07-28 13:46:55,365 - PROGRESS: pass 9, dispatched chunk #174 = documents up to #17500/18846, outstanding queue size 94\n",
      "2022-07-28 13:46:55,410 - PROGRESS: pass 9, dispatched chunk #175 = documents up to #17600/18846, outstanding queue size 94\n",
      "2022-07-28 13:46:55,416 - PROGRESS: pass 9, dispatched chunk #176 = documents up to #17700/18846, outstanding queue size 95\n",
      "2022-07-28 13:46:55,418 - PROGRESS: pass 9, dispatched chunk #177 = documents up to #17800/18846, outstanding queue size 96\n",
      "2022-07-28 13:46:55,419 - PROGRESS: pass 9, dispatched chunk #178 = documents up to #17900/18846, outstanding queue size 97\n",
      "2022-07-28 13:46:55,498 - PROGRESS: pass 9, dispatched chunk #179 = documents up to #18000/18846, outstanding queue size 94\n",
      "2022-07-28 13:46:55,499 - PROGRESS: pass 9, dispatched chunk #180 = documents up to #18100/18846, outstanding queue size 95\n",
      "2022-07-28 13:46:55,500 - PROGRESS: pass 9, dispatched chunk #181 = documents up to #18200/18846, outstanding queue size 96\n",
      "2022-07-28 13:46:55,500 - PROGRESS: pass 9, dispatched chunk #182 = documents up to #18300/18846, outstanding queue size 97\n",
      "2022-07-28 13:46:55,513 - PROGRESS: pass 9, dispatched chunk #183 = documents up to #18400/18846, outstanding queue size 98\n",
      "2022-07-28 13:46:55,515 - PROGRESS: pass 9, dispatched chunk #184 = documents up to #18500/18846, outstanding queue size 99\n",
      "2022-07-28 13:46:55,582 - PROGRESS: pass 9, dispatched chunk #185 = documents up to #18600/18846, outstanding queue size 100\n",
      "2022-07-28 13:46:55,614 - PROGRESS: pass 9, dispatched chunk #186 = documents up to #18700/18846, outstanding queue size 100\n",
      "2022-07-28 13:46:55,670 - PROGRESS: pass 9, dispatched chunk #187 = documents up to #18800/18846, outstanding queue size 100\n",
      "2022-07-28 13:46:55,710 - PROGRESS: pass 9, dispatched chunk #188 = documents up to #18846/18846, outstanding queue size 100\n",
      "2022-07-28 13:46:56,383 - merging changes from 1500 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:56,488 - topic #0 (0.100): 0.015*\"drive\" + 0.010*\"card\" + 0.009*\"scsi\" + 0.008*\"mb\" + 0.007*\"disk\" + 0.006*\"bit\" + 0.006*\"hard\" + 0.006*\"mhz\" + 0.005*\"bus\" + 0.005*\"mac\"\n",
      "2022-07-28 13:46:56,490 - topic #7 (0.100): 0.021*\"jpeg\" + 0.013*\"image\" + 0.012*\"gif\" + 0.008*\"file\" + 0.008*\"car\" + 0.007*\"color\" + 0.007*\"images\" + 0.006*\"format\" + 0.006*\"bit\" + 0.005*\"quality\"\n",
      "2022-07-28 13:46:56,491 - topic #5 (0.100): 0.008*\"armenian\" + 0.006*\"azerbaijan\" + 0.004*\"russian\" + 0.003*\"armenia\" + 0.003*\"source\" + 0.003*\"book\" + 0.003*\"armenians\" + 0.003*\"azeri\" + 0.002*\"xfree\" + 0.002*\"dead\"\n",
      "2022-07-28 13:46:56,493 - topic #8 (0.100): 0.694*\"ax\" + 0.055*\"max\" + 0.004*\"ei\" + 0.004*\"di\" + 0.003*\"giz\" + 0.003*\"tm\" + 0.003*\"bhj\" + 0.002*\"ey\" + 0.002*\"wm\" + 0.002*\"qq\"\n",
      "2022-07-28 13:46:56,518 - topic #1 (0.100): 0.010*\"file\" + 0.007*\"windows\" + 0.006*\"program\" + 0.006*\"mail\" + 0.006*\"software\" + 0.005*\"ftp\" + 0.005*\"graphics\" + 0.005*\"files\" + 0.004*\"dos\" + 0.004*\"data\"\n",
      "2022-07-28 13:46:56,521 - topic diff=0.027007, rho=0.070984\n",
      "2022-07-28 13:46:56,633 - -10.409 per-word bound, 1359.4 perplexity estimate based on a held-out corpus of 46 documents with 2932 words\n",
      "2022-07-28 13:46:56,883 - merging changes from 9346 documents into a model of 18846 documents\n",
      "2022-07-28 13:46:56,914 - topic #5 (0.100): 0.008*\"armenian\" + 0.005*\"azerbaijan\" + 0.004*\"russian\" + 0.003*\"armenia\" + 0.003*\"source\" + 0.003*\"book\" + 0.003*\"armenians\" + 0.003*\"azeri\" + 0.002*\"xfree\" + 0.002*\"dead\"\n",
      "2022-07-28 13:46:56,915 - topic #1 (0.100): 0.010*\"file\" + 0.007*\"windows\" + 0.006*\"program\" + 0.006*\"mail\" + 0.006*\"software\" + 0.005*\"ftp\" + 0.005*\"graphics\" + 0.005*\"files\" + 0.005*\"dos\" + 0.004*\"data\"\n",
      "2022-07-28 13:46:56,917 - topic #7 (0.100): 0.021*\"jpeg\" + 0.013*\"image\" + 0.012*\"gif\" + 0.008*\"file\" + 0.008*\"car\" + 0.008*\"color\" + 0.007*\"images\" + 0.006*\"format\" + 0.006*\"bit\" + 0.005*\"quality\"\n",
      "2022-07-28 13:46:56,918 - topic #3 (0.100): 0.012*\"game\" + 0.008*\"team\" + 0.006*\"games\" + 0.006*\"play\" + 0.005*\"period\" + 0.005*\"season\" + 0.004*\"time\" + 0.004*\"win\" + 0.004*\"players\" + 0.004*\"hockey\"\n",
      "2022-07-28 13:46:56,919 - topic #0 (0.100): 0.015*\"drive\" + 0.010*\"card\" + 0.009*\"scsi\" + 0.008*\"mb\" + 0.007*\"disk\" + 0.006*\"hard\" + 0.006*\"bit\" + 0.006*\"mhz\" + 0.005*\"mac\" + 0.005*\"bus\"\n",
      "2022-07-28 13:46:56,920 - topic diff=0.021209, rho=0.070984\n",
      "2022-07-28 13:46:56,990 - -10.392 per-word bound, 1344.0 perplexity estimate based on a held-out corpus of 46 documents with 2932 words\n",
      "2022-07-28 13:46:57,117 - LdaMulticore lifecycle event {'msg': 'trained LdaMulticore<num_terms=84565, num_topics=10, decay=0.5, chunksize=100> in 52.17s', 'datetime': '2022-07-28T13:46:57.117227', 'gensim': '4.2.0', 'python': '3.8.0 (default, Dec  9 2021, 17:53:27) \\n[GCC 8.4.0]', 'platform': 'Linux-5.4.0-1080-azure-x86_64-with-glibc2.27', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "# Build LDA model\n",
    "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                       id2word=id2word,\n",
    "                                       num_topics=10, \n",
    "                                       random_state=100,\n",
    "                                       chunksize=100,\n",
    "                                       passes=10,\n",
    "                                       per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a696899",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.corpora as corpora\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "# Preprocess documents\n",
    "cleaned_docs = topic_model._preprocess_text(docs)\n",
    "\n",
    "# Extract vectorizer and tokenizer from BERTopic\n",
    "vectorizer = topic_model.vectorizer_model\n",
    "tokenizer = vectorizer.build_tokenizer()\n",
    "\n",
    "# Extract features for Topic Coherence evaluation\n",
    "words = vectorizer.get_feature_names()\n",
    "tokens = [tokenizer(doc) for doc in cleaned_docs]\n",
    "dictionary = corpora.Dictionary(tokens)\n",
    "corpus = [dictionary.doc2bow(token) for token in tokens]\n",
    "topic_words = [[words for words, _ in topic_model.get_topic(topic)] \n",
    "               for topic in range(len(set(topics))-1)]\n",
    "\n",
    "# Evaluate\n",
    "coherence_model = CoherenceModel(topics=topic_words, \n",
    "                                 texts=tokens, \n",
    "                                 corpus=corpus,\n",
    "                                 dictionary=dictionary, \n",
    "                                 coherence='c_v')\n",
    "coherence = coherence_model.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "d937829e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-21 {color: black;background-color: white;}#sk-container-id-21 pre{padding: 0;}#sk-container-id-21 div.sk-toggleable {background-color: white;}#sk-container-id-21 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-21 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-21 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-21 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-21 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-21 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-21 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-21 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-21 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-21 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-21 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-21 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-21 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-21 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-21 div.sk-item {position: relative;z-index: 1;}#sk-container-id-21 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-21 div.sk-item::before, #sk-container-id-21 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-21 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-21 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-21 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-21 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-21 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-21 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-21 div.sk-label-container {text-align: center;}#sk-container-id-21 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-21 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-21\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer(stop_words=&#x27;english&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" checked><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(stop_words=&#x27;english&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "CountVectorizer(stop_words='english')"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), stop_words=\"english\")\n",
    "vectorizer.fit(txtClean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "675a7089",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/env/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "words = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "8c1ef5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = vectorizer.build_tokenizer()\n",
    "tokens = [tokenizer(doc) for doc in txtClean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "56ca8ae2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-28 14:54:19,924 - adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2022-07-28 14:54:20,680 - adding document #10000 to Dictionary<76191 unique tokens: ['bashers', 'beat', 'bit', 'bowman', 'confused']...>\n",
      "2022-07-28 14:54:21,336 - built Dictionary<109445 unique tokens: ['bashers', 'beat', 'bit', 'bowman', 'confused']...> from 18846 documents (total 1478445 corpus positions)\n",
      "2022-07-28 14:54:21,337 - Dictionary lifecycle event {'msg': \"built Dictionary<109445 unique tokens: ['bashers', 'beat', 'bit', 'bowman', 'confused']...> from 18846 documents (total 1478445 corpus positions)\", 'datetime': '2022-07-28T14:54:21.337357', 'gensim': '4.2.0', 'python': '3.8.0 (default, Dec  9 2021, 17:53:27) \\n[GCC 8.4.0]', 'platform': 'Linux-5.4.0-1080-azure-x86_64-with-glibc2.27', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "dictionary = corpora.Dictionary(tokens)\n",
    "corpus = [dictionary.doc2bow(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5e70c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-28 14:54:38,860 - using ParallelWordOccurrenceAccumulator<processes=15, batch_size=64> to estimate probabilities from sliding windows\n",
      "2022-07-28 14:54:40,331 - worker encountered unexpected exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 561, in run\n",
      "    self._run()\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 581, in _run\n",
      "    self.accumulator.partial_accumulate(docs, self.window_size)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 353, in partial_accumulate\n",
      "    super(WordOccurrenceAccumulator, self).accumulate(texts, window_size)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 296, in accumulate\n",
      "    self.analyze_text(virtual_document, doc_num)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 360, in analyze_text\n",
      "    self._slide_window(window, doc_num)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 375, in _slide_window\n",
      "    self._token_at_edge = window[0]\n",
      "IndexError: index 0 is out of bounds for axis 0 with size 0\n",
      "2022-07-28 14:54:40,341 - serializing accumulator to return to master...\n",
      "2022-07-28 14:54:40,379 - serializing accumulator to return to master...\n",
      "2022-07-28 14:54:40,345 - worker encountered unexpected exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 561, in run\n",
      "    self._run()\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 581, in _run\n",
      "    self.accumulator.partial_accumulate(docs, self.window_size)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 353, in partial_accumulate\n",
      "    super(WordOccurrenceAccumulator, self).accumulate(texts, window_size)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 296, in accumulate\n",
      "    self.analyze_text(virtual_document, doc_num)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 360, in analyze_text\n",
      "    self._slide_window(window, doc_num)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 375, in _slide_window\n",
      "    self._token_at_edge = window[0]\n",
      "IndexError: index 0 is out of bounds for axis 0 with size 0\n",
      "2022-07-28 14:54:40,352 - serializing accumulator to return to master...\n",
      "2022-07-28 14:54:40,347 - worker encountered unexpected exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 561, in run\n",
      "    self._run()\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 581, in _run\n",
      "    self.accumulator.partial_accumulate(docs, self.window_size)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 353, in partial_accumulate\n",
      "    super(WordOccurrenceAccumulator, self).accumulate(texts, window_size)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 296, in accumulate\n",
      "    self.analyze_text(virtual_document, doc_num)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 360, in analyze_text\n",
      "    self._slide_window(window, doc_num)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 375, in _slide_window\n",
      "    self._token_at_edge = window[0]\n",
      "IndexError: index 0 is out of bounds for axis 0 with size 0\n",
      "2022-07-28 14:54:40,356 - serializing accumulator to return to master...\n",
      "2022-07-28 14:54:40,370 - worker encountered unexpected exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 561, in run\n",
      "    self._run()\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 581, in _run\n",
      "    self.accumulator.partial_accumulate(docs, self.window_size)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 353, in partial_accumulate\n",
      "    super(WordOccurrenceAccumulator, self).accumulate(texts, window_size)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 296, in accumulate\n",
      "    self.analyze_text(virtual_document, doc_num)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 360, in analyze_text\n",
      "    self._slide_window(window, doc_num)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 375, in _slide_window\n",
      "    self._token_at_edge = window[0]\n",
      "IndexError: index 0 is out of bounds for axis 0 with size 0\n",
      "2022-07-28 14:54:40,359 - accumulator serialized\n",
      "2022-07-28 14:54:40,330 - worker encountered unexpected exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 561, in run\n",
      "    self._run()\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 581, in _run\n",
      "    self.accumulator.partial_accumulate(docs, self.window_size)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 353, in partial_accumulate\n",
      "    super(WordOccurrenceAccumulator, self).accumulate(texts, window_size)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 296, in accumulate\n",
      "    self.analyze_text(virtual_document, doc_num)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 360, in analyze_text\n",
      "    self._slide_window(window, doc_num)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 375, in _slide_window\n",
      "    self._token_at_edge = window[0]\n",
      "IndexError: index 0 is out of bounds for axis 0 with size 0\n",
      "2022-07-28 14:54:40,327 - worker encountered unexpected exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 561, in run\n",
      "    self._run()\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 581, in _run\n",
      "    self.accumulator.partial_accumulate(docs, self.window_size)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 353, in partial_accumulate\n",
      "    super(WordOccurrenceAccumulator, self).accumulate(texts, window_size)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 296, in accumulate\n",
      "    self.analyze_text(virtual_document, doc_num)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 360, in analyze_text\n",
      "    self._slide_window(window, doc_num)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 375, in _slide_window\n",
      "    self._token_at_edge = window[0]\n",
      "IndexError: index 0 is out of bounds for axis 0 with size 0\n",
      "2022-07-28 14:54:40,362 - serializing accumulator to return to master...\n",
      "2022-07-28 14:54:40,362 - serializing accumulator to return to master...\n",
      "2022-07-28 14:54:40,365 - accumulator serialized\n",
      "2022-07-28 14:54:40,365 - accumulator serialized\n",
      "2022-07-28 14:54:40,389 - 22 batches submitted to accumulate stats from 1408 documents (-59783 virtual)\n",
      "2022-07-28 14:54:40,394 - accumulator serialized\n",
      "2022-07-28 14:54:40,383 - worker encountered unexpected exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 561, in run\n",
      "    self._run()\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 581, in _run\n",
      "    self.accumulator.partial_accumulate(docs, self.window_size)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 353, in partial_accumulate\n",
      "    super(WordOccurrenceAccumulator, self).accumulate(texts, window_size)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 296, in accumulate\n",
      "    self.analyze_text(virtual_document, doc_num)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 360, in analyze_text\n",
      "    self._slide_window(window, doc_num)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 375, in _slide_window\n",
      "    self._token_at_edge = window[0]\n",
      "IndexError: index 0 is out of bounds for axis 0 with size 0\n",
      "2022-07-28 14:54:40,395 - worker encountered unexpected exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 561, in run\n",
      "    self._run()\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 581, in _run\n",
      "    self.accumulator.partial_accumulate(docs, self.window_size)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 353, in partial_accumulate\n",
      "    super(WordOccurrenceAccumulator, self).accumulate(texts, window_size)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 296, in accumulate\n",
      "    self.analyze_text(virtual_document, doc_num)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 360, in analyze_text\n",
      "    self._slide_window(window, doc_num)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 375, in _slide_window\n",
      "    self._token_at_edge = window[0]\n",
      "IndexError: index 0 is out of bounds for axis 0 with size 0\n",
      "2022-07-28 14:54:40,420 - serializing accumulator to return to master...\n",
      "2022-07-28 14:54:40,420 - serializing accumulator to return to master...\n",
      "2022-07-28 14:54:40,425 - 29 batches submitted to accumulate stats from 1856 documents (-79965 virtual)\n",
      "2022-07-28 14:54:40,422 - worker encountered unexpected exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 561, in run\n",
      "    self._run()\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 581, in _run\n",
      "    self.accumulator.partial_accumulate(docs, self.window_size)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 353, in partial_accumulate\n",
      "    super(WordOccurrenceAccumulator, self).accumulate(texts, window_size)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 296, in accumulate\n",
      "    self.analyze_text(virtual_document, doc_num)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 360, in analyze_text\n",
      "    self._slide_window(window, doc_num)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 375, in _slide_window\n",
      "    self._token_at_edge = window[0]\n",
      "IndexError: index 0 is out of bounds for axis 0 with size 0\n",
      "2022-07-28 14:54:40,430 - accumulator serialized\n",
      "2022-07-28 14:54:40,435 - 31 batches submitted to accumulate stats from 1984 documents (-80887 virtual)\n",
      "2022-07-28 14:54:40,427 - worker encountered unexpected exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 561, in run\n",
      "    self._run()\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 581, in _run\n",
      "    self.accumulator.partial_accumulate(docs, self.window_size)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 353, in partial_accumulate\n",
      "    super(WordOccurrenceAccumulator, self).accumulate(texts, window_size)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 296, in accumulate\n",
      "    self.analyze_text(virtual_document, doc_num)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 360, in analyze_text\n",
      "    self._slide_window(window, doc_num)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 375, in _slide_window\n",
      "    self._token_at_edge = window[0]\n",
      "IndexError: index 0 is out of bounds for axis 0 with size 0\n",
      "2022-07-28 14:54:40,409 - worker encountered unexpected exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 561, in run\n",
      "    self._run()\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 581, in _run\n",
      "    self.accumulator.partial_accumulate(docs, self.window_size)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 353, in partial_accumulate\n",
      "    super(WordOccurrenceAccumulator, self).accumulate(texts, window_size)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 296, in accumulate\n",
      "    self.analyze_text(virtual_document, doc_num)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 360, in analyze_text\n",
      "    self._slide_window(window, doc_num)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 375, in _slide_window\n",
      "    self._token_at_edge = window[0]\n",
      "IndexError: index 0 is out of bounds for axis 0 with size 0\n",
      "2022-07-28 14:54:40,444 - serializing accumulator to return to master...\n",
      "2022-07-28 14:54:40,445 - worker encountered unexpected exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 561, in run\n",
      "    self._run()\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 581, in _run\n",
      "    self.accumulator.partial_accumulate(docs, self.window_size)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 353, in partial_accumulate\n",
      "    super(WordOccurrenceAccumulator, self).accumulate(texts, window_size)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 296, in accumulate\n",
      "    self.analyze_text(virtual_document, doc_num)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 360, in analyze_text\n",
      "    self._slide_window(window, doc_num)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 375, in _slide_window\n",
      "    self._token_at_edge = window[0]\n",
      "IndexError: index 0 is out of bounds for axis 0 with size 0\n",
      "2022-07-28 14:54:40,436 - worker encountered unexpected exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 561, in run\n",
      "    self._run()\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 581, in _run\n",
      "    self.accumulator.partial_accumulate(docs, self.window_size)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 353, in partial_accumulate\n",
      "    super(WordOccurrenceAccumulator, self).accumulate(texts, window_size)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 296, in accumulate\n",
      "    self.analyze_text(virtual_document, doc_num)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 360, in analyze_text\n",
      "    self._slide_window(window, doc_num)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 375, in _slide_window\n",
      "    self._token_at_edge = window[0]\n",
      "IndexError: index 0 is out of bounds for axis 0 with size 0\n",
      "2022-07-28 14:54:40,452 - serializing accumulator to return to master...\n",
      "2022-07-28 14:54:40,444 - serializing accumulator to return to master...\n",
      "2022-07-28 14:54:40,453 - serializing accumulator to return to master...\n",
      "2022-07-28 14:54:40,457 - accumulator serialized\n",
      "2022-07-28 14:54:40,453 - serializing accumulator to return to master...\n",
      "2022-07-28 14:54:40,471 - accumulator serialized\n",
      "2022-07-28 14:54:40,476 - accumulator serialized\n",
      "2022-07-28 14:54:40,479 - worker encountered unexpected exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 561, in run\n",
      "    self._run()\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 581, in _run\n",
      "    self.accumulator.partial_accumulate(docs, self.window_size)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 353, in partial_accumulate\n",
      "    super(WordOccurrenceAccumulator, self).accumulate(texts, window_size)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 296, in accumulate\n",
      "    self.analyze_text(virtual_document, doc_num)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 360, in analyze_text\n",
      "    self._slide_window(window, doc_num)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 375, in _slide_window\n",
      "    self._token_at_edge = window[0]\n",
      "IndexError: index 0 is out of bounds for axis 0 with size 0\n",
      "2022-07-28 14:54:40,504 - serializing accumulator to return to master...\n",
      "2022-07-28 14:54:40,355 - accumulator serialized\n",
      "2022-07-28 14:54:40,342 - accumulator serialized\n",
      "2022-07-28 14:54:40,535 - accumulator serialized\n",
      "2022-07-28 14:54:40,430 - accumulator serialized\n",
      "2022-07-28 14:54:40,465 - accumulator serialized\n",
      "2022-07-28 14:54:40,632 - worker encountered unexpected exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 561, in run\n",
      "    self._run()\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 581, in _run\n",
      "    self.accumulator.partial_accumulate(docs, self.window_size)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 353, in partial_accumulate\n",
      "    super(WordOccurrenceAccumulator, self).accumulate(texts, window_size)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 296, in accumulate\n",
      "    self.analyze_text(virtual_document, doc_num)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 360, in analyze_text\n",
      "    self._slide_window(window, doc_num)\n",
      "  File \"/data/env/lib/python3.8/site-packages/gensim/topic_coherence/text_analysis.py\", line 375, in _slide_window\n",
      "    self._token_at_edge = window[0]\n",
      "IndexError: index 0 is out of bounds for axis 0 with size 0\n",
      "2022-07-28 14:54:40,635 - serializing accumulator to return to master...\n",
      "2022-07-28 14:54:40,463 - accumulator serialized\n",
      "2022-07-28 14:54:40,636 - accumulator serialized\n"
     ]
    }
   ],
   "source": [
    "coherence_model = CoherenceModel(topics=topicc, \n",
    "                                 texts=tokens, \n",
    "                                 corpus=corpus,\n",
    "                                 dictionary=dictionary, \n",
    "                                 coherence='c_v')\n",
    "coherence = coherence_model.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "c89cf120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5.579879075280098"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coherence"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
